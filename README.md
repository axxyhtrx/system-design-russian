WIP: Это перевод основного репозитория по системному дизайну.

# Системный дизайн

Добро пожаловать на курс. Надеюсь, вы получите удовольствие от обучения.

_Этот курс также доступен по ссылке [website](https://karanpratapsingh.com/courses/system-design) и в виде электронной книги [leanpub](https://leanpub.com/systemdesign). Пожалуйста поставьте ⭐ для мотивации, если этот курс был полезным для вас!_

# Содержание

- **Приступая к работе**

  - [Что такое системный дизайн](#what-is-system-design)

- **Часть I**

  - [IP](#ip)
  - [Модель OSI](#osi-model)
  - [TCP и UDP](#tcp-and-udp)
  - [Система доменных имён (DNS)](#domain-name-system-dns)
  - [Балансировка нагрузки](#load-balancing)
  - [Кластеры](#clustering)
  - [Кеширование](#caching)
  - [Content Delivery Network (CDN)](#content-delivery-network-cdn)
  - [Прокси](#proxy)
  - [Доступность](#availability)
  - [Масштабируемость](#scalability)
  - [Хранилище](#storage)

- **Часть II**

  - [Базы данных и СУБД](#databases-and-dbms)
  - [SQL базы данных](#sql-databases)
  - [NoSQL базы данных](#nosql-databases)
  - [SQL vs NoSQL](#sql-vs-nosql-databases)
  - [Реплицирование баз данных](#database-replication)
  - [Индексы](#indexes)
  - [Нормализация и денормализация](#normalization-and-denormalization)
  - [ACID и BASE модели согласованности](#acid-and-base-consistency-models)
  - [CAP теорема](#cap-theorem)
  - [PACELC теорема](#pacelc-theorem)
  - [Транзакции](#transactions)
  - [Распределённые транзакции](#distributed-transactions)
  - [Шардирование](#sharding)
  - [Согласованное хеширование](#consistent-hashing)
  - [Федерация баз данных](#database-federation)

- **Часть III**

  - [N-уровневая архитектура](#n-tier-architecture)
  - [Брокеры сообщений](#message-brokers)
  - [Очереди сообщений](#message-queues)
  - [Модель Издатель — подписчик(PUB-SUB)](#publish-subscribe)
  - [Корпоративная сервисная шина (ESB)](#enterprise-service-bus-esb)
  - [Монолиты и Микросервисы](#monoliths-and-microservices)
  - [Событийно-ориентированная архитектура (EDA)](#event-driven-architecture-eda)
  - [Источники событий](#event-sourcing)
  - [Command and Query Responsibility Segregation (CQRS)](#command-and-query-responsibility-segregation-cqrs)
  - [API Gateway](#api-gateway)
  - [REST, GraphQL, gRPC](#rest-graphql-grpc)
  - [Длинные опросы, Web сокеты, Server-Sent Events (SSE)](#long-polling-websockets-server-sent-events-sse)

- **Часть IV**

  - [Геохеширование и квадродерево](#geohashing-and-quadtrees)
  - [Circuit breaker](#circuit-breaker)
  - [Rate Limiting](#rate-limiting)
  - [Service Discovery](#service-discovery)
  - [SLA, SLO, SLI](#sla-slo-sli)
  - [Disaster recovery](#disaster-recovery)
  - [Virtual Machines (VMs) and Containers](#virtual-machines-vms-and-containers)
  - [OAuth 2.0 and OpenID Connect (OIDC)](#oauth-20-and-openid-connect-oidc)
  - [Single Sign-On (SSO)](#single-sign-on-sso)
  - [SSL, TLS, mTLS](#ssl-tls-mtls)

- **Часть V**

  - [System Design Interviews](#system-design-interviews)
  - [URL Shortener](#url-shortener)
  - [WhatsApp](#whatsapp)
  - [Twitter](#twitter)
  - [Netflix](#netflix)
  - [Uber](#uber)

- **Дополнения**

  - [Next Steps](#next-steps)
  - [References](#references)

# Что такое системный дизайн?

Прежде чем мы начнем этот курс, давайте поговорим о том, что вообще такое системный дизайн.

Проектирование системы - это процесс определения архитектуры, интерфейсов и данных для системы, удовлетворяющей определенным требованиям. Системный дизайн удовлетворяет потребности вашего бизнеса или организации с помощью слаженных и эффективных систем. Он требует систематического подхода к созданию и проектированию систем. Хороший системный дизайн требует, чтобы мы думали обо всем, начиная с инфраструктуры и заканчивая данными и способами их хранения.


## Why is System Design so important?

Проектирование системы помогает нам определить решение, которое отвечает требованиям бизнеса. Это
одно из самых ранних решений, которые мы можем принять при создании системы. Часто очень важно
мыслить на высоком уровне, поскольку эти решения очень сложно исправить впоследствии. Это
также облегчает рассуждения и управление архитектурными изменениями по мере развития системы.

# IP

IP-адрес - это уникальный адрес, идентифицирующий устройство в Интернете или локальной сети. IP расшифровывается как _"Интернет-протокол"_, который представляет собой набор правил, определяющих формат данных, передаваемых через Интернет или локальную сеть.

По сути, IP-адреса - это идентификатор, позволяющий пересылать информацию между устройствами в сети. Они содержат информацию о местоположении и делают устройства доступными для связи. Интернету необходим способ различать разные компьютеры, маршрутизаторы и веб-сайты. IP-адреса обеспечивают такой способ и являются важной частью работы интернета.

## Versions

Теперь давайте узнаем о различных версиях IP-адресов:

### IPv4

Оригинальный протокол Интернета - IPv4, использующий 32-битную цифровую десятичную систему счисления, которая позволяет использовать только около 4 миллиардов IP-адресов. Изначально этого было более чем достаточно, но по мере распространения Интернета нам потребовалось что-то лучшее.

_Пример: `102.22.192.181`._

### IPv6

IPv6 - это новый протокол, который был представлен в 1998 году. Его развертывание началось в середине 2000-х годов, а поскольку число пользователей Интернета растет в геометрической прогрессии, оно продолжается до сих пор.

Этот новый протокол использует 128-битную буквенно-цифровую шестнадцатеричную нотацию. Это означает, что IPv6 может предоставить около ~340e+36 IP-адресов. Этого более чем достаточно, чтобы удовлетворить растущий спрос на годы вперед.

_Пример: `2001:0db8:85a3:0000:0000:8a2e:0370:7334`_

## Types

Давайте обсудим типы IP-адресов:

### Public

Публичный IP-адрес - это адрес, в котором один основной адрес связан со всей вашей сетью. При таком типе IP-адреса каждое из подключенных устройств имеет один и тот же IP-адрес.

Пример: IP-адрес, предоставленный вашему маршрутизатору интернет-провайдером.

### Private

Частный IP-адрес - это уникальный IP-номер, присваиваемый каждому устройству, которое подключается к вашей интернет-сети, включая такие устройства, как компьютеры, планшеты и смартфоны, используемые в вашем доме.

Пример: IP-адреса, генерируемые домашним маршрутизатором для ваших устройств.

### Static

Статический IP-адрес не меняется и создается вручную, а не назначается. Такие адреса обычно стоят дороже, но они более надежны.

_Пример: Они обычно используются для таких важных вещей, как надежные службы геолокации, удаленный доступ, хостинг серверов и т. д._

### Dynamic

Динамический IP-адрес время от времени меняется и не всегда является одним и тем же. Он назначается сервером [Dynamic Host Configuration Protocol (DHCP)](https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol). Динамические IP-адреса - самый распространенный тип адресов интернет-протокола. Они дешевле в развертывании и позволяют нам повторно использовать IP-адреса в сети по мере необходимости.

_Пример: Они чаще всего используются для потребительского оборудования и личного пользования._

# OSI Model

Модель OSI - это логическая и концептуальная модель, определяющая сетевые коммуникации, используемые системами, открытыми для взаимодействия и связи с другими системами. Модель OSI (Open System Interconnection) также определяет логическую сеть и эффективно описывает передачу компьютерных пакетов с помощью протоколов различных уровней.

Модель OSI можно рассматривать как универсальный язык для компьютерных сетей. В ее основе лежит концепция разделения коммуникационной системы на семь абстрактных уровней, каждый из которых накладывается на предыдущий.

## Why does the OSI model matter?

Модель Open System Interconnection (OSI) определила общую терминологию, используемую в обсуждениях и документации по сетевым технологиям. Это позволяет нам разобрать очень сложный коммуникационный процесс на части и оценить его компоненты.

Хотя эта модель не реализована напрямую в наиболее распространенных сегодня сетях TCP/IP, она все равно может помочь нам сделать гораздо больше, например:

- Облегчить поиск и устранение неисправностей и помочь выявить угрозы во всем стеке.
- Поощрять производителей оборудования к созданию сетевых продуктов, которые могут взаимодействовать друг с другом по сети.
- Очень важно для развития мышления, ориентированного на безопасность.
- Разделение сложной функции на более простые компоненты.
  
## Layers

Семь уровней абстракции модели OSI можно определить следующим образом, сверху вниз:

![osi-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/osi-model/osi-model.png)

### Application

Это единственный уровень, который напрямую взаимодействует с данными, поступающими от пользователя. Программные приложения, такие как веб-браузеры и почтовые клиенты, полагаются на прикладной уровень для инициирования взаимодействия. Однако следует уточнить, что клиентские приложения не являются частью прикладного уровня, скорее, прикладной уровень отвечает за протоколы и манипуляции с данными, на которые опирается программное обеспечение для представления значимых данных пользователю. К протоколам прикладного уровня относятся такие как HTTP иSMTP.

### Presentation

Презентационный уровень также называют уровнем трансляции. Данные с прикладного уровня извлекаются здесь и манипулируются в соответствии с требуемым форматом для передачи по сети. Функции презентационного уровня - перевод, шифрование/дешифрование и сжатие.

### Session

Это уровень, отвечающий за открытие и закрытие связи между двумя устройствами. Время между открытием и закрытием связи называется сессией. Сессионный уровень обеспечивает, чтобы сессия оставалась открытой достаточно долго, чтобы передать все данные, которыми обмениваются, а затем быстро закрывает сессию, чтобы не тратить ресурсы впустую. Сессионный уровень также синхронизирует передачу данных с контрольными точками.

### Transport

Транспортный уровень (также известный как уровень 4) отвечает за сквозную передачу данных между двумя устройствами. Он включает в себя получение данных от сеансового уровня и разбиение их на фрагменты, называемые сегментами, перед отправкой на сетевой уровень (уровень 3). Он также отвечает за сборку сегментов на принимающем устройстве в данные, которые может использовать сеансовый уровень.

### Network

Сетевой уровень отвечает за передачу данных между двумя различными сетями. Сетевой уровень разбивает сегменты транспортного уровня на более мелкие единицы, называемые пакетами, на устройстве отправителя и собирает эти пакеты на устройстве получателя. Сетевой уровень также находит наилучший физический путь для передачи данных к месту назначения, что называется маршрутизацией. Если два взаимодействующих устройства находятся в одной сети, то сетевой уровень не нужен.

### Data Link

Канальный уровень очень похож на сетевой уровень, за исключением того, что канальный уровень облегчает передачу данных между двумя устройствами в одной сети. Канальный уровень получает пакеты с сетевого уровня и разбивает их на более мелкие фрагменты, называемые кадрами.

### Physical

Этот уровень включает в себя физическое оборудование, участвующее в передаче данных, например кабели и коммутаторы. Именно на этом уровне данные преобразуются в битовый поток, представляющий собой последовательность 1 и 0. Физический уровень обоих устройств также должен согласовать сигнальные соглашения, чтобы 1 и 0 можно было отличить на обоих устройствах.

# TCP and UDP

## TCP

Протокол управления передачей (TCP) ориентирован на соединение, то есть после установления соединения данные могут передаваться в обоих направлениях. TCP имеет встроенные системы проверки на наличие ошибок и гарантирует, что данные будут доставлены в том порядке, в котором они были отправлены, что делает его идеальным протоколом для передачи такой информации, как неподвижные изображения, файлы данных и веб-страницы.
![tcp](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/tcp.png)

Но хотя TCP инстинктивно надежен, его механизмы обратной связи также приводят к большим накладным расходам, что приводит к большему использованию доступной полосы пропускания в сети.

## UDP

User Datagram Protocol (UDP) - это более простой интернет-протокол без соединений, в котором не требуются службы проверки и восстановления ошибок. В UDP нет накладных расходов на открытие соединения, поддержание соединения или его прерывание. Данные постоянно отправляются получателю, независимо от того, получены они или нет.

![udp](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/udp.png)

Его предпочитают использовать для связи в реальном времени, например, для широковещательной или многоадресной передачи данных по сети. Мы должны использовать UDP вместо TCP, когда нам нужна наименьшая задержка, а задержка данных хуже, чем их потеря.

## TCP vs UDP

TCP - это протокол, ориентированный на соединение, в то время как UDP - протокол без соединения. Ключевым различием между TCP и UDP является скорость, поскольку TCP сравнительно медленнее UDP. В целом UDP является более быстрым, простым и эффективным протоколом, однако повторная передача потерянных пакетов данных возможна только при использовании TCP.

TCP обеспечивает упорядоченную доставку данных от пользователя к серверу (и наоборот), в то время как UDP не предназначен для сквозной передачи данных и не проверяет готовность получателя.

| Характеристика | TCP | UDP |
| ------------------- | ------------------------------------------- | ---------------------------------- |
Соединение | Требуется установленное соединение | Протокол без соединения | Гарантированная доставка | Может гарантировать доставку.
| Гарантированная доставка | Может гарантировать доставку данных | Не может гарантировать доставку данных |
| Повторная передача | Повторная передача потерянных пакетов возможна | Повторная передача потерянных пакетов невозможна |
| Скорость | Медленнее, чем UDP | Быстрее, чем TCP |
| Широковещание | Не поддерживает широковещание | Поддерживает широковещание |

# Domain Name System (DNS)

Ранее мы узнали об IP-адресах, которые позволяют каждой машине соединяться с другими машинами. Но, как мы знаем, людям удобнее работать с именами, чем с цифрами. Легче запомнить такое имя, как `google.com`, чем что-то вроде `122.250.192.232`.

Это привело нас к системе доменных имен (DNS), которая представляет собой иерархическую и децентрализованную систему именования, используемую для преобразования человекочитаемых доменных имен в IP-адреса.

## How DNS works

![how-dns-works](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/domain-name-system/how-dns-works.png)

Поиск DNS включает в себя следующие восемь шагов:

1. Клиент набирает [example.com](http://example.com) в веб-браузере, запрос отправляется в Интернет и поступает на DNS-резольвер.
2. Затем резолвер рекурсивно запрашивает корневой сервер имен DNS.
3. Корневой сервер отвечает на запрос с адресом домена верхнего уровня (TLD).
4. Затем преобразователь делает запрос к ДВУ `.com`.
5. Сервер ДВУ отвечает IP-адресом сервера имен домена [example.com](http://example.com).
6. Наконец, рекурсивный преобразователь отправляет запрос серверу имен домена.
7. IP-адрес [example.com](http://example.com) возвращается на преобразователь с сервера имен.
8. Затем DNS-резольвер отвечает веб-браузеру IP-адресом домена, запрошенного изначально.

После разрешения IP-адреса клиент должен иметь возможность запрашивать содержимое с разрешенного IP-адреса. Например, разрешенный IP-адрес может вернуть веб-страницу для отображения в браузере.

## Server types

Теперь давайте рассмотрим четыре основные группы серверов, составляющих инфраструктуру DNS.

### DNS Resolver

DNS-резольвер (также известный как рекурсивный DNS-резольвер) - это первая остановка при выполнении DNS-запроса. Рекурсивный резолвер выступает в роли посредника между клиентом и сервером имен DNS. После получения DNS-запроса от веб-клиента рекурсивный преобразователь либо отвечает кэшированными данными, либо отправляет запрос на корневой сервер имен, затем еще один запрос на сервер имен ДВУ, а затем последний запрос на авторитетный сервер имен. После получения ответа от авторитетного сервера имен, содержащего запрашиваемый IP-адрес, рекурсивный преобразователь отправляет ответ клиенту.

### DNS root server

Корневой сервер принимает запрос рекурсивного распознавателя, включающий доменное имя, а корневой сервер имен отвечает на него, направляя рекурсивный распознаватель на сервер имен ДВУ, основанный на расширении этого домена (`.com`, `.net`, `.org` и т. д.). Корневые серверы имен контролируются некоммерческой организацией под названием [Internet Corporation for Assigned Names and Numbers (ICANN)](https://www.icann.org).

Каждому рекурсивному преобразователю известно 13 корневых серверов имен DNS. Обратите внимание, что, хотя существует 13 корневых серверов имен, это не означает, что в системе корневых серверов имен только 13 машин. Существует 13 типов корневых серверов имен, но каждый из них имеет несколько копий по всему миру, которые используют [Anycast routing](https://en.wikipedia.org/wiki/Anycast) для обеспечения быстрых ответов.

### TLD nameserver

Сервер имен TLD хранит информацию обо всех доменных именах, имеющих общее расширение домена, например `.com`, `.net` или то, что идет после последней точки в URL.

Управлением серверами имен TLD занимается [Internet Assigned Numbers Authority (IANA)](https://www.iana.org), который является подразделением [ICANN](https://www.icann.org). IANA разделяет серверы TLD на две основные группы:

- **Общие домены верхнего уровня**: Это домены типа `.com`, `.org`, `.net`, `.edu` и `.gov`.
- **Домены верхнего уровня с кодом страны**: К ним относятся любые домены, относящиеся к определенной стране или государству. Примеры: `.uk`, `.us`, `.ru` и `.jp`.

### Authoritative DNS server

Авторитативный сервер имен обычно является последним шагом в поиске IP-адреса. Авторитативный сервер имен содержит информацию, специфичную для обслуживаемого им доменного имени (например, [google.com](http://google.com)), и он может предоставить рекурсивному резолверу IP-адрес этого сервера, найденный в записи A DNS, или, если домен имеет запись CNAME (псевдоним), он предоставит рекурсивному резолверу псевдоним домена, и тогда рекурсивному резолверу придется выполнить новый поиск DNS, чтобы получить запись от авторитетного сервера имен (часто это запись A, содержащая IP-адрес). Если он не может найти домен, возвращается сообщение NXDOMAIN.

## Query Types

В системе DNS существует три типа запросов:

### Recursive

При рекурсивном запросе DNS-клиент требует, чтобы DNS-сервер (обычно рекурсивный преобразователь DNS) ответил клиенту либо запрошенной записью ресурса, либо сообщением об ошибке, если преобразователь не может найти эту запись.

### Iterative

При итеративном запросе DNS-клиент указывает имя хоста, а DNS-резольвер возвращает наилучший ответ. Если DNS-резольвер имеет соответствующие записи DNS в своем кэше, он возвращает их. Если нет, он направляет клиента DNS к корневому серверу или другому авторитетному серверу имен, который находится ближе всего к требуемой зоне DNS. Затем DNS-клиент должен повторить запрос непосредственно к DNS-серверу, на который он был направлен.

### Non-recursive

Нерекурсивный запрос - это запрос, в котором DNS-резольвер уже знает ответ. Он либо сразу возвращает запись DNS, поскольку уже хранит ее в локальном кэше, либо запрашивает сервер имен DNS, который является авторитетным для этой записи, то есть у него точно есть правильный IP для этого имени хоста. В обоих случаях нет необходимости в дополнительных раундах запросов (как в рекурсивных или итеративных запросах). Вместо этого клиенту сразу же возвращается ответ.

## Record Types

DNS-записи (они же файлы зон) - это инструкции, которые хранятся на авторитетных DNS-серверах и предоставляют информацию о домене, в том числе о том, какой IP-адрес связан с этим доменом и как обрабатывать запросы для этого домена.

Эти записи состоят из серии текстовых файлов, записанных в так называемом _синтаксисе DNS_. Синтаксис DNS - это просто строка символов, используемых в качестве команд, которые указывают DNS-серверу, что делать. Все записи DNS также имеют значение _"TTL"_, что означает "время жизни" и указывает, как часто DNS-сервер будет обновлять эту запись.

Существует больше типов записей, но сейчас мы рассмотрим некоторые из наиболее часто используемых:

- **A (Address record)**: Это запись, содержащая IP-адрес домена.
- **AAA (запись адреса IP версии 6)**: Запись, содержащая IPv6-адрес домена (в отличие от A-записей, в которых хранится IPv4-адрес).
- **CNAME (запись канонического имени)**: Перенаправляет один домен или поддомен на другой домен, НЕ предоставляет IP-адрес.
- **MX (запись почтового обменника)**: Направляет почту на почтовый сервер.
- **TXT (текстовая запись)**: Эта запись позволяет администратору хранить в ней текстовые заметки. Эти записи часто используются для обеспечения безопасности электронной почты.
- **NS (записи сервера имен)**: Хранит сервер имен для записи DNS.
- **SOA (Start of Authority)**: Хранит информацию администратора о домене.
- **SRV (Service Location record)**: Определяет порт для определенных служб.
- **PTR (Reverse-lookup Pointer record)**: Указывает доменное имя при обратном поиске.
- **CERT (запись сертификата)**: Хранит сертификаты открытых ключей.

## Subdomains

Поддомен - это дополнительная часть основного доменного имени. Обычно он используется для логического разделения сайта на разделы. Мы можем создать несколько поддоменов или дочерних доменов на основном домене.

Например, `blog.example.com`, где `blog` - это поддомен, `example` - основной домен, а `.com` - домен верхнего уровня (TLD). Аналогичными примерами могут быть `support.example.com` или `careers.example.com`.

## DNS Zones

Зона DNS - это отдельная часть пространства доменных имен, которая делегируется юридическому лицу, например человеку, организации или компании, которые отвечают за поддержание зоны DNS. Зона DNS - это также административная функция, позволяющая осуществлять детальный контроль над компонентами DNS, такими как авторитативные серверы имен.

## DNS Caching

Кэш DNS (иногда называемый кэшем DNS-резольвера) - это временная база данных, поддерживаемая операционной системой компьютера, которая содержит записи обо всех последних посещениях и попытках посещения веб-сайтов и других интернет-доменов. Другими словами, кэш DNS - это просто память последних обращений к DNS, к которой наш компьютер может быстро обратиться, когда пытается понять, как загрузить веб-сайт.

Система доменных имен устанавливает время жизни (TTL) для каждой записи DNS. TTL определяет количество секунд, в течение которых запись может кэшироваться клиентом или сервером DNS. Когда запись сохраняется в кэше, вместе с ней сохраняется и значение TTL. Сервер продолжает обновлять TTL записи, хранящейся в кэше, отсчитывая каждую секунду. Когда оно достигнет нуля, запись будет удалена или очищена из кэша. В этот момент, если поступает запрос на эту запись, DNS-сервер должен начать процесс разрешения.

## Reverse DNS

Обратный поиск DNS - это запрос DNS на получение доменного имени, связанного с заданным IP-адресом. Это противоположно более распространенному прямому DNS-поиску, при котором система DNS запрашивается для возврата IP-адреса. В процессе обратного преобразования IP-адреса используются записи PTR. Если у сервера нет PTR-записи, он не сможет выполнить обратный поиск.

Обратный поиск обычно используется серверами электронной почты. Серверы электронной почты проверяют, пришло ли сообщение электронной почты с действительного сервера, прежде чем принять его в свою сеть. Многие серверы электронной почты будут отклонять сообщения с серверов, не поддерживающих обратный поиск, или с серверов, которые с большой вероятностью не являются легитимными.

_Примечание: обратный поиск DNS не является общепринятым, поскольку он не является критическим для нормального функционирования Интернета._

## Examples

Вот некоторые широко используемые управляемые решения для DNS:

- [Route53](https://aws.amazon.com/route53)
- [Cloudflare DNS](https://www.cloudflare.com/dns)
- [Google Cloud DNS](https://cloud.google.com/dns)
- [Azure DNS](https://azure.microsoft.com/en-in/services/dns)
- [NS1](https://ns1.com/products/managed-dns)

# Load Balancing

Балансировка нагрузки позволяет распределять входящий сетевой трафик между несколькими ресурсами, обеспечивая высокую доступность и надежность за счет отправки запросов только на те ресурсы, которые находятся в режиме онлайн. Это позволяет добавлять или убирать ресурсы в зависимости от потребностей.

![Балансировка нагрузки](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer.png)

Для дополнительной масштабируемости и избыточности мы можем попытаться сбалансировать нагрузку на каждом уровне нашей системы:

![load-balancing-layers](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer-layers.png)

## But why?

Современные веб-сайты с высокой посещаемостью должны обслуживать сотни тысяч, а то и миллионы одновременных запросов от пользователей или клиентов. Чтобы экономически эффективно масштабироваться для удовлетворения таких больших объемов, современные вычислительные технологии обычно требуют добавления дополнительных серверов.

Балансировщик нагрузки может находиться перед серверами и направлять запросы клиентов между всеми серверами, способными выполнить эти запросы, таким образом, чтобы максимально увеличить скорость и загрузку мощностей. Это гарантирует, что ни один сервер не будет перегружен, что может привести к снижению производительности. Если один сервер выходит из строя, балансировщик нагрузки перенаправляет трафик на оставшиеся серверы. Когда в группу серверов добавляется новый сервер, балансировщик нагрузки автоматически начинает отправлять на него запросы.

## Workload distribution

Это основной функционал, предоставляемый балансировщиком нагрузки, который имеет несколько общих вариаций:

- **На основе хоста**: Распределяет запросы на основе запрашиваемого имени хоста.
- **На основе пути**: Использование всего URL для распределения запросов, а не только имени хоста.
- **На основе содержимого**: Проверяет содержимое сообщения в запросе. Это позволяет распределять запросы на основе содержимого, например значения параметра.

## Layers

Как правило, балансировщики нагрузки работают на одном из двух уровней:

### Сетевой уровень

Это балансировщик нагрузки, работающий на транспортном уровне сети, также известном как уровень 4. Он выполняет маршрутизацию на основе сетевой информации, такой как IP-адреса, и не может выполнять маршрутизацию на основе контента. Часто это специализированные аппаратные устройства, способные работать на высокой скорости.

### Прикладной уровень

Это балансировщик нагрузки, работающий на прикладном уровне, также известном как уровень 7. Балансировщики нагрузки могут читать запросы целиком и выполнять маршрутизацию на основе содержимого. Это позволяет управлять нагрузкой на основе полного понимания трафика.

## Типы

Давайте рассмотрим различные типы балансировщиков нагрузки:

### Программные

Программные балансировщики нагрузки обычно проще развернуть, чем аппаратные. Они также более экономичны и гибки, и их используют вместе со средами разработки программного обеспечения. Программный подход дает нам возможность гибко настраивать балансировщик нагрузки в соответствии с конкретными потребностями нашей среды. Повышение гибкости может быть связано с необходимостью выполнять больше работы по настройке балансировщика нагрузки. По сравнению с аппаратными версиями, которые предлагают более закрытый подход, программные балансировщики дают нам больше свободы для внесения изменений и обновлений.

Программные балансировщики нагрузки широко распространены и предлагаются либо в виде устанавливаемых решений, требующих настройки и управления, либо в виде управляемых облачных сервисов.

### Аппаратные

Как следует из названия, аппаратный балансировщик нагрузки опирается на физическое, локальное оборудование для распределения приложений и сетевого трафика. Эти устройства могут обрабатывать большой объем трафика, но часто имеют высокую цену и довольно ограничены в гибкости.

Аппаратные балансировщики нагрузки имеют собственное встроенное программное обеспечение, которое требует обслуживания и обновления по мере выхода новых версий и исправлений безопасности.

Балансировка нагрузки DNS - это практика настройки домена в системе доменных имен (DNS) таким образом, чтобы клиентские запросы к домену распределялись между группой серверных машин.

К сожалению, балансировка нагрузки DNS имеет присущие ей проблемы, ограничивающие ее надежность и эффективность. Прежде всего, DNS не проверяет серверы и сети на наличие сбоев или ошибок. Он всегда возвращает один и тот же набор IP-адресов для домена, даже если серверы не работают или недоступны.

## Алгоритмы распределения запросов

Теперь давайте обсудим часто используемые алгоритмы маршрутизации:

- **Round-robin**: Запросы распределяются между серверами приложений по очереди.
- **Weighted Round-robin**: Развивает простую технику Round-robin для учета различий в характеристиках серверов, таких как производительность вычислений и обработка трафика, с помощью весов, которые могут быть назначены администратором через DNS-записи.
- **Наименьшие соединения**: Новый запрос отправляется на сервер с наименьшим количеством текущих соединений с клиентами. Относительная вычислительная мощность каждого сервера учитывается при определении сервера с наименьшим количеством соединений.
- **Наименьшее время отклика**: Отправляет запросы на сервер, выбранный по формуле, сочетающей самое быстрое время отклика и наименьшее количество активных соединений.
- **Наименьшая пропускная способность**: Этот метод измеряет трафик в мегабитах в секунду (Мбит/с), отправляя запросы клиентов на сервер с наименьшим трафиком в Мбит/с.
- **Хеширование**: Распределяет запросы на основе определенного нами ключа, например IP-адреса клиента или URL-адреса запроса.

## Преимущества

Балансировка нагрузки также играет ключевую роль в предотвращении простоев. Среди других преимуществ балансировки нагрузки можно выделить следующие:

- Масштабируемость
- Избыточность
- Гибкость
- Эффективность

## Избыточные балансировщики нагрузки

Как вы уже, наверное, догадались, сам балансировщик нагрузки может быть единственной точкой отказа. Чтобы преодолеть это, можно использовать второй или `N` количество балансировщиков нагрузки в режиме кластера.

И если произойдет сбой и _активный_ балансировщик нагрузки выйдет из строя, другой _резервный_ балансировщик нагрузки сможет взять на себя его функции, что сделает нашу систему более отказоустойчивой.

![redundant-load-balancing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/redundant-load-balancer.png)

## Особенности

Вот некоторые часто востребованные функции балансировщиков нагрузки:

- **Автомасштабирование**: Запуск и отключение ресурсов в зависимости от спроса.
- **Липкие сессии**: Возможность назначить одного и того же пользователя или устройство на один и тот же ресурс, чтобы сохранить состояние сессии на ресурсе.
- **Проверка здоровья**: Возможность определить, что ресурс не работает или работает плохо, чтобы удалить его из пула балансировки нагрузки.
- **Персистентные соединения**: Позволяет серверу открывать постоянное соединение с клиентом, например WebSocket.
- **Шифрование**: Работа с зашифрованными соединениями, такими как TLS и SSL.
- **Сертификаты**: Представление сертификатов клиенту и проверка подлинности клиентских сертификатов.
- **Сжатие**: Сжатие ответов.
- **Кэширование**: Балансировщик нагрузки прикладного уровня может предлагать возможность кэширования ответов.
- **Запись в журнал**: Ведение журнала метаданных запросов и ответов может служить важным аудиторским следом или источником аналитических данных.
- **Отслеживание запросов**: Присвоение каждому запросу уникального идентификатора для целей ведения журнала, мониторинга и устранения неполадок.
- **Переадресация**: Возможность перенаправления входящего запроса на основе таких факторов, как запрашиваемый путь.
- **Фиксированный ответ**: Возвращение статического ответа на запрос, например сообщения об ошибке.
## Examples

Ниже перечислены некоторые решения по балансировке нагрузки, широко используемые в отрасли:

- [Amazon Elastic Load Balancing](https://aws.amazon.com/elasticloadbalancing)
- [Azure Load Balancing](https://azure.microsoft.com/en-in/services/load-balancer)
- [GCP Load Balancing](https://cloud.google.com/load-balancing)
- [DigitalOcean Load Balancer](https://www.digitalocean.com/products/load-balancer)
- [Nginx](https://www.nginx.com)
- [HAProxy](http://www.haproxy.org)

# Кластеризация

В общем случае компьютерный кластер - это группа из двух или более компьютеров, или узлов, которые работают параллельно для достижения общей цели. Это позволяет распределять между узлами кластера рабочие нагрузки, состоящие из большого количества отдельных, распараллеливаемых задач. В результате эти задачи могут использовать совокупную память и вычислительную мощность каждого компьютера для повышения общей производительности.

Для создания компьютерного кластера отдельные узлы должны быть подключены к сети, чтобы обеспечить межузловое взаимодействие. Затем с помощью программного обеспечения можно объединить узлы вместе и сформировать кластер. Он может иметь общее устройство хранения данных и/или локальное хранилище на каждом узле.

![cluster](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/cluster.png)

Как правило, хотя бы один узел назначается лидером и выступает в качестве точки входа в кластер. Ведущий узел может отвечать за делегирование входящей работы другим узлам и, при необходимости, агрегировать результаты и возвращать ответ пользователю.

В идеале кластер функционирует как единая система. Пользователь, обращающийся к кластеру, не должен знать, является ли система кластером или отдельной машиной. Кроме того, кластер должен быть спроектирован таким образом, чтобы минимизировать задержки и предотвратить узкие места в коммуникации между узлами.


## Типы

Компьютерные кластеры можно разделить на три типа:

- Высокая доступность или отказоустойчивость
- Балансировка нагрузки
- Высокопроизводительные вычисления

## Конфигурации

Две наиболее часто используемые конфигурации кластеризации высокой доступности (HA) - активно-активная и активно-пассивная.

### Active-Active

![active-active](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-active.png)

Активно-активный кластер обычно состоит как минимум из двух узлов, на которых одновременно активно работает один и тот же вид сервиса. Основная цель активно-активного кластера - добиться балансировки нагрузки. Балансировщик нагрузки распределяет рабочие нагрузки между всеми узлами, чтобы предотвратить перегрузку какого-либо одного узла. Поскольку для обслуживания доступно больше узлов, повышается пропускная способность и время отклика.

### Active-Passive

![active-passive](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-passive.png)

Как и конфигурация активно-пассивного кластера, активно-пассивный кластер также состоит как минимум из двух узлов. Однако, как следует из названия _активно-пассивный_, не все узлы будут активными. Например, в случае двух узлов, если первый узел уже активен, то второй узел должен быть пассивным или находиться в режиме ожидания.

## Преимущества

Ниже перечислены четыре ключевых преимущества кластерных вычислений:

- Высокая доступность
- Масштабируемость
- Производительность
- Экономичность

## Балансировка нагрузки и кластеризация

Балансировка нагрузки имеет некоторые общие черты с кластеризацией, но это разные процессы. Кластеризация обеспечивает избыточность и повышает производительность и доступность. Серверы в кластере знают друг о друге и работают вместе для достижения общей цели. При балансировке нагрузки серверы не знают друг о друге. Вместо этого они реагируют на запросы, которые получают от балансировщика нагрузки.

Мы можем использовать балансировку нагрузки в сочетании с кластеризацией, но она также применима в случаях с независимыми серверами, объединенными общей целью, например, для запуска веб-сайта, бизнес-приложения, веб-службы или другого ИТ-ресурса.

## Проблемы

Наиболее очевидной проблемой кластеризации является повышенная сложность установки и обслуживания. Операционная система, приложение и его зависимости должны быть установлены и обновлены на каждом узле.

Это становится еще сложнее, если узлы в кластере неоднородны. Также необходимо тщательно следить за использованием ресурсов на каждом узле и агрегировать журналы, чтобы убедиться в правильности поведения программного обеспечения.

Кроме того, усложняется управление хранением данных: общее устройство хранения должно предотвращать перезапись узлов друг другом, а распределенные хранилища данных должны синхронизироваться.
## Примеры

Кластеризация широко используется в промышленности, и зачастую многие технологии предлагают тот или иной режим кластеризации. Например:

- Контейнеры ([Kubernetes](https://kubernetes.io), [Amazon ECS](https://aws.amazon.com/ecs)).
- Базы данных ([Cassandra](https://cassandra.apache.org/_/index.html), [MongoDB](https://www.mongodb.com))
- Кэш ([Redis](https://redis.io/docs/manual/scaling))

# Кэширование

_ "В компьютерных науках есть только две трудные вещи: инвалидация кэша и именование вещей". - Фил Карлтон_

![кэширование](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/caching.png)

Основная задача кэша - повысить производительность поиска данных за счет снижения необходимости обращаться к более медленному слою хранения. В отличие от баз данных, в которых данные обычно полные и долговременные, кэш обычно хранит подмножество данных на временной основе.

Кэши используют принцип _"недавно запрошенные данные, скорее всего, будут запрошены снова"._

## Кэширование и память

Как и память компьютера, кэш - это компактная, быстродействующая память, которая хранит данные в виде иерархии уровней, начиная с первого и последовательно переходя от него. Они обозначаются как L1, L2, L3 и так далее. Кэш также записывается по запросу, например, когда произошло обновление и новое содержимое необходимо сохранить в кэше, заменив им старое.

Независимо от того, читается или записывается кэш, это происходит по одному блоку за раз. Каждый блок также имеет тег, который содержит место, где данные были сохранены в кэше. Когда данные запрашиваются из кэша, происходит поиск по тегам, чтобы найти нужное содержимое в памяти первого уровня (L1). Если нужные данные не найдены, поиск ведется еще в L2.

Если данные не найдены и там, поиск продолжается в L3, затем в L4 и так далее, пока они не будут найдены, после чего они считываются и загружаются. Если данные вообще не найдены в кэше, то они записываются в него для быстрого извлечения в следующий раз.

## Попадание в кэш и пропуск кэша

### Попадание в кэш

Попадание в кэш описывает ситуацию, когда содержимое успешно обслуживается из кэша. Метки быстро перебираются в памяти, и когда данные найдены и прочитаны, это считается попаданием в кэш.

**Холодный, теплый и горячий кэш**.

Попадание в кэш также можно назвать холодным, теплым или горячим. В каждом из этих случаев описывается скорость считывания данных.

Горячий кэш - это случай, когда данные были считаны из памяти с максимально возможной скоростью. Это происходит, когда данные извлекаются из L1.

Холодный кэш - это чтение данных с _самой_ медленной возможной скоростью, однако оно все равно успешно, поэтому оно все равно считается попаданием в кэш. Данные просто находятся ниже в иерархии памяти, например в L3 или ниже.

Теплый кэш используется для описания данных, которые находятся в L2 или L3. Он не так быстр, как горячий кэш, но все же быстрее, чем холодный. Как правило, называя кэш теплым, вы хотите сказать, что он медленнее и ближе к холодному кэшу, чем к горячему.

### Пропуск кэша

Под пропуском кэша понимается случай, когда в памяти выполняется поиск, но данные не найдены. Когда это происходит, содержимое передается и записывается в кэш.

## Инвалидизация кэша

Признание кэша недействительным - это процесс, в ходе которого компьютерная система объявляет записи в кэше недействительными и удаляет или заменяет их. Если данные были изменены, они должны быть аннулированы в кэше, если нет, это может привести к непоследовательной работе приложения. Существует три вида систем кэширования:

###  Запись через кэш (Write-through cache)

![write-through-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-through-cache.png)

Данные записываются в кэш и соответствующую базу данных одновременно.

**Плюсы**: Быстрый поиск, полная согласованность данных между кэшем и хранилищем.

**Минусы**:Более высокая задержка при операциях записи.

### Кэш  с обходом записи (Write-around cache)

![write-around-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-around-cache.png)

Когда запись идет напрямую в базу данных или постоянное хранилище, минуя кэш.

**Плюсы**:Это может уменьшить задержку.

**Минусы**:Увеличивает количество пропусков кэша, поскольку в случае пропусков кэша системе приходится считывать информацию из базы данных. В результате это может привести к увеличению задержки чтения в случае приложений, которые быстро записывают и перечитывают информацию. Чтение происходит из более медленного внутреннего хранилища, что приводит к увеличению задержки.

### Кэш с обратной записью (Write-back cache)

![write-back-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-back-cache.png)

В этом случае запись выполняется только в слой кэширования, и запись подтверждается, как только запись в кэш завершается. Затем кэш асинхронно синхронизирует эту запись с базой данных.

**Плюсы**: Это приведет к снижению задержек и высокой пропускной способности приложений, интенсивно работающих с записью.

**Минусы**: Существует риск потери данных в случае сбоя слоя кэширования. Мы можем улучшить эту ситуацию, имея более одной реплики, подтверждающей запись в кэш.

## Политики вытеснения

Ниже перечислены наиболее распространенные политики вытеснения кэша:

- **First In First Out (FIFO)**: Кэш вытесняет первый блок, к которому обратились первым, не обращая внимания на то, как часто или сколько раз к нему обращались до этого.
- **Last In First Out (LIFO)**: Кэш вытесняет блок, доступ к которому был получен последним, без учета того, как часто или сколько раз к нему обращались до этого.
- **Least Recently Used (LRU)**: В первую очередь удаляются наименее часто используемые элементы.
- **Most Recently Used (MRU)**: В отличие от LRU, в первую очередь отбрасываются наиболее часто используемые элементы.
- **Least Frequently Used (LFU)**: Подсчитывает, как часто требуется тот или иной элемент. Те, которые используются реже всего, отбрасываются первыми.
- **Random Replacement(RR)**: Случайно выбирает элемент-кандидат и выбрасывает его, чтобы освободить место, когда это необходимо.

## Распределённый кэш

![distributed-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/distributed-cache.png)

Распределенный кэш - это система, объединяющая память с произвольным доступом (RAM) нескольких компьютеров, подключенных к сети, в единое хранилище данных в памяти, используемое в качестве кэша для обеспечения быстрого доступа к данным. В то время как большинство кэшей традиционно находятся в одном физическом сервере или аппаратном компоненте, распределенный кэш может выходить за пределы памяти одного компьютера, объединяя несколько компьютеров.

## Глобальный кэш

![global-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/global-cache.png)

Как следует из названия, у нас будет один общий кэш, который будут использовать все узлы приложения. Если запрашиваемые данные не найдены в глобальном кэше, кэш отвечает за поиск недостающей части данных из базового хранилища данных.

## Примеры использования

Кэширование может иметь множество реальных вариантов использования, например:

- Кэширование баз данных
- Сеть доставки контента (CDN)
- Кэширование системы доменных имен (DNS)
- Кэширование API


**Когда не стоит использовать кэширование?**

Давайте также рассмотрим некоторые сценарии, в которых не следует использовать кэш:

- Кэширование не помогает, если доступ к кэшу занимает столько же времени, сколько и доступ к основному хранилищу данных.
- Кэширование не работает так же хорошо, когда запросы имеют низкую повторяемость (большую случайность), потому что производительность кэша зависит от повторяющихся шаблонов доступа к памяти.
- Кэширование не помогает при частых изменениях данных, так как кэшированная версия выходит из синхронизации, а к первичному хранилищу данных приходится обращаться каждый раз.

_Важно отметить, что кэш не следует использовать в качестве постоянного хранилища данных. Они почти всегда реализуются в энергонезависимой памяти, потому что она быстрее, и поэтому должны рассматриваться как временные._

## Преимущества

Ниже перечислены некоторые преимущества кэширования:

- Повышает производительность
- Сокращение задержки
- Снижение нагрузки на базу данных
- Снижение затрат на сеть
- Повышение пропускной способности при чтении

## Примеры

Вот несколько часто используемых технологий для кэширования:

- [Redis](https://redis.io)
- [Memcached](https://memcached.org)
- [Amazon Elasticache](https://aws.amazon.com/elasticache)
- [Aerospike](https://aerospike.com)

# Сеть доставки контента (CDN)

Сеть доставки контента (CDN) - это географически распределенная группа серверов, которые работают вместе, чтобы обеспечить быструю доставку интернет-контента. Как правило, статические файлы, такие как HTML/CSS/JS, фотографии и видео, обслуживаются из CDN.

![cdn-map](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn-map.png)

## Зачем использовать CDN?

Сеть доставки контента (CDN) повышает доступность и избыточность контента, снижает затраты на пропускную способность и повышает безопасность. Обслуживание контента из CDN может значительно повысить производительность, поскольку пользователи получают контент из близких к ним центров обработки данных, а нашим серверам не приходится обслуживать запросы, которые выполняет CDN.

## Как работает CDN?

![cdn](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn.png)

В CDN оригинальный сервер содержит оригинальные версии контента, в то время как пограничные серверы многочисленны и распределены по различным точкам мира.

Чтобы минимизировать расстояние между посетителями и сервером сайта, CDN хранит кэшированную версию своего контента в нескольких географических точках, известных как граничные точки. В каждой граничной точке расположено несколько кэширующих серверов, отвечающих за доставку контента посетителям в пределах своей близости.

После того как статические активы кэшируются на всех серверах CDN для определенного местоположения, все последующие запросы посетителей сайта на статические активы будут доставляться с этих граничных серверов, а не с исходного, что снижает нагрузку на исходный сервер и улучшает масштабируемость.

Например, когда кто-то из жителей Великобритании запрашивает наш сайт, который может быть размещен в США, он будет обслуживаться с ближайшего граничного сервера, например с граничного сервера в Лондоне. Это гораздо быстрее, чем если бы посетитель делал полный запрос к исходному серверу, что увеличивает задержку.

## Типы

CDN обычно делятся на два типа:

### Push CDNs

Push CDN получают новый контент каждый раз, когда на сервере происходят изменения. Мы берем на себя полную ответственность за предоставление контента, загрузку непосредственно в CDN и переписывание URL-адресов для указания на CDN. Мы можем настроить время истечения срока действия контента и время его обновления. Контент загружается только тогда, когда он новый или измененный, что минимизирует трафик, но максимизирует хранение.

Сайты с небольшим объемом трафика или сайты с нечасто обновляемым контентом хорошо работают с push CDN. Контент размещается в CDN один раз, а не извлекается заново через регулярные промежутки времени.

### Pull CDN

В ситуации с Pull CDN кэш обновляется на основе запроса. Когда клиент отправляет запрос, требующий статические активы из CDN, если у CDN их нет, то она получает только что обновленные активы с исходного сервера и заполняет свой кэш этими новыми активами, а затем отправляет эти новые кэшированные активы пользователю.

В отличие от Push CDN, этот способ требует меньше обслуживания, поскольку обновление кэша на узлах CDN происходит на основе запросов клиента к исходному серверу. Сайты с большим трафиком хорошо работают с pull CDN, так как трафик распределяется более равномерно, а на CDN остается только недавно запрошенный контент.

## Недостатки

Как мы все знаем, за все хорошее приходится платить, поэтому давайте обсудим некоторые недостатки CDN:

- **Дополнительные расходы**: Использование CDN может быть дорогостоящим, особенно для сервисов с высоким трафиком.
- **Ограничения**: Некоторые организации и страны блокируют домены или IP-адреса популярных CDN.
- **Местоположение**: Если большая часть нашей аудитории находится в стране, где у CDN нет серверов, данные на нашем сайте, возможно, будут перемещаться дальше, чем без использования CDN.


## Примеры

Вот несколько широко используемых CDN:

- [Amazon CloudFront](https://aws.amazon.com/cloudfront)
- [Google Cloud CDN](https://cloud.google.com/cdn)
- [Cloudflare CDN](https://www.cloudflare.com/cdn)
- [Fastly](https://www.fastly.com/products/cdn)

# Прокси

Прокси-сервер - это промежуточное оборудование/программное обеспечение, которое находится между клиентом и внутренним сервером. Он получает запросы от клиентов и передает их на исходные серверы. Обычно прокси-серверы используются для фильтрации запросов, регистрации запросов, а иногда и для преобразования запросов (добавление/удаление заголовков, шифрование/дешифрование или сжатие).

## Типы

Существует два типа прокси-серверов:

### Forward Proxy

Прокси-сервер, часто называемый прокси, прокси-сервер или веб-прокси, - это сервер, который находится перед группой клиентских компьютеров. Когда эти компьютеры делают запросы к сайтам и службам в Интернете, прокси-сервер перехватывает эти запросы и затем общается с веб-серверами от имени этих клиентов, как посредник.

![forward-proxy](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/forward-proxy.png)

**Преимущества**

Вот некоторые преимущества прямого прокси-сервера:

- Блокировка доступа к определенному контенту
- Позволяет получить доступ к [гео-ограниченному](https://en.wikipedia.org/wiki/Geo-blocking) контенту
- Обеспечивает анонимность
- Избежать других ограничений на просмотр

Хотя прокси-серверы обеспечивают анонимность, они все равно могут отслеживать нашу личную информацию. Установка и обслуживание прокси-сервера может быть дорогостоящей и требует настройки.

### Reverse Proxy

Обратный прокси-сервер - это сервер, который находится перед одним или несколькими веб-серверами и перехватывает запросы от клиентов. Когда клиенты отправляют запросы на исходный сервер веб-сайта, эти запросы перехватываются обратным прокси-сервером.

Разница между прямым и обратным прокси-сервером тонкая, но важная. Упрощенно можно сказать, что прямой прокси сидит перед клиентом и следит за тем, чтобы ни один сервер-оригинал никогда не общался напрямую с этим клиентом. С другой стороны, обратный прокси сидит перед сервером происхождения и гарантирует, что ни один клиент никогда не будет общаться напрямую с этим сервером.

![reverse-proxy](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/reverse-proxy.png)

Внедрение обратного прокси приводит к увеличению сложности. Один обратный прокси - это единственная точка отказа, настройка нескольких обратных прокси (т. е. обход отказа) еще больше увеличивает сложность.

**Преимущества**

Вот некоторые преимущества использования обратного прокси:

- Повышенная безопасность
- Кэширование
- SSL-шифрование
- Балансировка нагрузки
- Масштабируемость и гибкость

## Балансировщик нагрузки против обратного прокси

Подождите, разве обратный прокси не похож на балансировщик нагрузки? Нет, поскольку балансировщик нагрузки полезен, когда у нас есть несколько серверов. Часто балансировщики нагрузки направляют трафик на набор серверов, выполняющих одну и ту же функцию, в то время как обратные прокси могут быть полезны даже при наличии всего одного веб-сервера или сервера приложений. Обратный прокси также может выступать в роли балансировщика нагрузки, но не наоборот.

## Примеры

Ниже приведены некоторые часто используемые прокси серверы:

- [Nginx](https://www.nginx.com)
- [HAProxy](http://www.haproxy.org)
- [Traefik](https://doc.traefik.io/traefik)
- [Envoy](https://www.envoyproxy.io)

# Availability (Доступность)

Доступность - это время, в течение которого система остается работоспособной для выполнения требуемых функций в определенный период. Это простая мера процента времени, в течение которого система, услуга или машина остается работоспособной в нормальных условиях.

## Девятки доступности

Доступность часто измеряется временем работы (или простоя) в процентах от времени, в течение которого сервис доступен. Обычно она измеряется количеством девяток.

$$
Availability = \frac{Uptime}{(Uptime + Downtime)}
$$

Если доступность составляет 99,00%, говорят, что у него "2 девятки" доступности, а если 99,9%, то "3 девятки", и так далее.

| Доступность (в процентах) | Время простоя (год) | Время простоя (месяц) | Время простоя (неделя) |
| ------------------------ | ------------------ | ----------------- | ------------------ |
| 90% (одна девятка) | 36,53 дня | 72 часа | 16,8 часа |
| 99% (две девятки) | 3,65 дня | 7,20 часа | 1,68 часа |
| 99,9% (три девятки)| 8,77 часов | 43,8 минут | 10,1 минут |
| 99,99% (четыре девятки) | 52,6 минуты | 4,32 минуты | 1,01 минуты |
| 99,999% (пять девяток) | 5,25 минут | 25,9 секунд | 6,05 секунд |
| 99,9999% (шесть девяток) | 31,56 секунды | 2,59 секунды | 604,8 миллисекунды |
| 99,99999% (семь девяток) | 3,15 секунды | 263 миллисекунды | 60,5 миллисекунды |
| 99,999999% (восемь девяток) | 315,6 миллисекунд | 26,3 миллисекунд | 6 миллисекунд |
| 99,9999999% (девять девяток) | 31,6 миллисекунды | 2,6 миллисекунды | 0,6 миллисекунды |

## Последовательная и параллельная доступность

Если сервис состоит из нескольких компонентов, склонных к сбоям, общая доступность сервиса зависит от того, работают ли эти компоненты последовательно или параллельно.

### Последовательная

Общая доступность снижается, если два компонента расположены последовательно.

$$
Availability \space (Total) = Availability \space (Foo) * Availability \space (Bar)
$$

Например, если доступность `Foo` и `Bar` составляет 99,9%, то их общая доступность в последовательности будет равна 99,8%.

### Параллельная

Общая доступность повышается, когда два компонента работают параллельно.

$$
Availability \space (Total) = 1 - (1 - Availability \space (Foo)) * (1 - Availability \space (Bar))
$$

Например, если доступность `Foo` и `Bar` составляет 99,9%, то их общая доступность в параллельном режиме будет равна 99,9999%.

## Доступность в сравнении с надежностью (Availability vs Reliability)

Если система надежна, она доступна. Однако если она доступна, то не обязательно надежна. Другими словами, высокая надежность способствует высокой доступности, но можно добиться высокой доступности даже с ненадежной системой.

## Высокая доступность и отказоустойчивость (High availability vs Fault Tolerance)

Как высокая доступность, так и отказоустойчивость относятся к методам обеспечения высокого уровня работоспособности. Однако достигают они этой цели по-разному.

Отказоустойчивая система не имеет перерывов в обслуживании, но имеет значительно более высокую стоимость, в то время как высокодоступная система имеет минимальные перерывы в обслуживании. Отказоустойчивость требует полного аппаратного резервирования, поскольку в случае отказа основной системы, без потери работоспособности, ее место должна занять другая система.

# Масштабируемость

Масштабируемость - это показатель того, насколько хорошо система реагирует на изменения, добавляя или удаляя ресурсы для удовлетворения текущих потребностей.

![масштабируемость](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/scalability/scalability.png)

Давайте обсудим различные типы масштабирования:

## Вертикальное масштабирование

Вертикальное масштабирование (также известное как увеличение масштаба) расширяет возможности системы за счет увеличения мощности существующей машины. Другими словами, вертикальное масштабирование - это расширение возможностей приложения за счет увеличения мощности оборудования.

### Преимущества

- Простота внедрения
- Легче управлять
- Согласованность данных

### Недостатки

- Риск больших простоев
- Сложнее модернизировать
- Может стать единственной точкой отказа

## Горизонтальное масштабирование

Горизонтальное масштабирование (также известное как масштабирование наружу) позволяет расширить масштаб системы за счет добавления новых машин. Это повышает производительность сервера за счет добавления большего количества экземпляров к существующему пулу серверов, что позволяет распределить нагрузку более равномерно.

### Преимущества

- Увеличенная избыточность
- Повышенная отказоустойчивость
- Гибкость и эффективность
- Легче модернизировать

### Недостатки

- Повышенная сложность
- Несогласованность данных
- Повышенная нагрузка на последующие службы

# Хранилище

Хранилище - это механизм, который позволяет системе хранить данные, временно или постоянно. В контексте проектирования систем эта тема чаще всего обходится стороной, однако важно иметь базовое представление о некоторых распространенных типах методов хранения, которые помогут нам точно настроить наши компоненты хранения. Давайте обсудим некоторые важные концепции хранения данных:

## RAID

RAID (Redundant Array of Independent Disks) - это способ хранения одних и тех же данных на нескольких жестких дисках или твердотельных накопителях (SSD) для защиты данных в случае отказа диска.

Однако существуют различные уровни RAID, и не все они направлены на обеспечение избыточности. Давайте обсудим некоторые часто используемые уровни RAID:

- **RAID 0**: Также известен как чередование, данные равномерно распределяются между всеми дисками массива.
- **RAID 1**: Также известен как зеркалирование, по крайней мере два диска содержат точную копию набора данных. Если один диск выходит из строя, другие продолжают работать.
- **RAID 5**: Чередование с контролем четности. Требуется использование не менее 3 дисков, данные распределяются по нескольким дискам, как в RAID 0, но при этом четность распределяется по дискам.
- **RAID 6**: Чередование с двойной четностью. RAID 6 похож на RAID 5, но данные о четности записываются на два диска.
- **RAID 10**: Комбинирует чередование плюс зеркалирование из RAID 0 и RAID 1. Он обеспечивает безопасность за счет зеркалирования всех данных на вторичных дисках, а также использует чередование на каждом наборе дисков для ускорения передачи данных.

### Сравнение

Давайте сравним все характеристики различных уровней RAID:

| Features | RAID 0 | RAID 1 | RAID 5 | RAID 6 | RAID 10 |
| -------------------- | -------- | -------------------- | -------------------- | --------------------------- | ---------------------------------------- |
Описание | Полосовое копирование | Зеркальное копирование | Полосовое копирование с контролем четности | Полосовое копирование с двойным контролем четности | Полосовое копирование и зеркальное копирование |
| Минимальное количество дисков | 2 | 2 | 3 |  4 | 4 |
Производительность чтения | Высокая | Высокая | Высокая | Высокая | Высокая |
Производительность записи | Высокая | Средняя | Высокая | Высокая | Средняя | 
Стоимость | Низкая | Высокая | Низкая | Низкая |  Высокая |
| Отказоустойчивость | Нет | Отказ одного диска | Отказ одного диска | Отказ двух дисков | До одного отказа диска в каждом подмассиве |
| Использование емкости | 100% | 50% | 67%-94% | 50%-80% | 50% |


## Тома (Volumes)

Том - это фиксированный объем памяти на диске или ленте. Термин "том" часто используется как синоним самого хранилища, однако один диск может содержать более одного тома или том может охватывать более одного диска.

## Файловое хранилище

Файловое хранилище - это решение, позволяющее хранить данные в виде файлов и представлять их конечным пользователям в виде иерархической структуры каталогов. Основное преимущество заключается в предоставлении удобного решения для хранения и извлечения файлов. Чтобы найти файл в файловом хранилище, требуется полный путь к нему. Он экономичен и легко структурируется и обычно находится на жестких дисках, то есть для пользователя и на жестком диске они выглядят одинаково.

Пример: [Amazon EFS](https://aws.amazon.com/efs), [Azure files](https://azure.microsoft.com/en-in/services/storage/files), [Google Cloud Filestore](https://cloud.google.com/filestore) и т. д.

## Блочное хранение

При блочном хранении данные делятся на блоки (чанки) и хранятся как отдельные фрагменты. Каждому блоку данных присваивается уникальный идентификатор, что позволяет системе хранения размещать небольшие фрагменты данных там, где это удобнее всего.

Блочное хранение также отделяет данные от пользовательской среды, позволяя распределять их по нескольким средам. Это создает несколько путей к данным и позволяет пользователю быстро получить их. Когда пользователь или приложение запрашивает данные из блочной системы хранения, базовая система хранения повторно собирает блоки данных и представляет их пользователю или приложению.

Пример: [Amazon EBS](https://aws.amazon.com/ebs).

## Объектное хранилище

Объектное хранилище, которое также известно как объектно-ориентированное хранилище, разбивает файлы данных на части, называемые объектами. Затем эти объекты хранятся в едином хранилище, которое может быть распределено по нескольким сетевым системам.

Пример: [Amazon S3](https://aws.amazon.com/s3), [Azure Blob Storage](https://azure.microsoft.com/en-in/services/storage/blobs), [Google Cloud Storage](https://cloud.google.com/storage) и т. д.

## NAS

NAS (Network Attached Storage) - это устройство хранения данных, подключенное к сети, которое позволяет хранить и извлекать данные из центрального хранилища для авторизованных пользователей сети. Устройства NAS являются гибкими, то есть по мере необходимости мы можем добавлять к ним дополнительные хранилища. Это быстрее, дешевле и обеспечивает все преимущества публичного облака на месте, предоставляя нам полный контроль.

## HDFS

Распределенная файловая система Hadoop (HDFS) - это распределенная файловая система, разработанная для работы на аппаратном обеспечении. HDFS обладает высокой отказоустойчивостью и предназначена для развертывания на недорогом оборудовании. HDFS обеспечивает высокую пропускную способность доступа к данным приложений и подходит для приложений с большими массивами данных. Она имеет много общего с существующими распределенными файловыми системами.

HDFS предназначена для надежного хранения очень больших файлов на машинах в большом кластере. Каждый файл хранится в виде последовательности блоков, причем все блоки в файле, кроме последнего, имеют одинаковый размер. Блоки файла реплицируются для обеспечения отказоустойчивости.

# Базы данных и СУБД

## Что такое база данных?

База данных - это организованная коллекция структурированной информации, или данных, обычно хранящихся в электронном виде в компьютерной системе. База данных обычно управляется системой управления базами данных (СУБД). Вместе данные и СУБД, а также связанные с ними приложения называются системой баз данных, часто сокращаемой до просто базы данных.

## Что такое СУБД?

Для работы с базой данных обычно требуется комплексное программное обеспечение, известное как система управления базами данных (СУБД). СУБД служит интерфейсом между базой данных и ее конечными пользователями или программами, позволяя пользователям получать, обновлять и управлять организацией и оптимизацией информации. СУБД также облегчает надзор и контроль над базами данных, позволяя выполнять различные административные операции, такие как мониторинг производительности, настройка, резервное копирование и восстановление.

## Компоненты

Вот некоторые общие компоненты, встречающиеся в различных базах данных:

### Схема

Роль схемы заключается в определении формы структуры данных и указании того, какие типы данных могут находиться в ней. Схемы могут строго соблюдаться во всей базе данных, слабо соблюдаться в части базы данных, или их может не быть вовсе.

### Таблица

Каждая таблица содержит различные столбцы, как в электронных таблицах. В таблице может быть как всего два столбца, так и до сотни и более столбцов, в зависимости от типа информации, помещаемой в таблицу.

### Столбец

Столбец содержит набор значений данных определенного типа, по одному значению для каждой строки базы данных. Столбец может содержать текстовые значения, числа, перечисления, временные метки и т. д.

### Строка

Данные в таблице записываются в строках. В таблице могут быть тысячи или миллионы строк, содержащих определенную информацию.

## Типы

![database-types](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/databases-and-dbms/database-types.png)

Ниже приведены различные типы баз данных:

- **[SQL](https://karanpratapsingh.com/courses/system-design/sql-databases)**
- **[NoSQL](https://karanpratapsingh.com/courses/system-design/nosql-databases)**
  - Документоориентированные
  - Ключ-значение
  - Графовые
  - Временная серия
  - Wide-column
  - Multy-model

Базы данных SQL и NoSQL - это обширные темы, и они будут рассмотрены отдельно в разделах [Базы данных SQL](https://karanpratapsingh.com/courses/system-design/sql-databases) и [Базы данных NoSQL](https://karanpratapsingh.com/courses/system-design/nosql-databases). Узнайте, как они сравниваются друг с другом в [SQL vs NoSQL databases](https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases).

## Проблемы

Некоторые общие проблемы, возникающие при работе с базами данных в масштабе:

- **Принятие значительного увеличения объема данных**: Взрыв данных, поступающих от датчиков, подключенных машин и десятков других источников.
- **Обеспечение безопасности данных**: В наши дни утечки данных происходят повсеместно, и сейчас как никогда важно обеспечить безопасность данных, но в то же время их легкий доступ для пользователей.
- **Соответствие требованиям**: Компаниям необходим доступ к данным в режиме реального времени, чтобы своевременно принимать решения и использовать новые возможности.
- **Управление и поддержка базы данных и инфраструктуры**: По мере усложнения баз данных и роста объемов данных компании сталкиваются с необходимостью нанимать дополнительных специалистов для управления базами данных.
- **Устранение ограничений на масштабируемость**: Чтобы выжить, бизнес должен расти, а вместе с ним должно расти и управление данными. Но очень сложно предсказать, сколько мощностей потребуется компании, особенно в случае с локальными базами данных.
- **Обеспечение резидентности данных, суверенитета данных или требований к латентности**: В некоторых организациях есть сценарии использования, для которых лучше использовать локальные базы данных. В таких случаях идеальным вариантом являются инженерные системы, предварительно настроенные и оптимизированные для работы базы данных.

# Базы данных SQL

База данных SQL (или реляционная) - это набор элементов данных с заранее определенными связями между ними. Эти элементы организованы в виде набора таблиц со столбцами и строками. Таблицы используются для хранения информации об объектах, которые должны быть представлены в базе данных. Каждый столбец таблицы содержит определенный тип данных, а поле хранит фактическое значение атрибута. Строки таблицы представляют собой набор связанных значений одного объекта или сущности.

Каждая строка таблицы может быть помечена уникальным идентификатором, называемым первичным ключом, а строки нескольких таблиц могут быть связаны между собой с помощью внешних ключей. К этим данным можно получить доступ множеством различных способов, не перестраивая сами таблицы базы данных. Базы данных SQL обычно следуют [модели согласованности ACID](https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#acid).

## Материализованные представления

Материализованное представление - это предварительно вычисленный набор данных, полученный из спецификации запроса и сохраненный для последующего использования. Поскольку данные предварительно вычислены, запрос к материализованному представлению выполняется быстрее, чем запрос к базовой таблице представления. Эта разница в производительности может быть значительной, если запрос выполняется часто или является достаточно сложным.

Кроме того, это позволяет выполнять подмножество данных и повышает производительность сложных запросов, выполняемых на больших наборах данных, что снижает нагрузку на сеть. Существуют и другие варианты использования материализованных представлений, но в основном они применяются для повышения производительности и репликации.

## Проблема N+1 запроса

Проблема N+1 запроса возникает, когда уровень доступа к данным выполняет N дополнительных SQL-запросов для получения тех же данных, которые могли быть получены при выполнении основного SQL-запроса. Чем больше значение N, тем больше запросов будет выполнено, тем больше влияние на производительность.

Это часто встречается в GraphQL и ORM (Object-Relational Mapping) инструментах и может быть решено путем оптимизации SQL-запроса или использования dataloader, который группирует последовательные запросы и делает один запрос данных под капотом.

## Преимущества

Давайте рассмотрим некоторые преимущества использования реляционных баз данных:

- Простота и точность
- Доступность
- согласованность данных
- Гибкость

## Недостатки

Ниже перечислены недостатки реляционных баз данных:

- Дорогое обслуживание
- Сложная эволюция схемы
- Проблемы с производительностью (объединение, денормализация и т.д.)
- Сложность масштабирования из-за плохой горизонтальной масштабируемости

## Примеры

Вот некоторые широко используемые реляционные базы данных:

- [PostgreSQL](https://www.postgresql.org)
- [MySQL](https://www.mysql.com)
- [MariaDB](https://mariadb.org)
- [Amazon Aurora](https://aws.amazon.com/rds/aurora)

# Базы данных NoSQL

NoSQL - это широкая категория, в которую входят любые базы данных, не использующие SQL в качестве основного языка доступа к данным. Эти типы баз данных также иногда называют нереляционными базами данных. В отличие от реляционных баз данных, данные в базах NoSQL не должны соответствовать заранее определенной схеме. Базы данных NoSQL следуют [модели согласованности BASE] (https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#base).

Ниже представлены различные типы баз данных NoSQL:

### Документоориентированные

База данных документов (также известная как документоориентированная база данных или хранилище документов) - это база данных, хранящая информацию в документах. Это базы данных общего назначения, которые служат для различных целей, как для транзакционных, так и для аналитических приложений.

**Преимущества**

- Интуитивно понятная и гибкая
- Легкое горизонтальное масштабирование
- Бессхемность

**Недостатки**

- Бессхемность
- Нереляционный

**Примеры**

- [MongoDB](https://www.mongodb.com)
- [Amazon DocumentDB](https://aws.amazon.com/documentdb)
- [CouchDB](https://couchdb.apache.org)

### Ключ-значение

Один из самых простых типов баз данных NoSQL, базы данных "ключ-значение" сохраняют данные в виде группы пар "ключ-значение", состоящих из двух элементов данных каждый. Их также иногда называют хранилищем ключевых значений.

**Преимущества**

- Простота и производительность
- Высокая масштабируемость при больших объемах трафика
- Управление сессиями
- Оптимизированный поиск

**Недостатки**

- Базовый CRUD
- Значения не могут быть отфильтрованы
- Отсутствует возможность индексирования и сканирования
- Не оптимизирован для сложных запросов

**Примеры**

- [Redis](https://redis.io)
- [Memcached](https://memcached.org)
- [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
- [Aerospike](https://aerospike.com)

### Графовые

Графовая база данных - это база данных NoSQL, которая использует графовые структуры для семантических запросов с узлами, ребрами и свойствами для представления и хранения данных вместо таблиц или документов.

Граф связывает элементы данных в хранилище с коллекцией узлов и ребер, причем ребра представляют собой отношения между узлами. Отношения позволяют напрямую связывать данные в хранилище и, во многих случаях, извлекать их одной операцией.

**Преимущества**

- Скорость выполнения запросов
- Маневренность и гибкость
- Явное представление данных

**Недостатки**

- Сложность
- Отсутствие стандартизированного языка запросов

**Примеры использования**

- Обнаружение мошенничества
- Системы рекомендаций
- Социальные сети
- Картирование сетей

**Примеры**
- [Neo4j](https://neo4j.com)
- [ArangoDB](https://www.arangodb.com)
- [Amazon Neptune](https://aws.amazon.com/neptune)
- [JanusGraph](https://janusgraph.org)

### Временные ряды

База данных временных рядов - это база данных, оптимизированная для работы с данными с временными метками, или временными рядами.

**Преимущества**

- Быстрая вставка и извлечение данных
- Эффективное хранение данных

**Примеры использования**

- Данные IoT
- Анализ метрик
- Мониторинг приложений
- Понимание финансовых тенденций

**Примеры**

- [InfluxDB](https://www.influxdata.com)
- [Apache Druid](https://druid.apache.org)

### Wide-column

Базы данных с широкими колонками, также известные как хранилища с широкими колонками, не зависят от схемы. Данные хранятся в семействах столбцов, а не в строках и столбцах.

**Преимущества**

- Высокая масштабируемость, может обрабатывать петабайты данных.
- Идеальны для приложений, работающих с большими данными в режиме реального времени

**Недостатки**

- Дорогостоящий
- Увеличенное время записи

**Примеры использования**

- Бизнес-аналитика
- Хранение данных на основе атрибутов

**Примеры**

- [BigTable](https://cloud.google.com/bigtable)
- [Apache Cassandra](https://cassandra.apache.org)
- [ScyllaDB](https://www.scylladb.com)

### Multi-model

Многомодельные базы данных объединяют различные модели баз данных (например, реляционную, графовую, ключевую, документную и т. д.) в единый интегрированный бэкэнд. Это означает, что они могут работать с различными типами данных, индексами, запросами и хранить данные более чем в одной модели.

**Преимущества**

- Гибкость
- Подходит для сложных проектов
- Согласованность данных

**Недостатки**

- Сложность
- Менее зрелый

**Примеры**

- [ArangoDB](https://www.arangodb.com)
- [Azure Cosmos DB](https://azure.microsoft.com/en-in/services/cosmos-db)
- [Couchbase](https://www.couchbase.com)

# SQL vs NoSQL базы данных

В мире баз данных существует два основных типа решений: SQL (реляционные) и NoSQL (нереляционные) базы данных. Оба типа отличаются друг от друга тем, как они были созданы, какой тип информации они хранят и как они ее хранят. Реляционные базы данных структурированы и имеют предопределенные схемы, в то время как нереляционные базы данных неструктурированы, распределены и имеют динамическую схему.

## Высокоуровневые различия

Вот некоторые высокоуровневые различия между SQL и NoSQL:

### Хранение

В SQL данные хранятся в таблицах, где каждая строка представляет собой объект, а каждый столбец - данные об этом объекте.

Базы данных NoSQL используют различные модели хранения данных, такие как ключ-значение, граф, документ и т. д.

### Схема

В SQL каждая запись соответствует фиксированной схеме, то есть столбцы должны быть определены и выбраны до ввода данных, а каждая строка должна содержать данные для каждого столбца. Схему можно изменить позже, но для этого необходимо модифицировать базу данных с помощью миграций.

В то время как в NoSQL схемы являются динамическими. Поля можно добавлять на лету, и каждая _запись_ (или ее эквивалент) не обязательно должна содержать данные для каждого _поля_.

### Запрос

Базы данных SQL используют язык SQL (структурированный язык запросов) для определения и манипулирования данными, который является очень мощным.

В базах данных NoSQL запросы сосредоточены на коллекции документов. Различные базы данных имеют разный синтаксис для запросов.

### Масштабируемость

В большинстве ситуаций базы данных SQL масштабируются вертикально, что может оказаться очень дорого. Реляционную базу данных можно масштабировать на несколько серверов, но это сложный и трудоемкий процесс.

С другой стороны, базы данных NoSQL масштабируются горизонтально, то есть мы можем легко добавить дополнительные серверы в нашу инфраструктуру баз данных NoSQL для обработки большого трафика. Любое дешевое товарное оборудование или облачные инстансы могут служить хостингом для баз данных NoSQL, что делает их гораздо более экономичными, чем вертикальное масштабирование. Многие технологии NoSQL также автоматически распределяют данные между серверами.

### Надежность

Подавляющее большинство реляционных баз данных соответствуют стандарту ACID. Поэтому, когда речь идет о надежности данных и гарантии выполнения транзакций, SQL-базы по-прежнему остаются лучшим выбором.

Большинство решений NoSQL жертвуют соответствием ACID ради производительности и масштабируемости.

## Причины

Как всегда, мы всегда должны выбирать ту технологию, которая лучше соответствует требованиям. Итак, давайте рассмотрим некоторые причины выбора базы данных на основе SQL или NoSQL:

**Для SQL**

- Структурированные данные со строгой схемой
- Реляционные данные
- Необходимость в сложных объединениях
- Транзакции
- Поиск по индексу очень быстрый

**Для NoSQL**

- Динамическая или гибкая схема
- Нереляционные данные
- Нет необходимости в сложных объединениях
- Очень интенсивная работа с данными
- Очень высокая пропускная способность по IOPS

# Репликация баз данных

Репликация - это процесс, который включает в себя обмен информацией для обеспечения согласованности между избыточными ресурсами, такими как несколько баз данных, для повышения надежности, отказоустойчивости или доступности.

## Репликация "ведущий-ведомый

Ведущее устройство обслуживает чтение и запись, реплицируя записи на одно или несколько ведомых устройств, которые обслуживают только чтение. Ведомые также могут реплицировать дополнительные ведомые в виде дерева. Если ведущий выходит из строя, система может продолжать работать в режиме "только чтение" до тех пор, пока ведомый не будет переведен в разряд ведущих или не будет создан новый ведущий.

![master-slave-replication](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-slave-replication.png)

### Преимущества

- Резервное копирование всей базы данных относительно не влияет на работу ведущего.
- Приложения могут считывать данные с ведомых устройств без воздействия на ведущее.
- Ведомые устройства могут быть переведены в автономный режим и синхронизированы с ведущим устройством без каких-либо простоев.

### Недостатки

- Репликация добавляет больше оборудования и дополнительную сложность.
- Время простоя и возможная потеря данных при отказе ведущего устройства.
- В архитектуре "ведущий-ведомый" все записи также должны производиться на ведущий.
- Чем больше ведомых, тем больше нужно реплицировать, что увеличивает задержку репликации.

## Репликация мастер-мастер

Оба мастера обслуживают чтение/запись и координируют работу друг с другом. Если один из мастеров выходит из строя, система может продолжать работать как на чтение, так и на запись.

![master-master-replication](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-master-replication.png)

### Преимущества

- Приложения могут читать с обоих мастеров.
- Распределение нагрузки на запись между обоими ведущими узлами.
- Простое, автоматическое и быстрое восстановление работоспособности.

### Недостатки

- Не так просты в настройке и развертывании, как master-slave.
- Либо слабо согласованы, либо имеют повышенную задержку записи из-за синхронизации.
- Разрешение конфликтов становится актуальным при добавлении большего числа узлов записи и увеличении задержки.

## Синхронная и асинхронная репликация

Основное различие между синхронной и асинхронной репликацией заключается в способе записи данных в реплику. При синхронной репликации данные записываются в первичное хранилище и в реплику одновременно. Таким образом, первичная копия и реплика всегда должны оставаться синхронизированными.

В отличие от этого, при асинхронной репликации данные копируются в реплику после того, как они уже записаны в первичное хранилище. Хотя процесс репликации может происходить практически в режиме реального времени, чаще всего репликация выполняется по расписанию, и это более экономично.

# Индексы

Индексы хорошо известны в базах данных, они используются для повышения скорости операций поиска данных в хранилище. Индекс - это компромисс между увеличением накладных расходов на хранение и замедлением записи (поскольку нам приходится не только записывать данные, но и обновлять индекс) и ускорением чтения. Индексы используются для быстрого поиска данных без необходимости изучать каждую строку в таблице базы данных. Индексы могут быть созданы на основе одного или нескольких столбцов таблицы базы данных, обеспечивая основу как для быстрого случайного поиска, так и для эффективного доступа к упорядоченным записям.

![indexes](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/indexes.png)

Индекс - это структура данных, которую можно воспринимать как оглавление, указывающее нам на место, где находятся реальные данные. Так, когда мы создаем индекс на столбец таблицы, мы храним этот столбец и указатель на всю строку в индексе. Индексы также используются для создания различных представлений одних и тех же данных. Для больших наборов данных это отличный способ задать различные фильтры или схемы сортировки, не прибегая к созданию нескольких дополнительных копий данных.

Одно из качеств, которым могут обладать индексы баз данных, заключается в том, что они могут быть **плотными** или **разрозненными**. Каждое из этих качеств индекса имеет свои компромиссы. Давайте рассмотрим, как работает каждый тип индекса:

## Плотный индекс

В плотном индексе для каждой строки таблицы создается запись индекса. Записи могут быть найдены напрямую, поскольку каждая запись индекса содержит значение ключа поиска и указатель на фактическую запись.

![dense-index](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/dense-index.png)

Плотные индексы требуют большего обслуживания, чем разреженные, во время записи. Поскольку каждая строка должна иметь запись, база данных должна поддерживать индекс при вставках, обновлениях и удалениях. Наличие записи для каждого ряда также означает, что плотные индексы требуют больше памяти. Преимущество плотного индекса в том, что значения могут быть быстро найдены с помощью двоичного поиска. Плотные индексы также не накладывают никаких требований к упорядочиванию данных.

## Разреженный индекс

В разреженном индексе записи создаются только для некоторых записей.

![sparse-index](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/sparse-index.png)

Разреженные индексы требуют меньшего обслуживания, чем плотные индексы, во время записи, поскольку содержат только подмножество значений. Это меньшее бремя обслуживания означает, что вставки, обновления и удаления будут выполняться быстрее. Меньшее количество записей также означает, что индекс будет использовать меньше памяти. Поиск данных происходит медленнее, поскольку за двоичным поиском обычно следует сканирование всей страницы. Разреженные индексы также необязательны при работе с упорядоченными данными.

# Нормализация и денормализация

## Термины

Прежде чем мы продолжим, давайте рассмотрим некоторые часто используемые термины в нормализации и денормализации.

### Ключи

**Первичный ключ**: Столбец или группа столбцов, которые могут быть использованы для уникальной идентификации каждой строки таблицы.

**Композитный ключ**: Первичный ключ, состоящий из нескольких столбцов.

**Суперключ**: Набор всех ключей, которые могут однозначно идентифицировать все строки, присутствующие в таблице.

**Кандидатский ключ**: Атрибуты, которые однозначно идентифицируют строки в таблице.

**Иностранный ключ**: Это ссылка на первичный ключ другой таблицы.

**Альтернативный ключ**: Ключи, которые не являются первичными, называются альтернативными ключами.

**Замещающий ключ**: Генерируемое системой значение, которое однозначно идентифицирует каждую запись в таблице, когда ни один другой столбец не может обладать свойствами первичного ключа.

### Зависимости

**Частичная зависимость**: Возникает, когда первичный ключ определяет некоторые другие атрибуты.

**Функциональная зависимость**: Это связь, существующая между двумя атрибутами, обычно между первичным ключом и неключевым атрибутом в таблице.

**Транзитивная функциональная зависимость**: Возникает, когда неключевой атрибут определяет другой атрибут.

### Аномалии

Аномалия в базе данных возникает, когда в базе данных есть недостаток, связанный с неправильным планированием или хранением всего в плоской базе данных. Обычно это решается с помощью процесса нормализации.

Существует три типа аномалий баз данных:

**Аномалия вставки**: Возникает, когда мы не можем вставить определенные атрибуты в базу данных без наличия других атрибутов.

**Аномалия обновления**: Возникает в случае избыточности данных и частичного обновления. Другими словами, для корректного обновления базы данных необходимы другие действия, такие как добавление, удаление или и то, и другое.

**Аномалия удаления**: Возникает, когда удаление одних данных требует удаления других.

**Пример**.

Рассмотрим следующую таблицу, которая не нормализована:

| ID | Name | Role | Team |
| --- | ------ | ----------------- | ---- |
| 1 | Питер | инженер-программист | A |
| 2 | Брайан | DevOps инженер | B |
| 3 | Хейли | Product Manager | C |
| 4 | Хейли | менеджер по продукту | C |
| 5 | Стив | Frontend Engineer | D |

Представим, что мы наняли нового человека "Джон", но ему не сразу назначили команду. Это вызовет аномалию вставки, поскольку атрибут команды еще не присутствует.

Далее, допустим, Хейли из команды C получила повышение, чтобы отразить это изменение в базе данных, нам нужно будет обновить 2 строки для поддержания согласованности, что может вызвать аномалию _обновления_.

Наконец, мы хотим удалить команду B, но для этого нам также потребуется удалить дополнительную информацию, такую как имя и роль, это пример аномалии _удаления_.

## Нормализация

Нормализация - это процесс организации данных в базе данных. Он включает в себя создание таблиц и установление отношений между ними в соответствии с правилами, призванными как защитить данные, так и сделать базу данных более гибкой за счет устранения избыточности и противоречивых зависимостей.

### Зачем нужна нормализация?

Цель нормализации - устранить избыточные данные и обеспечить их согласованность. Полностью нормализованная база данных позволяет расширять ее структуру для размещения новых типов данных без сильного изменения существующей структуры. В результате приложения, взаимодействующие с базой данных, подвергаются минимальному воздействию.

### Нормальные формы

Нормальные формы - это ряд рекомендаций, обеспечивающих нормализацию базы данных. Давайте обсудим некоторые основные нормальные формы:

**1NF**

Чтобы таблица находилась в первой нормальной форме (1НФ), она должна соответствовать следующим правилам:

- Повторяющиеся группы не допускаются.
- Каждый набор связанных данных должен быть идентифицирован первичным ключом.
- Набор связанных данных должен иметь отдельную таблицу.
- Смешение типов данных в одном столбце не допускается.

**2NF**.

Чтобы таблица была во второй нормальной форме (2НФ), она должна соответствовать следующим правилам:

- Удовлетворяет первой нормальной форме (1НФ).
- Не должна иметь частичных зависимостей.

**3NF**

Чтобы таблица находилась в третьей нормальной форме (3NF), она должна соответствовать следующим правилам:

- Удовлетворяет второй нормальной форме (2НФ).
- Переходные функциональные зависимости не допускаются.

**BCNF**

Нормальная форма Бойса-Кодда (или BCNF) - это несколько более сильная версия третьей нормальной формы (3NF), используемая для решения некоторых типов аномалий, с которыми не справляется 3NF в своем первоначальном виде. Иногда ее также называют нормальной формой 3,5 (3,5НФ).

Чтобы таблица была в нормальной форме Бойса-Кодда (BCNF), она должна соответствовать следующим правилам:

- Удовлетворяет третьей нормальной форме (3НФ).
- Для каждой функциональной зависимости X → Y, X должен быть суперключом.

Существуют и другие нормальные формы, такие как 4НФ, 5НФ и 6НФ, но мы не будем обсуждать их здесь. Посмотрите это [удивительное видео](https://www.youtube.com/watch?v=GFQaEYEc8_8), где все подробно описано.

В реляционных базах данных отношение часто называют _"нормализованным"_, если оно соответствует третьей нормальной форме. Большинство 3НФ-отношений не содержат аномалий при вставке, обновлении и удалении.

Как и в случае со многими формальными правилами и спецификациями, реальные сценарии не всегда позволяют добиться идеального соответствия. Если вы решите нарушить одно из первых трех правил нормализации, убедитесь, что ваше приложение предвидит возможные проблемы, такие как избыточные данные и противоречивые зависимости.

### Преимущества

Вот некоторые преимущества нормализации:

- Уменьшение избыточности данных.
- Улучшение дизайна данных.
- Повышает согласованность данных.
- Обеспечивает ссылочную целостность.

### Недостатки

Давайте рассмотрим некоторые недостатки нормализации:

- Сложный дизайн данных.
- Замедление производительности.
- Накладные расходы на обслуживание.
- Требуется больше соединений.

## Денормализация

Денормализация - это техника оптимизации базы данных, при которой мы добавляем избыточные данные в одну или несколько таблиц. Это может помочь нам избежать дорогостоящих объединений в реляционной базе данных. Она пытается улучшить производительность чтения за счет некоторого снижения производительности записи. Избыточные копии данных записываются в несколько таблиц, чтобы избежать дорогостоящих объединений.

Когда данные становятся распределенными с помощью таких техник, как федерация и шардинг, управление соединениями по сети еще больше усложняется. Денормализация позволяет обойти необходимость в таких сложных соединениях.

_Примечание: Денормализация не означает отмену нормализации._

### Преимущества

Давайте рассмотрим некоторые преимущества денормализации:

- Получение данных происходит быстрее.
- Написание запросов стало проще.
- Сокращение числа таблиц.
- Удобство управления.

### Недостатки

Ниже перечислены некоторые недостатки денормализации:

- Дорогие вставки и обновления.
- Повышает сложность проектирования базы данных.
- Увеличение избыточности данных.
- Больше шансов на несогласованность данных.

# Модели согласованности ACID и BASE

Давайте обсудим модели согласованности ACID и BASE.

## ACID

Термин ACID расшифровывается как Atomicity, Consistency, Isolation, and Durability. Свойства ACID используются для поддержания целостности данных во время обработки транзакций.

Для того чтобы поддерживать целостность данных до и после транзакции, реляционные базы данных следуют свойствам ACID. Давайте разберемся в этих терминах:

### Атомарный

Все операции в транзакции завершаются успешно или все операции откатываются.

### Consistent

По завершении транзакции база данных становится структурно целостной.

### Изолированная

Транзакции не конфликтуют друг с другом. Спорный доступ к данным сдерживается базой данных, так что транзакции выглядят как последовательно выполняющиеся.

### Долговечность

После того как транзакция завершена и записи и обновления записаны на диск, она останется в системе, даже если произойдет сбой в системе.

## BASE

С увеличением объема данных и требований к высокой доступности подход к проектированию баз данных также значительно изменился. Чтобы увеличить способность к масштабированию и одновременно обеспечить высокую доступность, мы переносим логику из базы данных на отдельные серверы. Таким образом, база данных становится более независимой и ориентированной на реальный процесс хранения данных.

В мире баз данных NoSQL транзакции ACID встречаются реже, поскольку некоторые базы данных ослабили требования к немедленной согласованности, свежести и точности данных, чтобы получить другие преимущества, такие как масштаб и отказоустойчивость.

Свойства BASE намного слабее, чем гарантии ACID, но прямого соответствия один к одному между этими двумя моделями согласованности не существует. Давайте разберемся в этих терминах:

### Базовая доступность

База данных работает большую часть времени.

### Мягкое состояние

Хранилища не обязательно должны быть согласованными на запись, как и разные реплики не должны быть все время взаимно согласованными.

### Последовательность в конечном итоге

Данные могут не быть согласованными сразу, но со временем они становятся согласованными. Чтение в системе все еще возможно, даже если оно может не дать правильного ответа из-за несогласованности.

## Компромиссы между ACID и BASE

Не существует правильного ответа на вопрос о том, какая модель согласованности нужна нашему приложению - ACID или BASE. Обе модели были разработаны для удовлетворения различных требований. Выбирая базу данных, мы должны учитывать свойства обеих моделей и требования нашего приложения.

Учитывая слабую согласованность BASE, разработчикам необходимо быть более осведомленными и строгими в отношении согласованности данных, если они выбирают BASE-хранилище для своего приложения. Очень важно знать поведение BASE в выбранной базе данных и работать в рамках этих ограничений.

С другой стороны, планирование с учетом BASE-ограничений иногда может стать серьезным недостатком по сравнению с простотой ACID-транзакций. Полностью ACID-база данных идеально подходит для тех случаев, когда важна надежность и согласованность данных.

# CAP Теорема

Теорема CAP утверждает, что распределенная система может обеспечить только две из трех желаемых характеристик - согласованность, доступность и устойчивость к разбиению (CAP).

![cap-theorem](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/cap-theorem/cap-theorem.png)

Давайте подробно рассмотрим три характеристики распределенной системы, на которые ссылается теорема CAP.

### Согласованность

Согласованность означает, что все клиенты видят одни и те же данные в одно и то же время, независимо от того, к какому узлу они подключаются. Чтобы этого не произошло, при записи данных на один узел они должны быть мгновенно переданы или реплицированы на все узлы системы, прежде чем запись будет признана "успешной".

### Доступность

Доступность означает, что любой клиент, сделавший запрос на получение данных, получит ответ, даже если один или несколько узлов не работают.

### Толерантность к разделению

Устойчивость к разделам означает, что система продолжает работать, несмотря на потерю сообщений или частичный отказ. Система, устойчивая к разделам, может выдержать любое количество отказов сети, не приводящее к отказу всей сети. Данные в достаточной степени реплицируются между комбинациями узлов и сетей, чтобы система продолжала работать при периодических сбоях.

## Компромисс между согласованностью и доступностью

Мы живем в физическом мире и не можем гарантировать стабильность сети, поэтому распределенные базы данных должны выбирать терпимость к разделам (P). Это подразумевает компромисс между согласованностью (C) и доступностью (A).

### База данных CA

База данных CA обеспечивает согласованность и доступность на всех узлах. Она не может этого сделать, если между любыми двумя узлами в системе есть разделение, и поэтому не может обеспечить отказоустойчивость.

**Пример**: [PostgreSQL](https://www.postgresql.org), [MariaDB](https://mariadb.org).

### База данных CP

База данных CP обеспечивает согласованность и устойчивость к разделам за счет доступности. Когда между двумя узлами возникает разделение, система должна выключить несовместимый узел, пока разделение не будет устранено.

**Пример**: [MongoDB](https://www.mongodb.com), [Apache HBase](https://hbase.apache.org).

### База данных AP

База данных AP обеспечивает доступность и устойчивость к разделам за счет согласованности. Когда происходит разделение, все узлы остаются доступными, но узлы, находящиеся не на том конце раздела, могут возвращать более старую версию данных, чем другие. Когда раздел разрешается, базы данных AP обычно повторно синхронизируют узлы, чтобы устранить все несоответствия в системе.

**Пример**: [Apache Cassandra](https://cassandra.apache.org), [CouchDB](https://couchdb.apache.org).

# Теорема PACELC

Теорема PACELC является расширением теоремы CAP. Теорема CAP утверждает, что в случае разделения сети (P) в распределенной системе необходимо выбирать между доступностью (A) и согласованностью (C).

PACELC расширяет теорему CAP, вводя задержку (L) в качестве дополнительного атрибута распределенной системы. Теорема утверждает, что в противном случае (E), даже когда система работает нормально при отсутствии разделов, приходится выбирать между задержкой (L) и согласованностью (C).

_Теорема PACELC была впервые описана [Daniel J. Abadi](https://scholar.google.com/citations?user=zxeEF2gAAAAJ)._

![pacelc-theorem](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/pacelc-theorem/pacelc-theorem.png)

Теорема PACELC была разработана для устранения ключевого ограничения теоремы CAP, поскольку она не учитывает производительность и задержку.

Например, согласно теореме CAP, база данных может считаться доступной, если запрос возвращает ответ через 30 дней. Очевидно, что такая задержка неприемлема для любого реального приложения.

# Транзакции

Транзакция - это серия операций над базой данных, которые рассматриваются как "единое целое". Операции в транзакции либо все успешны, либо все неудачны. Таким образом, понятие транзакции поддерживает целостность данных, когда часть системы выходит из строя. Не все базы данных предпочитают поддерживать ACID-транзакции, обычно потому, что для них приоритетны другие оптимизации, которые трудно или теоретически невозможно реализовать вместе.

_Обычно реляционные базы данных поддерживают транзакции ACID, а нереляционные - нет (бывают исключения)._

## Состояния

Транзакция в базе данных может находиться в одном из следующих состояний:

![transaction-states](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/transactions/transaction-states.png)

### Active

В этом состоянии транзакция находится в процессе выполнения. Это начальное состояние каждой транзакции.

### Partially Committed

Когда транзакция выполняет свою заключительную операцию, считается, что она находится в состоянии частичной фиксации.

### Committed

Если транзакция успешно выполняет все свои операции, считается, что она зафиксирована. Все ее последствия теперь навсегда закреплены в системе базы данных.

### Failed

Транзакция считается неудачной, если ни одна из проверок, выполненных системой восстановления базы данных, не дала результата. Провалившаяся транзакция больше не может продолжаться.

### Aborted

Если любая из проверок не удалась и транзакция достигла состояния неудачи, менеджер восстановления откатывает все свои операции записи в базу данных, чтобы вернуть базу данных в исходное состояние, в котором она находилась до выполнения транзакции. Транзакции в этом состоянии прерываются.

Модуль восстановления базы данных может выбрать одну из двух операций после прерывания транзакции:

- Перезапустить транзакцию
- Завершить транзакцию

### Terminated

Если отката не было или транзакция пришла из состояния _committed state_, то система согласована и готова к новой транзакции, а старая транзакция завершается.

# Распределенные транзакции

Распределенная транзакция - это набор операций над данными, выполняемых в двух или более базах данных. Обычно она координируется на отдельных узлах, соединенных сетью, но может охватывать и несколько баз данных на одном сервере.

## Зачем нужны распределенные транзакции?

В отличие от ACID-транзакции в одной базе данных, распределенная транзакция предполагает изменение данных в нескольких базах данных. Следовательно, обработка распределенных транзакций сложнее, поскольку база данных должна координировать фиксацию или откат изменений в транзакции как единое целое.

Другими словами, все узлы должны зафиксировать изменения, или все должны прервать транзакцию, и вся транзакция откатывается назад. Вот почему нам нужны распределенные транзакции.

Теперь давайте рассмотрим некоторые популярные решения для распределенных транзакций:

## Двухфазный коммит

![two-phase-commit](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/two-phase-commit.png)

Протокол двухфазной фиксации (2PC) - это распределенный алгоритм, который координирует все процессы, участвующие в распределенной транзакции, по вопросу фиксации или прерывания (отката) транзакции.

Этот протокол достигает своей цели даже во многих случаях временного сбоя системы и поэтому широко используется. Однако он не устойчив ко всем возможным конфигурациям сбоев, и в редких случаях для исправления ситуации требуется ручное вмешательство.

Этот протокол требует наличия узла-координатора, который, по сути, координирует и контролирует транзакции между различными узлами. Координатор пытается установить консенсус между множеством процессов в две фазы, отсюда и название.

### Фазы

Двухфазная фиксация состоит из следующих фаз:

**Фаза подготовки**.

В фазе подготовки узел-координатор собирает консенсус от каждого из узлов-участников. Транзакция будет прервана, если каждый из узлов не ответит, что он _подготовлен_.

**Фаза фиксации**.

Если все участники ответили координатору, что они _готовятся_, то координатор просит все узлы зафиксировать транзакцию. Если произойдет сбой, транзакция будет откачена.

### Проблемы

При использовании двухфазного протокола фиксации могут возникнуть следующие проблемы:

- Что делать, если один из узлов потерпел крах?
- Что, если сломается сам координатор?
- Это блокирующий протокол.

## Трехфазная фиксация (3PC)

![three-phase-commit](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/three-phase-commit.png)

Трехфазная фиксация (3PC) - это расширение двухфазной фиксации, в котором фаза фиксации разбивается на две фазы. Это помогает решить проблему блокировки, которая возникает в протоколе двухфазной фиксации.

### Фазы

Трехфазная фиксация состоит из следующих фаз:

**Фаза подготовки**.

Эта фаза аналогична двухфазной фиксации.

**Фаза предварительной фиксации**.

Координатор выпускает сообщение pre-commit, и все участвующие узлы должны его подтвердить. Если участник не получает это сообщение вовремя, то транзакция прерывается.

**Фаза коммита**

Этот этап также похож на двухфазный протокол фиксации.

### Почему фаза предварительной фиксации полезна?

Фаза предварительной коммисии выполняет следующее:

- Если узлы-участники найдены в этой фазе, это означает, что _каждый_ участник завершил первую фазу. Завершение фазы подготовки гарантировано.
- Теперь каждая фаза может отработать по времени и избежать бесконечных ожиданий.

## Саги

![sagas](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/sagas.png)

Сага - это последовательность локальных транзакций. Каждая локальная транзакция обновляет базу данных и публикует сообщение или событие для запуска следующей локальной транзакции в саге. Если локальная транзакция терпит неудачу из-за нарушения бизнес-правил, сага выполняет серию компенсирующих транзакций, которые отменяют изменения, внесенные предыдущими локальными транзакциями.

### Координация

Существует два распространенных подхода к реализации:

- **Хореография**: Каждая локальная транзакция публикует события в домене, которые вызывают локальные транзакции в других сервисах.
- **Оркестрация**: Оркестрант указывает участникам, какие локальные транзакции выполнять.

### Проблемы

- Паттерн Saga особенно трудно отлаживать.
- Существует риск возникновения циклической зависимости между участниками саги.
- Отсутствие изоляции данных участников создает проблемы с долговечностью.
- Тестирование затруднено, поскольку для имитации транзакции должны быть запущены все службы.

# Шардинг

Прежде чем обсуждать шардинг, давайте поговорим о разделении данных:

## Разбиение данных

Разбиение данных - это техника, позволяющая разбить базу данных на множество более мелких частей. Это процесс разделения базы данных или таблицы на несколько машин для улучшения управляемости, производительности и доступности базы данных.

### Методы

Существует множество различных способов решить, как разбить базу данных приложения на несколько меньших БД. Ниже приведены два наиболее популярных метода, используемых в различных крупномасштабных приложениях:

**Горизонтальное разбиение (или шардинг)**.

В этой стратегии мы разбиваем данные таблицы по горизонтали на основе диапазона значений, определяемого _ключом раздела_. Ее также называют **разбиением базы данных на части_**.

**Вертикальное разбиение**

При вертикальном разбиении мы разделяем данные по вертикали на основе столбцов. Мы делим таблицы на относительно меньшие таблицы с небольшим количеством элементов, и каждая часть находится в отдельном разделе.

В этом руководстве мы сосредоточимся на шардинге.

## Что такое шардинг?

Шардинг - это архитектурный паттерн базы данных, связанный с _горизонтальным разделением_, которое представляет собой практику разделения строк одной таблицы на несколько различных таблиц, известных как _разделы_ или _шарды_. Каждый раздел имеет одну и ту же схему и столбцы, но также подмножество общих данных. Кроме того, данные, хранящиеся в каждом из разделов, уникальны и не зависят от данных, хранящихся в других разделах.

![sharding](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/sharding/sharding.png)

Оправданием шардинга данных является то, что после определенного момента дешевле и целесообразнее масштабировать систему по горизонтали, добавляя больше машин, чем по вертикали, добавляя мощные серверы. Разделение может быть реализовано как на уровне приложения, так и на уровне базы данных.

## Критерии разделения

Существует большое количество критериев для разделения данных. Наиболее часто используются следующие критерии:

### Hash-Based

Эта стратегия разделяет строки на различные разделы на основе алгоритма хэширования, а не группирует строки базы данных на основе непрерывных индексов.

Недостатком этого метода является то, что динамическое добавление/удаление серверов базы данных становится дорогостоящим.

### Разбиение на основе списков

При списочном разбиении каждый раздел определяется и выбирается на основе списка значений в столбце, а не набора смежных диапазонов значений.

### Range Based

Разбиение по диапазонам сопоставляет данные с различными разделами на основе диапазонов значений ключа разбиения. Другими словами, мы разбиваем таблицу таким образом, чтобы каждый раздел содержал строки в заданном диапазоне, определяемом ключом разбиения.

Диапазоны должны быть смежными, но не пересекающимися, где каждый диапазон определяет неполную нижнюю и верхнюю границу раздела. Любые значения ключа раздела, равные или превышающие верхнюю границу диапазона, добавляются к следующему разделу.

### Композитный

Как следует из названия, составное разбиение разделяет данные на основе двух или более методов разбиения. Сначала мы разбиваем данные с помощью одного метода, а затем каждый раздел делится на подразделы с помощью того же или другого метода.

## Преимущества

Но зачем нам нужно шардинг? Вот некоторые преимущества:

- **Доступность**: Обеспечивает логическую независимость разделенной на разделы базы данных, гарантируя высокую доступность нашего приложения. Отдельные разделы могут управляться независимо друг от друга.
- **Масштабируемость**: Обеспечивает увеличение масштабируемости за счет распределения данных по нескольким разделам.
- **Безопасность**: Помогает повысить безопасность системы за счет хранения чувствительных и нечувствительных данных в разных разделах. Это обеспечивает лучшую управляемость и безопасность конфиденциальных данных.
- **Производительность запросов**: Повышает производительность системы. Вместо того чтобы запрашивать всю базу данных, теперь системе нужно запрашивать только меньший раздел.
- **Управляемость данных**: Разделение таблиц и индексов на более мелкие и управляемые единицы.
  
## Недостатки

- **Сложность**: Шардинг увеличивает сложность системы в целом.
- **Соединения между шардами**: Когда база данных разбита на разделы и распределена по нескольким машинам, часто бывает нецелесообразно выполнять соединения, охватывающие несколько шардов базы данных. Такие соединения не будут эффективными с точки зрения производительности, поскольку данные придется получать с нескольких серверов.
- **Ребалансировка**: Если распределение данных неравномерно или на один шард приходится большая нагрузка, в таких случаях необходимо перебалансировать шарды, чтобы запросы распределялись между ними как можно равномернее.

## Когда использовать шардинг?

Вот несколько причин, по которым шардинг может быть правильным выбором:

- Использование существующего оборудования вместо высокопроизводительных машин.
- Хранение данных в разных географических регионах.
- Быстрое масштабирование путем добавления новых шардов.
- Более высокая производительность, поскольку каждая машина испытывает меньшую нагрузку.
- Когда требуется больше одновременных подключений.

# Последовательное хэширование

Давайте сначала разберемся, какую проблему мы пытаемся решить.

## Зачем нам это нужно?

В традиционных методах распределения, основанных на хэшировании, мы используем хэш-функцию для хэширования наших ключей раздела (т. е. идентификатора запроса или IP). Затем, если мы используем модуло против общего количества узлов (серверов или баз данных). Это даст нам узел, куда мы хотим направить наш запрос.

![simple-hashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/simple-hashing.png)

$$
\begin{align*}
& Hash(key_1) \to H_1 \bmod N = Node_0 \\
& Hash(key_2) \to H_2 \bmod N = Node_1 \\
& Hash(key_3) \to H_3 \bmod N = Node_2 \\
& ... \\
& Hash(key_n) \to H_n \bmod N = Node_{n-1}
\end{align*}
$$

Где,

`key`: Идентификатор запроса или IP.

`H`: Результат хэш-функции.

`N`: Общее количество узлов.

`Node`: Узел, на который будет направлен запрос.

Проблема в том, что если мы добавим или удалим узел, это приведет к изменению `N`, а значит, наша стратегия отображения нарушится, так как те же самые запросы теперь будут направляться на другой сервер. Как следствие, большинство запросов придется перераспределять, что очень неэффективно.

Мы хотим равномерно распределять запросы между различными узлами, чтобы можно было добавлять или удалять узлы с минимальными усилиями. Следовательно, нам нужна схема распределения, которая не зависит напрямую от количества узлов (или серверов), чтобы при добавлении или удалении узлов количество ключей, которые нужно переместить, было минимальным.

Последовательное хеширование решает эту проблему горизонтальной масштабируемости, гарантируя, что при каждом увеличении или уменьшении масштаба нам не придется переставлять все ключи или трогать все серверы.

Теперь, когда мы поняли суть проблемы, давайте обсудим последовательное хеширование более подробно.

## Как это работает

Consistent Hashing - это распределенная схема хеширования, которая работает независимо от количества узлов в распределенной хеш-таблице, присваивая им позицию на абстрактном круге, или хеш-кольце. Это позволяет масштабировать серверы и объекты без ущерба для всей системы.

![последовательное хэширование](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/consistent-hashing.png)

При использовании последовательного хэширования только данные `K/N` требуют перераспределения.

$$
R = K/N
$$

Где,

`R`: Данные, требующие повторного распространения.

`K`: Количество ключей разделов.

`N`: Количество узлов.

Выход хэш-функции - это диапазон, скажем, `0...m-1`, который мы можем представить на нашем хэш-кольце. Мы хэшируем запросы и распределяем их по кольцу в зависимости от того, что получилось на выходе. Аналогичным образом мы хэшируем узлы и распределяем их по тому же кольцу.

$$
\begin{align*}
& Hash(key_1) = P_1 \\
& Hash(key_2) = P_2 \\
& Hash(key_3) = P_3 \\
& ... \\
& Hash(key_n) = P_{m-1}
\end{align*}
$$

Где,

`ключ`: Идентификатор запроса/узла или IP.

`P`: Позиция в хэш-кольце.

`m`: Общий радиус действия хэш-кольца.

Теперь, когда поступает запрос, мы можем просто направить его на ближайший узел по часовой стрелке (можно и против часовой). Это означает, что если добавляется или удаляется новый узел, мы можем использовать ближайший узел, и только _часть_ запросов нужно будет перенаправлять.

В теории последовательное хеширование должно равномерно распределять нагрузку, однако на практике этого не происходит. Обычно нагрузка распределяется неравномерно, и один сервер может в итоге обрабатывать большую часть запросов, становясь _горячей точкой_, по сути, узким местом в системе. Это можно исправить, добавив дополнительные узлы, но это может быть дорого.

## Виртуальные узлы

Чтобы обеспечить более равномерное распределение нагрузки, мы можем ввести идею виртуального узла, иногда также называемого VNode.

Вместо того чтобы назначать узлу одну позицию, хэш-диапазон делится на несколько меньших диапазонов, и каждому физическому узлу назначается несколько таких меньших диапазонов. Каждый из этих поддиапазонов считается виртуальным узлом. Таким образом, виртуальные узлы - это, по сути, существующие физические узлы, отображенные несколько раз в хэш-кольце, чтобы минимизировать изменения в назначенном узлу диапазоне.

![virtual-nodes](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/virtual-nodes.png)

Для этого мы можем использовать `k` количество хэш-функций.

$$
\begin{align*}
& Hash_1(key_1) = P_1 \\
& Hash_2(key_2) = P_2 \\
& Hash_3(key_3) = P_3 \\
& . . . \\
& Hash_k(key_n) = P_{m-1}
\end{align*}
$$

Где,

`ключ`: Идентификатор запроса/узла или IP.

`k`: Количество хэш-функций.

`P`: Позиция в хэш-кольце.

`m`: Общий диапазон хэш-кольца.

Поскольку VNodes помогают более равномерно распределить нагрузку между физическими узлами кластера, разбивая хэш-диапазоны на более мелкие поддиапазоны, это ускоряет процесс перебалансировки после добавления или удаления узлов. Это также помогает нам уменьшить вероятность возникновения "горячих точек".

## Репликация данных

Для обеспечения высокой доступности и долговечности последовательное хеширование реплицирует каждый элемент данных на нескольких `N` узлах системы, где значение `N` эквивалентно _фактору репликации_.

Фактор репликации - это количество узлов, которые получат копию одних и тех же данных. В конечном итоге в согласованных системах это делается асинхронно.

## Преимущества

Давайте рассмотрим некоторые преимущества последовательного хеширования:

- Делает более предсказуемым быстрое масштабирование вверх и вниз.
- Облегчает разделение и репликацию между узлами.
- Обеспечивает масштабируемость и доступность.
- Уменьшает количество "горячих точек".

## Недостатки

Ниже перечислены некоторые недостатки последовательного хеширования:

- Повышение сложности.
- Каскадные сбои.
- Распределение нагрузки может быть неравномерным.
- Управление ключами может быть дорогостоящим, если узлы периодически выходят из строя.

## Примеры

Давайте рассмотрим несколько примеров использования последовательного хеширования:

- Разбиение данных в [Apache Cassandra](https://cassandra.apache.org).
- Распределение нагрузки между несколькими узлами хранения в [Amazon DynamoDB](https://aws.amazon.com/dynamodb).

# Федерация баз данных

Федерация (или функциональное разделение) разделяет базы данных по функциям. Благодаря архитектуре федерации несколько отдельных физических баз данных представляются конечным пользователям как одна логическая база данных.

Все компоненты федерации связаны между собой одной или несколькими федеративными схемами, которые выражают общность данных во всей федерации. Эти федеративные схемы используются для определения информации, которая может быть совместно использована компонентами федерации, и для обеспечения общей основы для взаимодействия между ними.

![database-federation](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-federation/database-federation.png)

Федерация также обеспечивает целостное, единое представление данных, полученных из нескольких источников. Источниками данных для федеративных систем могут быть базы данных и различные другие формы структурированных и неструктурированных данных.

## Характеристики

Давайте рассмотрим некоторые ключевые характеристики федеративной базы данных:

- **Прозрачность**: Федеративная база данных маскирует различия между пользователями и реализациями базовых источников данных. Поэтому пользователям не нужно знать, где хранятся данные.
- **Гетерогенность**: Источники данных могут различаться по многим параметрам. Система федеративных баз данных может работать с различным оборудованием, сетевыми протоколами, моделями данных и т. д.
- **Расширяемость**: Для удовлетворения меняющихся потребностей бизнеса могут потребоваться новые источники. Хорошая система федеративных баз данных должна обеспечивать простоту добавления новых источников.
- **Автономность**: Федеративная база данных не изменяет существующие источники данных, интерфейсы должны оставаться прежними.
- **Интеграция данных**: Федеративная база данных может интегрировать данные из различных протоколов, систем управления базами данных и т. д.

## Преимущества

Вот некоторые преимущества федеративных баз данных:

- Гибкое совместное использование данных.
- Автономность компонентов базы данных.
- Единый доступ к разнородным данным.
- Отсутствие жесткой связи приложений с унаследованными базами данных.

## Недостатки

Ниже перечислены некоторые недостатки федеративных баз данных:

- Добавляет больше оборудования и дополнительные сложности.
- Объединение данных из двух баз данных является сложной задачей.
- Зависимость от автономных источников данных.
- Производительность запросов и масштабируемость.

# N-уровневая архитектура

N-уровневая архитектура делит приложение на логические и физические уровни. Слои - это способ разделения ответственности и управления зависимостями. Каждый уровень несет определенную ответственность. Более высокий уровень может использовать сервисы более низкого уровня, но не наоборот.

![n-tier-architecture](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/n-tier-architecture/n-tier-architecture.png)

Уровни физически разделены, работают на разных машинах. Уровень может обращаться к другому уровню напрямую или использовать асинхронный обмен сообщениями. Хотя каждый уровень может быть размещен на отдельном уровне, это не обязательно. Несколько уровней могут быть размещены на одном ярусе. Физическое разделение уровней улучшает масштабируемость и отказоустойчивость и увеличивает задержки из-за дополнительного сетевого взаимодействия.

N-уровневая архитектура может быть двух типов:

- В архитектуре с закрытыми уровнями уровень может обращаться только к следующему уровню, расположенному сразу за ним.
- В архитектуре с открытыми уровнями уровень может вызывать любой из нижележащих уровней.

Архитектура закрытого уровня ограничивает зависимости между уровнями. Однако она может создавать ненужный сетевой трафик, если один уровень просто передает запросы следующему уровню.

## Типы N-уровневых архитектур

Давайте рассмотрим некоторые примеры N-уровневых архитектур:

### 3-уровневая архитектура

Трехуровневая архитектура широко распространена и состоит из следующих различных уровней:

- **Презентационный уровень**: Управляет взаимодействием пользователей с приложением.
- **Уровень бизнес-логики**: Принимает данные от прикладного уровня, проверяет их в соответствии с бизнес-логикой и передает их на уровень данных.
- **Уровень доступа к данным**: Получает данные от бизнес-слоя и выполняет необходимые операции с базой данных.

### Двухуровневая архитектура

В этой архитектуре презентационный слой работает на клиенте и взаимодействует с хранилищем данных. Между клиентом и сервером нет ни слоя бизнес-логики, ни непосредственного слоя.

### Одноуровневая или 1-Tier архитектура

Это самая простая архитектура, поскольку она эквивалентна запуску приложения на персональном компьютере. Все необходимые компоненты для работы приложения находятся на одном приложении или сервере.

## Преимущества

Вот некоторые преимущества использования N-уровневой архитектуры:

- Повышение доступности.
- Повышение безопасности, так как уровни могут вести себя как брандмауэр.
- Отдельные уровни позволяют масштабировать их по мере необходимости.
- Улучшение обслуживания, так как разные люди могут управлять разными уровнями.

## Недостатки

Ниже перечислены некоторые недостатки N-уровневой архитектуры:

- Повышенная сложность системы в целом.
- Увеличение сетевых задержек при увеличении числа уровней.
- Дороговизна, поскольку каждый уровень будет иметь свои собственные аппаратные затраты.
- Сложность управления сетевой безопасностью.

# Брокеры сообщений

Брокер сообщений - это программное обеспечение, которое позволяет приложениям, системам и сервисам взаимодействовать друг с другом и обмениваться информацией. Брокер сообщений делает это путем трансляции сообщений между формальными протоколами обмена сообщениями. Это позволяет взаимозависимым сервисам "разговаривать" друг с другом напрямую, даже если они написаны на разных языках или реализованы на разных платформах.

![message-broker](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-brokers/message-broker.png)

Брокеры сообщений могут проверять, хранить, маршрутизировать и доставлять сообщения по назначению. Они служат посредниками между другими приложениями, позволяя отправителям отправлять сообщения, не зная, где находятся получатели, активны ли они, и сколько их всего. Это облегчает разделение процессов и сервисов в системах.

## Модели

Брокеры сообщений предлагают две основные модели распределения сообщений или стили обмена сообщениями:

- **[Point-to-Point messaging](https://karanpratapsingh.com/courses/system-design/message-queues)**: Это схема распределения, используемая в очередях сообщений с отношениями "один к одному" между отправителем и получателем сообщения.
- **[Publish-Subscribe messaging](https://karanpratapsingh.com/courses/system-design/publish-subscribe)**: В этом шаблоне распределения сообщений, часто называемом _"pub/sub"_, производитель каждого сообщения публикует его в теме, а множество потребителей сообщений подписываются на темы, от которых они хотят получать сообщения.

_Мы подробно рассмотрим эти шаблоны обмена сообщениями в последующих уроках._

## Брокеры сообщений и потоковая передача событий

Брокеры сообщений могут поддерживать два или более шаблонов обмена сообщениями, включая очереди сообщений и pub/sub, в то время как платформы потоковой передачи событий предлагают только шаблоны распределения в стиле pub/sub. Платформы потоковой передачи событий, предназначенные для работы с большими объемами сообщений, легко масштабируются. Они способны упорядочивать потоки записей по категориям, называемым _темами_, и хранить их в течение заранее определенного времени. Однако, в отличие от брокеров сообщений, платформы потоковой передачи событий не могут гарантировать доставку сообщений или отслеживать, какие потребители получили сообщения.

Платформы потоковой передачи событий обладают большей масштабируемостью, чем брокеры сообщений, но меньшим количеством функций, обеспечивающих отказоустойчивость, таких как повторная отправка сообщений, а также более ограниченными возможностями маршрутизации и постановки сообщений в очередь.

## Message brokers vs Enterprise Service Bus (ESB)

Инфраструктура [Enterprise Service Bus (ESB)](https://karanpratapsingh.com/courses/system-design/enterprise-service-bus) сложна, ее интеграция и обслуживание могут оказаться дорогостоящими. Их сложно устранять при возникновении проблем в производственных средах, их нелегко масштабировать, а обновление является утомительным.

Брокеры сообщений - это _"облегченная"_ альтернатива ESB, которая обеспечивает аналогичную функциональность, механизм межсервисного взаимодействия, но при этом стоит дешевле. Они хорошо подходят для использования в [архитектурах микросервисов](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices), которые стали более распространенными, поскольку ESB вышли из моды

## Примеры

Вот некоторые часто используемые брокеры сообщений:

- [NATS](https://nats.io)
- [Apache Kafka](https://kafka.apache.org)
- [RabbitMQ](https://www.rabbitmq.com)
- [ActiveMQ](https://activemq.apache.org)

# Очереди сообщений

Очередь сообщений - это форма межсервисного взаимодействия, которая обеспечивает асинхронную связь. Она асинхронно получает сообщения от производителей и отправляет их потребителям.

Очереди используются для эффективного управления запросами в крупномасштабных распределенных системах. В небольших системах с минимальной нагрузкой на обработку и небольшими базами данных запись может быть предсказуемо быстрой. Однако в более сложных и больших системах запись может занимать практически недетерминированное время.

![message-queue](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-queues/message-queue.png)

## Устройство

Сообщения хранятся в очереди до тех пор, пока не будут обработаны и удалены. Каждое сообщение обрабатывается только один раз одним потребителем. Вот как это работает:

- Производитель публикует задание в очереди, а затем уведомляет пользователя о статусе задания.
- Потребитель забирает задание из очереди, обрабатывает его и сигнализирует о завершении работы.

## Преимущества

Давайте обсудим некоторые преимущества использования очереди сообщений:

- **Масштабируемость**: Очереди сообщений позволяют масштабировать именно там, где это необходимо. При пиковых нагрузках несколько экземпляров нашего приложения могут добавлять все запросы в очередь без риска столкновения.
- **Отсоединение**: Очереди сообщений устраняют зависимости между компонентами и значительно упрощают реализацию разделенных приложений.
- **Производительность**: Очереди сообщений обеспечивают асинхронную связь, что означает, что конечные точки, производящие и потребляющие сообщения, взаимодействуют с очередью, а не друг с другом. Производители могут добавлять запросы в очередь, не дожидаясь их обработки.
- **Надежность**: Очереди делают наши данные постоянными и уменьшают количество ошибок, которые возникают, когда различные части нашей системы выходят из строя.

## Особенности

Теперь давайте обсудим некоторые необходимые функции очередей сообщений:

### Push or Pull Delivery

Большинство очередей сообщений предоставляют как push, так и pull варианты получения сообщений. Pull означает постоянное обращение к очереди за новыми сообщениями. Push означает, что потребитель получает уведомление, когда сообщение доступно. Мы также можем использовать long-polling, чтобы позволить потребителям ожидать поступления новых сообщений в течение определенного времени.

### Очереди FIFO (First-In-First-Out)

В таких очередях первой обрабатывается самая старая (или первая) запись, которую иногда называют "головой" очереди.

### Расписание или задержка доставки

Многие очереди сообщений поддерживают установку определенного времени доставки сообщения. Если нам нужна общая задержка для всех сообщений, мы можем настроить очередь задержки.

### Доставка по очереди (At-Least-Once Delivery)

Очереди сообщений могут хранить несколько копий сообщений для обеспечения избыточности и высокой доступности, а также повторно отправлять сообщения в случае сбоев или ошибок связи, чтобы обеспечить их доставку хотя бы один раз.

### Exactly-Once Delivery

Когда дубликаты недопустимы, очереди сообщений FIFO (first-in-first-out) обеспечивают доставку каждого сообщения ровно один раз (и только один), автоматически отсеивая дубликаты.

### Очереди с мертвой буквой (Dead-letter Queues)

Очередь с мертвой буквой (DLQ) - это очередь, в которую другие очереди могут отправлять сообщения, которые не могут быть успешно обработаны. Это позволяет легко отложить их для дальнейшей проверки, не блокируя обработку очереди и не тратя циклы процессора на сообщение, которое, возможно, никогда не будет успешно обработано.

### Упорядочивание

Большинство очередей сообщений обеспечивают упорядочивание по принципу best-effort, что гарантирует доставку сообщений в том же порядке, в каком они были отправлены, и что сообщение будет доставлено хотя бы один раз.

### Сообщения с ядовитыми таблетками

Ядовитые таблетки - это специальные сообщения, которые могут быть получены, но не обработаны. Они являются механизмом, используемым для того, чтобы сигнализировать потребителю о завершении его работы, чтобы он больше не ждал новых входных данных, и похожи на закрытие сокета в модели клиент/сервер.

### Безопасность

Очереди сообщений аутентифицируют приложения, которые пытаются получить доступ к очереди. Это позволяет нам шифровать сообщения по сети, а также в самой очереди.

### Очереди задач

Очереди задач получают задания и связанные с ними данные, выполняют их, а затем доставляют результаты. Они могут поддерживать планирование и использоваться для выполнения вычислительно-интенсивных заданий в фоновом режиме.

## Обратное давление

Если очереди начинают сильно разрастаться, их размер может превысить объем памяти, что приведет к пропуску кэша, чтению с диска и еще большему снижению производительности. Обратное давление может помочь, ограничив размер очереди, тем самым поддерживая высокую пропускную способность и хорошее время отклика для заданий, уже находящихся в очереди. Когда очередь заполняется, клиенты получают сообщение о занятости сервера или код состояния HTTP 503, чтобы повторить попытку позже. Клиенты могут повторить запрос в более позднее время, возможно, с помощью стратегии [экспоненциального отката](https://en.wikipedia.org/wiki/Exponential_backoff).

## Примеры

Ниже приведены некоторые широко используемые очереди сообщений:

- [Amazon SQS](https://aws.amazon.com/sqs)
- [RabbitMQ](https://www.rabbitmq.com)
- [ActiveMQ](https://activemq.apache.org)
- [ZeroMQ](https://zeromq.org)

# Publish-Subscribe

Подобно очереди сообщений, публикация-подписка также является формой связи между сервисами, которая обеспечивает асинхронное взаимодействие. В модели pub/sub любое сообщение, опубликованное в теме, немедленно рассылается всем подписчикам этой темы.

![publish-subscribe](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/publish-subscribe/publish-subscribe.png)

Подписчики темы сообщения часто выполняют разные функции, и каждый из них может параллельно делать с сообщением что-то свое. Издателю не нужно знать, кто использует передаваемую им информацию, а подписчикам не нужно знать, откуда пришло сообщение. Такой стиль обмена сообщениями немного отличается от очередей сообщений, где компонент, отправляющий сообщение, часто знает, кому оно отправляется.

## Устройство

В отличие от очередей сообщений, которые хранят сообщения до тех пор, пока они не будут получены, темы сообщений передают сообщения практически без очереди и сразу же рассылают их всем подписчикам. Вот как это работает:

- Тема сообщений предоставляет легкий механизм для передачи асинхронных уведомлений о событиях и конечные точки, которые позволяют программным компонентам подключаться к теме для отправки и получения этих сообщений.
- Чтобы передать сообщение, компонент, называемый _издателем_, просто отправляет сообщение в тему.
- Все компоненты, подписанные на эту тему (известные как _подписчики_), получат каждое сообщение, которое было передано.

## Преимущества

Давайте обсудим некоторые преимущества использования publish-subscribe:

- **Устранение опроса**: Темы сообщений обеспечивают мгновенную доставку на основе push, устраняя необходимость для потребителей сообщений периодически проверять или _"опрашивать"_ новую информацию и обновления. Это способствует ускорению времени отклика и уменьшению задержки доставки, которая может быть особенно проблематичной в системах, где задержки недопустимы.
- **Динамическое нацеливание**: Pub/Sub делает процесс обнаружения сервисов более простым, естественным и менее подверженным ошибкам. Вместо того чтобы вести реестр пиров, которым приложение может отправлять сообщения, издатель просто публикует сообщения в теме. Затем любая заинтересованная сторона подписывает свою конечную точку на эту тему и начинает получать эти сообщения. Подписчики могут меняться, обновляться, множиться или исчезать, и система динамически подстраивается.
- **Разделённое и независимое масштабирование**: Издатели и подписчики разделены и работают независимо друг от друга, что позволяет нам развивать и масштабировать их независимо друг от друга.
- **Упрощение коммуникации**: Модель Publish-Subscribe снижает сложность, устраняя все соединения "точка-точка" с помощью одного соединения с темой сообщений, которая будет управлять подписками и решать, какие сообщения должны быть доставлены на конечные точки.

## Features

Теперь давайте обсудим некоторые необходимые функции publish-subscribe:

### Push Delivery

Сообщения Pub/Sub мгновенно отправляют асинхронные уведомления о событиях, когда сообщения публикуются в теме сообщения. Подписчики получают уведомления, когда сообщение становится доступным.

### Несколько протоколов доставки

В модели Publish-Subscribe темы, как правило, могут подключаться к нескольким типам конечных точек, таким как очереди сообщений, бессерверные функции, HTTP-серверы и т. д.

### Fanout

В этом случае сообщение отправляется в тему, а затем реплицируется и рассылается по нескольким конечным точкам. Fanout обеспечивает асинхронные уведомления о событиях, что, в свою очередь, позволяет выполнять параллельную обработку.

### Фильтрация

Эта функция позволяет подписчику создать политику фильтрации сообщений, чтобы он получал только те уведомления, которые его интересуют, а не все сообщения, опубликованные в данной теме.

### Долговечность

Службы обмена сообщениями Pub/Sub часто обеспечивают очень высокую долговечность и, по крайней мере, однократную доставку, храня копии одного и того же сообщения на нескольких серверах.

### Безопасность

Темы сообщений аутентифицируют приложения, которые пытаются опубликовать содержимое, что позволяет нам использовать зашифрованные конечные точки и шифровать сообщения при передаче по сети.

## Примеры

Вот некоторые часто используемые технологии публикации-подписки:

- [Amazon SNS](https://aws.amazon.com/sns)
- [Google Pub/Sub](https://cloud.google.com/pubsub)

# Enterprise Service Bus (ESB)

Сервисная шина предприятия (ESB) - это архитектурный паттерн, в котором централизованный программный компонент выполняет интеграцию между приложениями. Он выполняет преобразования моделей данных, управляет связью, выполняет маршрутизацию сообщений, преобразует протоколы связи и потенциально управляет композицией нескольких запросов. ESB может сделать эти интеграции и преобразования доступными в виде сервисного интерфейса для повторного использования новыми приложениями.

![enterprise-service-bus](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/enterprise-service-bus/enterprise-service-bus.png)

## Преимущества

Теоретически централизованная ESB позволяет стандартизировать и значительно упростить связь, обмен сообщениями и интеграцию между службами в масштабах предприятия. Вот некоторые преимущества использования ESB:

- **Повышение производительности разработчиков**: Позволяет разработчикам внедрять новые технологии в одну часть приложения, не затрагивая остальные части приложения.
- **Упрощенная и экономически эффективная масштабируемость**: Компоненты можно масштабировать независимо от других.
- **Большая отказоустойчивость**: Отказ одного компонента не влияет на остальные, и каждый микросервис может придерживаться собственных требований к доступности, не рискуя доступностью других компонентов системы.

## Недостатки

Хотя ESB были успешно внедрены во многих организациях, во многих других организациях ESB стали рассматривать как узкое место. Вот некоторые недостатки использования ESB:

- Внесение изменений или усовершенствований в одну интеграцию может дестабилизировать работу других, использующих эту же интеграцию.
- Единая точка отказа может вывести из строя все коммуникации.
- Обновления ESB часто влияют на существующие интеграции, поэтому для выполнения любого обновления требуется значительное тестирование.
- ESB управляется централизованно, что затрудняет взаимодействие между командами.
- Высокая сложность конфигурации и обслуживания.

## Примеры

Ниже приведены некоторые широко используемые технологии Enterprise Service Bus (ESB):

- [Azure Service Bus](https://azure.microsoft.com/en-in/services/service-bus)
- [IBM App Connect](https://www.ibm.com/in-en/cloud/app-connect)
- [Apache Camel](https://camel.apache.org)
- [Fuse ESB](https://www.redhat.com/en/technologies/jboss-middleware/fuse)

# Монолиты и микросервисы

## Монолиты

Монолит - это самодостаточное и независимое приложение. Оно создается как единое целое и отвечает не только за конкретную задачу, но и может выполнять все шаги, необходимые для удовлетворения бизнес-потребностей.

![monolith](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/monolith.png)

### Преимущества

Ниже перечислены некоторые преимущества монолитов:

- Простота разработки и отладки.
- Быстрая и надежная связь.
- Легкий мониторинг и тестирование.
- Поддержка ACID-транзакций.

### Недостатки

К общим недостаткам монолитов относятся:

- Сложность сопровождения по мере роста кодовой базы.
- Жестко связанное приложение, трудно расширяемое.
- Требуется приверженность определенному технологическому стеку.
- При каждом обновлении все приложение развертывается заново.
- Снижение надежности, поскольку одна ошибка может вывести из строя всю систему.
- Сложно масштабировать или внедрять новые технологии.

## Модульные монолиты

Модульный монолит - это подход, при котором мы создаем и развертываем одно приложение (это часть _монолита_), но строим его таким образом, что разбиваем код на независимые модули для каждой из функций, необходимых в нашем приложении.

Такой подход уменьшает зависимости модуля таким образом, что мы можем улучшать или изменять модуль, не затрагивая другие модули. При правильном подходе это может быть очень полезно в долгосрочной перспективе, так как снижает сложность, возникающую при поддержке монолита по мере роста системы.

## Микросервисы

Архитектура микросервисов состоит из набора небольших автономных сервисов, каждый из которых является самодостаточным и должен реализовывать одну бизнес-возможность в ограниченном контексте. Ограниченный контекст - это естественное разделение бизнес-логики, которое обеспечивает явную границу, в пределах которой существует модель домена.

![Микросервисы](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/microservices.png)

Каждый сервис имеет отдельную кодовую базу, которая может управляться небольшой командой разработчиков. Сервисы могут быть развернуты независимо друг от друга, и команда может обновлять существующий сервис без перестройки и развертывания всего приложения.

Сервисы отвечают за сохранение своих собственных данных или внешнего состояния (база данных для каждого сервиса). Это отличается от традиционной модели, в которой за сохранение данных отвечает отдельный слой данных.

### Характеристики

Стиль архитектуры микросервисов имеет следующие характеристики:

- **Свободно соединенные**: Сервисы должны быть слабо связаны друг с другом, чтобы их можно было независимо развертывать и масштабировать. Это приведет к децентрализации команд разработчиков и, таким образом, позволит им быстрее разрабатывать и внедрять сервисы с минимальными ограничениями и операционными зависимостями.
- **Мало, но целенаправленно**: Речь идет о масштабе и ответственности, а не о размере. Сервис должен быть ориентирован на решение конкретной проблемы. По сути, _"он делает одно дело и делает его хорошо"_. В идеале они могут быть независимы от базовой архитектуры.
- **Созданы для бизнеса**: Архитектура микросервисов обычно строится вокруг возможностей и приоритетов бизнеса.
- **Устойчивость и отказоустойчивость**: Сервисы должны быть спроектированы таким образом, чтобы они продолжали функционировать в случае сбоев или ошибок. В средах с независимо развертываемыми сервисами отказоустойчивость имеет первостепенное значение.
- **Высокая ремонтопригодность**: Сервисы должны быть просты в обслуживании и тестировании, поскольку сервисы, которые невозможно обслуживать, будут переписаны.

### Преимущества

Вот некоторые преимущества архитектуры микросервисов:

- Свободно связанные сервисы.
- Сервисы могут быть развернуты независимо друг от друга.
- Высокая гибкость для нескольких команд разработчиков.
- Повышение отказоустойчивости и изоляции данных.
- Лучшая масштабируемость, поскольку каждый сервис может быть масштабирован независимо.
- Исключается долгосрочная привязка к определенному технологическому стеку.

### Недостатки

Архитектура микросервисов имеет свой собственный набор проблем:

- Сложность распределенной системы.
- Тестирование сложнее.
- Дорогое обслуживание (отдельные серверы, базы данных и т. д.).
- Межсервисное взаимодействие имеет свои сложности.
- Целостность и непротиворечивость данных.
- Перегруженность сети и задержки.

### Лучшие практики

Давайте обсудим некоторые лучшие практики работы с микросервисами:

- Моделируйте сервисы вокруг бизнес-области.
- Сервисы должны иметь свободное соединение и высокую функциональную связность.
- Изолируйте сбои и используйте стратегии отказоустойчивости, чтобы предотвратить каскадное распространение сбоев внутри сервиса.
- Сервисы должны взаимодействовать только через хорошо спроектированные API. Избегайте утечки деталей реализации.
- Хранение данных должно быть приватным для сервиса, которому они принадлежат.
- Избегайте сцепления между сервисами. Причинами сцепления являются общие схемы баз данных и жесткие протоколы взаимодействия.
- Децентрализуйте все. За проектирование и создание сервисов отвечают отдельные команды. Избегайте совместного использования кода или схем данных.
- Отказывайте быстро, используя [автоматический выключатель](https://karanpratapsingh.com/courses/system-design/circuit-breaker) для достижения отказоустойчивости.
- Обеспечьте обратную совместимость изменений API.

### Подводные камни

Ниже перечислены некоторые распространенные подводные камни архитектуры микросервисов:

- Границы сервисов не основаны на бизнес-сфере.
- Недооценка того, насколько сложно построить распределенную систему.
- Общая база данных или общие зависимости между сервисами.
- Отсутствие согласованности с бизнесом.
- Отсутствие четкого владения.
- Отсутствие идемпотентности.
- Попытка сделать все [ACID вместо BASE](https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models).
- Отсутствие проектирования для обеспечения отказоустойчивости может привести к каскадным отказам.

## Остерегайтесь распределенного монолита

Распределенный монолит - это система, напоминающая архитектуру микросервисов, но тесно связанная внутри себя, как монолитное приложение. Принятие архитектуры микросервисов имеет массу преимуществ. Но при создании такой архитектуры велика вероятность того, что в итоге мы получим распределенный монолит.

Наши микросервисы - это просто распределенный монолит, если к ним применимо хотя бы одно из этих условий:

- Требуются коммуникации с низкой задержкой.
- Сервисы нелегко масштабируются.
- Зависимость между сервисами.
- Совместное использование одних и тех же ресурсов, например баз данных.
- Жестко связанные системы.

Одна из основных причин создания приложения с использованием архитектуры микросервисов - это масштабируемость. Поэтому микросервисы должны иметь слабосвязанные сервисы, которые позволяют каждому сервису быть независимым. Распределенная монолитная архитектура лишает нас этой возможности и заставляет большинство компонентов зависеть друг от друга, увеличивая сложность проектирования.

## Микросервисы против сервис-ориентированной архитектуры (SOA)

Вы могли видеть, как _сервис-ориентированная архитектура (SOA)_ упоминается в интернете, иногда даже взаимозаменяемо с микросервисами, но они отличаются друг от друга, и главное различие между этими двумя подходами сводится к _скопу_.

Сервисно-ориентированная архитектура (SOA) определяет способ сделать программные компоненты многократно используемыми с помощью сервисных интерфейсов. Эти интерфейсы используют общие стандарты взаимодействия и нацелены на максимальное повторное использование сервисов приложения, в то время как микросервисы строятся как набор различных мелких независимых сервисных единиц, ориентированных на автономность и разделение команд.

## Почему вам не нужны микросервисы

![architecture-range](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/architecture-range.png)

Итак, вы, возможно, задаетесь вопросом: монолиты кажутся плохой идеей с самого начала, почему кто-то должен их использовать?

Ну, это зависит от ситуации. Хотя у каждого подхода есть свои преимущества и недостатки, при построении новой системы рекомендуется начинать с монолита. Важно понимать, что микросервисы - это не серебряная пуля, вместо этого они решают организационную проблему. Архитектура микросервисов зависит от приоритетов вашей организации и команды в той же степени, что и технология.

Прежде чем принять решение о переходе на архитектуру микросервисов, необходимо задать себе такие вопросы, как:

- "Не слишком ли велика команда для эффективной работы над общей кодовой базой?
- Не блокируются ли команды другими командами?
- "Обеспечивают ли микросервисы явную ценность для бизнеса?"
- Достаточно ли развит мой бизнес для использования микросервисов?
- Не ограничивает ли нас текущая архитектура накладными расходами на коммуникации?

Если ваше приложение не требует разбиения на микросервисы, вам это не нужно. Не существует абсолютной необходимости в том, чтобы все приложения разбивались на микросервисы.

Мы часто черпаем вдохновение в таких компаниях, как Netflix, и их использовании микросервисов, но упускаем из виду, что мы - не Netflix. Они прошли через множество итераций и моделей, прежде чем у них появилось готовое решение для рынка, и эта архитектура стала для них приемлемой, когда они определили и решили проблему, которую пытались решить.

Вот почему важно глубоко понять, действительно ли вашему бизнесу нужны микросервисы. Я пытаюсь сказать, что микросервисы - это решения сложных проблем, и если у вашего бизнеса нет сложных проблем, то они вам не нужны.

# Event-Driven Architecture (EDA)

Архитектура, управляемая событиями (Event-Driven Architecture, EDA), - это использование событий в качестве способа взаимодействия внутри системы. Как правило, используется брокер сообщений для асинхронной публикации и потребления событий. Издатель не знает, кто потребляет событие, а потребители не знают друг о друге. Архитектура, управляемая событиями, - это просто способ достижения свободной связи между сервисами в системе.

## Что такое событие?

Событие - это точка данных, которая представляет собой изменение состояния системы. Оно не определяет, что должно произойти и как это изменение должно изменить систему, оно лишь уведомляет систему о конкретном изменении состояния. Когда пользователь совершает действие, он запускает событие.

## Компоненты

Архитектуры, управляемые событиями, состоят из трех ключевых компонентов:

- **Производители событий**: Публикуют событие в маршрутизатор.
- **Маршрутизаторы событий**: Фильтруют и передают события потребителям.
- **Потребители событий**: Используют события для отражения изменений в системе.

![event-driven-architecture](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-driven-architecture/event-driven-architecture.png)

Примечание: Точки на диаграмме обозначают различные события в системе.

## Паттерны

Существует несколько способов реализации событийно-управляемой архитектуры, и то, какой метод мы используем, зависит от конкретного случая, но вот несколько общих примеров:

- [Sagas](https://karanpratapsingh.com/courses/system-design/distributed-transactions#sagas)
- [Publish-Subscribe](https://karanpratapsingh.com/courses/system-design/publish-subscribe)
- [Event Sourcing](https://karanpratapsingh.com/courses/system-design/event-sourcing)
- [Command and Query Responsibility Segregation (CQRS)](https://karanpratapsingh.com/courses/system-design/command-and-query-responsibility-segregation)

Примечание: каждый из этих методов рассматривается отдельно.

## Преимущества

Давайте обсудим некоторые преимущества:

- Разделенные производители и потребители.
- Высокая масштабируемость и распределенность.
- Легко добавлять новых потребителей.
- Повышает гибкость.

## Проблемы

Вот некоторые проблемы архитектуры event-drive:

- Гарантированная доставка.
- Сложность обработки ошибок.
- Системы, управляемые событиями, в целом сложны.
- Обработка событий в порядке очереди.

## Примеры использования

Ниже приведены некоторые распространенные случаи использования, когда архитектуры, управляемые событиями, оказываются полезными:

- Метаданные и метрики.
- Журналы серверов и систем безопасности.
- Интеграция разнородных систем.
- Веерная и параллельная обработка.

## Примеры

Вот несколько широко используемых технологий для реализации событийно-управляемых архитектур:

- [NATS](https://nats.io)
- [Apache Kafka](https://kafka.apache.org)
- [Amazon EventBridge](https://aws.amazon.com/eventbridge)
- [Amazon SNS](https://aws.amazon.com/sns)
- [Google PubSub](https://cloud.google.com/pubsub)

# Event Sourcing

Вместо того чтобы хранить только текущее состояние данных в домене, используйте хранилище, работающее только с приложениями, для записи всей серии действий, выполняемых над этими данными. Хранилище действует как система записей и может быть использовано для материализации объектов домена.

![event-sourcing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-sourcing/event-sourcing.png)

Это может упростить задачи в сложных доменах, избавив от необходимости синхронизировать модель данных и бизнес-домен, а также повысить производительность, масштабируемость и скорость реагирования. Кроме того, это может обеспечить согласованность транзакционных данных, а также поддерживать полные журналы аудита и историю, что может позволить принять компенсирующие меры.

## Event sourcing vs Event-Driven Architecture (EDA)

Кажется, что ивент-сорсинг постоянно путают с [Event-driven Architecture (EDA)](https://karanpratapsingh.com/courses/system-design/event-driven-architecture). Событийно-управляемая архитектура - это использование событий для связи между границами сервисов. Как правило, используется брокер сообщений для асинхронной публикации и потребления событий в пределах других границ.

В то время как событийная архитектура предполагает использование событий в качестве состояния, что представляет собой другой подход к хранению данных. Вместо того чтобы хранить текущее состояние, мы будем хранить события. Кроме того, сорсинг событий - это один из нескольких паттернов для реализации событийно-ориентированной архитектуры.

## Преимущества

Давайте обсудим некоторые преимущества использования событийного сорсинга:

- Отлично подходит для создания отчетов в реальном времени.
- Отлично подходит для обеспечения отказоустойчивости, данные могут быть восстановлены из хранилища событий.
- Чрезвычайная гибкость, можно хранить сообщения любого типа.
- Предпочтительный способ обеспечения функциональности журналов аудита для систем с высоким уровнем соответствия.

## Недостатки

Ниже перечислены недостатки событийного сорсинга:

- Требуется чрезвычайно эффективная сетевая инфраструктура.
- Требуется надежный способ контроля форматов сообщений, например реестр схем.
- Различные события будут содержать различную полезную нагрузку.

# Command and Query Responsibility Segregation (CQRS)

Разделение ответственности команд и запросов (Command Query Responsibility Segregation, CQRS) - это архитектурный паттерн, который разделяет действия системы на команды и запросы. Впервые он был описан [Greg Young](https://twitter.com/gregyoung).

В CQRS _команда_ - это инструкция, директива для выполнения определенной задачи. Она представляет собой намерение изменить что-то и не возвращает значения, а лишь указывает на успех или неудачу. А _запрос_ - это запрос информации, который не изменяет состояние системы и не вызывает никаких побочных эффектов.

![command-and-query-responsibility-segregation](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/command-and-query-responsibility-segregation/command-and-query-responsibility-segregation.png)

Основной принцип CQRS - разделение команд и запросов. Они выполняют принципиально разные роли в системе, и их разделение означает, что каждая из них может быть оптимизирована по мере необходимости, что очень полезно для распределенных систем.

## CQRS с Event Sourcing

Паттерн CQRS часто используется вместе с паттерном Event Sourcing. Системы на основе CQRS используют отдельные модели данных для чтения и записи, каждая из которых предназначена для выполнения соответствующих задач и часто располагается в физически отдельных хранилищах.

При использовании паттерна Event Sourcing хранилище событий представляет собой модель записи и является официальным источником информации. Модель чтения в системе на основе CQRS обеспечивает материализованные представления данных, обычно в виде сильно денормализованных представлений.

## Преимущества

Давайте обсудим некоторые преимущества CQRS:

- Позволяет независимо масштабировать рабочие нагрузки чтения и записи.
- Более легкое масштабирование, оптимизация и изменение архитектуры.
- Близость к бизнес-логике благодаря свободному соединению.
- Приложение может избежать сложных соединений при запросах.
- Четкие границы между поведением системы.

## Недостатки

Ниже перечислены некоторые недостатки CQRS:

- Более сложный дизайн приложения.
- Возможны сбои в передаче сообщений или дублирование сообщений.
- Решение проблемы конечной согласованности является сложной задачей.
- Увеличение объема работ по обслуживанию системы.

## Сценарии использования

Вот несколько сценариев, в которых CQRS будет полезен:

- Производительность чтения данных должна настраиваться отдельно от производительности записи данных.
- Предполагается, что система будет развиваться с течением времени и может содержать несколько версий модели, или в ней регулярно меняются бизнес-правила.
- Интеграция с другими системами, особенно в сочетании с событийными источниками, когда временный отказ одной подсистемы не должен влиять на доступность других.
- Повышение безопасности, чтобы гарантировать, что только правильные доменные сущности выполняют запись в данные.

# API Gateway

Шлюз API - это инструмент управления API, который находится между клиентом и набором внутренних сервисов. Это единая точка входа в систему, которая инкапсулирует внутреннюю архитектуру системы и предоставляет API, адаптированный для каждого клиента. На него также возлагаются другие обязанности, такие как аутентификация, мониторинг, балансировка нагрузки, кэширование, дросселирование, ведение логов и т. д.

![api-gateway](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/api-gateway.png)

## Зачем нам нужен API-шлюз?

Гранулярность API, предоставляемых микросервисами, часто отличается от того, что нужно клиенту. Микросервисы обычно предоставляют мелкозернистые API, что означает, что клиентам необходимо взаимодействовать с несколькими сервисами. Поэтому API-шлюз может обеспечить единую точку входа для всех клиентов с некоторыми дополнительными возможностями и лучшим управлением.

## Особенности

Ниже перечислены некоторые необходимые функции API-шлюза:

- Аутентификация и авторизация
- [Обнаружение услуг](https://karanpratapsingh.com/courses/system-design/service-discovery)
- [Обратный прокси](https://karanpratapsingh.com/courses/system-design/proxy#reverse-proxy)
- [Кэширование](https://karanpratapsingh.com/courses/system-design/caching)
- Безопасность
- Повторные попытки и [Разрыв цепи](https://karanpratapsingh.com/courses/system-design/circuit-breaker)
- [Балансировка нагрузки](https://karanpratapsingh.com/courses/system-design/load-balancing)
- Протоколирование, трассировка
- Состав API
- [Ограничение скорости](https://karanpratapsingh.com/courses/system-design/rate-limiting) и дросселирование
- Версионирование
- Маршрутизация
- Белые или черные списки IP-адресов

## Преимущества

Давайте рассмотрим некоторые преимущества использования API-шлюза:

- Инкапсулирует внутреннюю структуру API.
- Обеспечивает централизованное представление API.
- Упрощает клиентский код.
- Мониторинг, аналитика, трассировка и другие подобные функции.

## Недостатки

Вот некоторые возможные недостатки API-шлюза:

- Возможность возникновения единой точки отказа.
- Может повлиять на производительность.
- Может стать узким местом при неправильном масштабировании.
- Конфигурация может быть сложной.

## Паттерн Backend For Frontend (BFF)

В паттерне Backend For Frontend (BFF) мы создаем отдельные сервисы бэкенда, которые будут потребляться определенными приложениями или интерфейсами фронтенда. Этот паттерн полезен, когда мы хотим избежать настройки одного бэкенда для нескольких интерфейсов. Впервые этот паттерн был описан [Sam Newman](https://samnewman.io).

Кроме того, иногда данные, возвращаемые микросервисами на фронтенд, не имеют того формата или не фильтруются так, как нужно фронтенду. Чтобы решить эту проблему, фронтенд должен иметь некоторую логику для переформатирования данных, и поэтому мы можем использовать BFF для переноса части этой логики на промежуточный слой.

![backend-for-frontend](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/backend-for-frontend.png)

Основная функция бэкенда для шаблона фронтенда - получить необходимые данные из соответствующего сервиса, отформатировать их и отправить на фронтенд.

В качестве бэкенда для фронтенда (BFF) очень хорошо работает _[GraphQL](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#graphql).

### Когда использовать этот паттерн?

Мы должны рассмотреть возможность использования паттерна Backend For Frontend (BFF), когда:

- Необходимо поддерживать общий или универсальный бэкенд-службу со значительными накладными расходами на разработку.
- Мы хотим оптимизировать бэкенд под требования конкретного клиента.
- В бэкенд общего назначения вносятся изменения, чтобы обеспечить работу с несколькими интерфейсами.

## Примеры

Ниже приведены некоторые широко используемые технологии шлюзов:

- [Amazon API Gateway](https://aws.amazon.com/api-gateway)
- [Apigee API Gateway](https://cloud.google.com/apigee)
- [Azure API Gateway](https://azure.microsoft.com/en-in/services/api-management)
- [Kong API Gateway](https://konghq.com/kong)

# REST, GraphQL, gRPC

Хороший дизайн API всегда является важной частью любой системы. Но также важно выбрать правильную технологию API. Поэтому в этом руководстве мы кратко рассмотрим различные технологии API, такие как REST, GraphQL и gRPC.

## Что такое API?

Прежде чем перейти к технологиям API, давайте сначала разберемся, что такое API.

API расшифровывается как интерфейс прикладного программирования. Это набор определений и протоколов для создания и интеграции прикладного программного обеспечения. Иногда его называют контрактом между поставщиком и пользователем информации, в котором указывается содержание, требуемое производителем, и содержание, требуемое потребителем.

Другими словами, если вы хотите взаимодействовать с компьютером или системой для получения информации или выполнения какой-либо функции, API поможет вам передать системе то, что вы хотите, чтобы она могла понять и выполнить запрос.

## REST

API [REST](https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm) (также известный как RESTful API) - это интерфейс прикладного программирования, который соответствует ограничениям архитектурного стиля REST и позволяет взаимодействовать с RESTful веб-сервисами. REST расшифровывается как Representational State Transfer и впервые был представлен [Roy Fielding](https://roy.gbiv.com) в 2000 году.

_В REST API основной единицей является ресурс._

### Концепции

Давайте обсудим некоторые концепции RESTful API.

**Ограничения**.

Для того чтобы API считался _RESTful_, он должен соответствовать следующим архитектурным ограничениям:

- **Единый интерфейс**: Должен существовать единый способ взаимодействия с определенным сервером.
- **Клиент-сервер**: Клиент-серверная архитектура, управляемая через HTTP.
- **Stateless**: Контекст клиента не должен храниться на сервере между запросами.
- **Cacheable**: Каждый ответ должен содержать информацию о том, является ли ответ кэшируемым или нет, и в течение какого времени ответы могут быть кэшированы на стороне клиента.
- **Слоистая система**: Архитектура приложения должна состоять из нескольких уровней.
- **Код по требованию**: Возвращение исполняемого кода для поддержки части вашего приложения. (необязательно)_

**Глаголы HTTP**.

HTTP определяет набор методов запроса для указания желаемого действия, которое должно быть выполнено для данного ресурса. Хотя они могут быть и существительными, эти методы запроса иногда называют _HTTP-главами_. Каждый из них реализует свою семантику, но некоторые общие черты разделяет группа этих методов.

Ниже приведены некоторые часто используемые глаголы HTTP:

- **GET**: Запрос представления указанного ресурса.
- **HEAD**: Ответ идентичен запросу `GET`, но без тела ответа.
- **POST**: Отправляет сущность на указанный ресурс, часто вызывая изменение состояния или побочные эффекты на сервере.
- **PUT**: Заменяет все текущие представления целевого ресурса на полезную нагрузку запроса.
- **DELETE**: Удаляет указанный ресурс.
- **PATCH**: Применяет частичные модификации к ресурсу.

**Коды ответов HTTP**

[Коды статуса ответа HTTP] (https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) указывают, был ли успешно выполнен определенный HTTP-запрос.

В стандарте определено пять классов:

- 1xx - информационные ответы.
- 2xx - успешные ответы.
- 3xx - ответы о перенаправлении.
- 4xx - ответы об ошибках клиента.
- 5xx - ответы об ошибках сервера.

Например, HTTP 200 означает, что запрос был выполнен успешно.

### Преимущества

Давайте обсудим некоторые преимущества REST API:

- Простой и понятный.
- Гибкость и портативность.
- Хорошая поддержка кэширования.
- Клиент и сервер разделены.

### Недостатки

Давайте обсудим некоторые недостатки REST API:

- Избыточная выборка данных.
- Иногда требуется несколько обращений к серверу.

### Примеры использования

REST API используются практически повсеместно и являются стандартом по умолчанию для разработки API. В целом REST API довольно гибкие и подходят практически для всех сценариев.

### Пример

Вот пример использования REST API, который работает с ресурсом **users**.

| URI | HTTP-глагол | Описание |
| ------------- | --------- | ------------------- |
| /users | GET | Получить всех пользователей |
| /users/\{id\} | GET | Получить пользователя по id |
| /users | POST | Добавить нового пользователя |
| /users/\{id\} | PATCH | Обновить пользователя по id |
| /users/\{id\} | DELETE | Удалить пользователя по id |

Я настоятельно рекомендую изучить [Hypermedia as the Engine of Application State (HATEOAS)](https://en.wikipedia.org/wiki/HATEOAS)._Так много еще предстоит узнать, когда речь идет о REST API.

## GraphQL

[GraphQL](https://graphql.org) - это язык запросов и серверная среда выполнения для API, приоритетом которой является предоставление клиентам именно тех данных, которые они запрашивают, и не более. Он был разработан [Facebook](https://engineering.fb.com) и позже, в 2015 году, стал открытым.

GraphQL призван сделать API быстрыми, гибкими и удобными для разработчиков. Кроме того, GraphQL дает разработчикам API возможность добавлять или упразднять поля, не влияя на существующие запросы. Разработчики могут создавать API с любыми методами, которые они предпочитают, а спецификация GraphQL обеспечит их предсказуемое функционирование для клиентов.

_В GraphQL основной единицей является запрос._

### Концепции

Давайте кратко обсудим некоторые ключевые понятия в GraphQL:

**Схема**.

Схема GraphQL описывает функциональность, которую клиенты могут использовать после подключения к серверу GraphQL.

**Запросы**.

Запрос - это запрос, сделанный клиентом. Он может состоять из полей и аргументов для запроса. Тип операции запроса также может быть [мутацией](https://graphql.org/learn/queries/#mutations), которая предоставляет возможность модифицировать данные на стороне сервера.

**Резольверы**.

Резольвер - это набор функций, которые генерируют ответы на GraphQL-запрос. Проще говоря, резолвер выступает в роли обработчика запросов GraphQL.

### Преимущества

Давайте обсудим некоторые преимущества GraphQL:

- Устранение избыточной выборки данных.
- Сильно определенная схема.
- Поддержка генерации кода.
- Оптимизация полезной нагрузки.

### Недостатки

Давайте обсудим некоторые недостатки GraphQL:

- Перенос сложности на сторону сервера.
- Кэширование становится затруднительным.
- Версионность неоднозначна.
- Проблема N+1.

### Примеры использования

GraphQL оказывается незаменимым в следующих сценариях:

- Сокращение пропускной способности приложения, так как мы можем запрашивать несколько ресурсов одним запросом.
- Быстрое создание прототипов для сложных систем.
- Когда мы работаем с графоподобной моделью данных.

### Пример

Вот схема GraphQL, определяющая тип `User` и тип `Query`.

```graphql
type Query {
  getUser: User
}

type User {
  id: ID
  name: String
  city: String
  state: String
}
```

Используя приведенную выше схему, клиент может легко запросить необходимые поля без необходимости получать весь ресурс или гадать, что может вернуть API.

```graphql
{
  getUser {
    id
    name
    city
  }
}
```

В результате клиент получит следующий ответ:

```json
{
  "getUser": {
    "id": 123,
    "name": "Karan",
    "city": "San Francisco"
  }
}
```

_Узнайте больше о GraphQL на [graphql.org](https://graphql.org)._

## gRPC

[gRPC](https://grpc.io) - это современный высокопроизводительный фреймворк с открытым исходным кодом [Remote Procedure Call (RPC)](https://en.wikipedia.org/wiki/Remote_procedure_call), который может работать в любой среде. Он может эффективно соединять сервисы в центрах обработки данных и между ними благодаря подключаемой поддержке балансировки нагрузки, трассировки, проверки работоспособности, аутентификации и многого другого.

### Концепции

Давайте обсудим некоторые ключевые понятия gRPC.

**Буферы протоколов**.

Буферы протоколов представляют собой нейтральный для языка и платформы расширяемый механизм для сериализации структурированных данных, совместимый как с прямыми, так и с обратными данными. Это похоже на JSON, только меньше и быстрее, и генерирует привязки к родным языкам.

**Определение сервиса**.

Как и многие другие системы RPC, gRPC основан на идее определения сервиса и указания методов, которые могут быть вызваны удаленно, с их параметрами и возвращаемыми типами. gRPC использует буферы протоколов в качестве [Interface Definition Language (IDL)](https://en.wikipedia.org/wiki/Interface_description_language) для описания как интерфейса сервиса, так и структуры сообщений полезной нагрузки.

### Преимущества

Давайте обсудим некоторые преимущества gRPC:

- Легкость и эффективность.
- Высокая производительность.
- Встроенная поддержка генерации кода.
- Двунаправленная потоковая передача.

### Недостатки

Давайте обсудим некоторые недостатки gRPC:

- Относительно новый по сравнению с REST и GraphQL.
- Ограниченная поддержка браузеров.
- Более сложная кривая обучения.
- Не читается человеком.

### Примеры использования

Ниже перечислены примеры использования gRPC:

- Общение в реальном времени с помощью двунаправленной потоковой передачи.
- Эффективное межсервисное взаимодействие в микросервисах.
- Коммуникация с низкой задержкой и высокой пропускной способностью.
- Полиглотские среды.

### Пример

Вот базовый пример сервиса gRPC, определенного в файле `*.proto`. Используя это определение, мы можем легко сгенерировать код сервиса `HelloService` на выбранном нами языке программирования.

```protobuf
service HelloService {
  rpc SayHello (HelloRequest) returns (HelloResponse);
}

message HelloRequest {
  string greeting = 1;
}

message HelloResponse {
  string reply = 1;
}
```

## REST vs GraphQL vs gRPC

Теперь, когда мы знаем, как работают эти техники проектирования API, давайте сравним их по следующим параметрам:

- Приведет ли это к тесному взаимодействию?
- Насколько _разговорчивы_ (отдельные вызовы API для получения необходимой информации) API?
- Какова производительность?
- Насколько сложна интеграция?
- Насколько хорошо работает кэширование?
- Встроенный инструментарий и генерация кода?
- Какова открываемость API?
- Насколько легко версифицировать API?

| Type | Coupling | Chattiness | Performance | Complexity | Caching | Codegen | Discoverability | Versioning |
| ------- | -------- | ---------- | ----------- | ---------- | ------- | ------- | --------------- | ---------- |
| REST | Низкий | Высокий | Хороший | Средний | Отличный | Плохой | Хороший | Легкий |
| GraphQL | Средний | Низкий | Хороший | Высокий | Пользовательский | Хороший | Хороший | Пользовательский |
| gRPC | Высокий | Средний | Большой | Низкий | Пользовательский | Большой | Плохой | Тяжелый |

### Какая технология API лучше?

Ответ - ни одна из них. Серебряной пули не существует, поскольку у каждой из этих технологий есть свои преимущества и недостатки. Пользователей волнует только последовательное использование наших API, поэтому при разработке API ориентируйтесь на свой домен и требования.

# Длинные опросы, WebSockets, события, отправляемые сервером (SSE)

Изначально веб-приложения разрабатывались по модели клиент-сервер, где веб-клиент всегда является инициатором транзакций, таких как запрос данных с сервера. Таким образом, не существовало механизма, позволяющего серверу самостоятельно отправлять данные клиенту без предварительного запроса со стороны клиента. Давайте обсудим некоторые подходы к решению этой проблемы.

## Длинный опрос

Длинный опрос HTTP - это техника, используемая для передачи клиенту информации с сервера как можно быстрее. В результате серверу не нужно ждать, пока клиент отправит запрос.

При длинном опросе сервер не закрывает соединение после получения запроса от клиента. Вместо этого сервер отвечает только в том случае, если доступно новое сообщение или достигнут порог таймаута.

![long-polling](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/long-polling.png)

Как только клиент получает ответ, он тут же отправляет новый запрос на сервер, чтобы получить новое ожидающее соединение для отправки данных клиенту, и операция повторяется. При таком подходе сервер эмулирует функцию push в реальном времени.

### Устройство

Давайте разберемся, как работает длинный опрос:

1. Клиент делает первоначальный запрос и ждет ответа.
2. Сервер получает запрос и откладывает отправку до тех пор, пока не появится обновление.
3. Как только обновление доступно, ответ отправляется клиенту.
4. Клиент получает ответ и сразу же или через определенный промежуток времени делает новый запрос, чтобы снова установить соединение.

### Преимущества

Вот некоторые преимущества длинного опроса:

- Простота реализации, подходит для небольших проектов.
- Почти повсеместная поддержка.

### Недостатки

Основной недостаток длинного опроса в том, что он обычно не масштабируется. Ниже перечислены некоторые другие причины:

- Каждый раз создается новое соединение, что может быть интенсивным для сервера.
- Надежность упорядочивания сообщений может стать проблемой при многократных запросах.
- Увеличение задержки, поскольку серверу приходится ждать нового запроса.

## WebSockets

WebSocket обеспечивает полнодуплексные каналы связи через одно TCP-соединение. Это постоянное соединение между клиентом и сервером, которое обе стороны могут использовать для отправки данных в любое время.

Клиент устанавливает соединение WebSocket с помощью процесса, известного как WebSocket handshake. Если процесс проходит успешно, то сервер и клиент могут обмениваться данными в обоих направлениях в любое время. Протокол WebSocket обеспечивает связь между клиентом и сервером с меньшими накладными расходами, облегчая передачу данных с сервера и на сервер в режиме реального времени.

![websockets](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/websockets.png)

Это стало возможным благодаря стандартизированному способу отправки сервером содержимого клиенту без запроса и возможности передачи сообщений туда и обратно при сохранении соединения открытым.

### Устройство

Давайте разберемся, как работают WebSockets:

1. Клиент инициирует процесс рукопожатия WebSocket, отправляя запрос.
2. Запрос также содержит заголовок [HTTP Upgrade](https://en.wikipedia.org/wiki/HTTP/1.1_Upgrade_header), который позволяет переключиться на протокол WebSocket (`ws://`).
3. Сервер отправляет ответ клиенту, подтверждая запрос WebSocket handshake.
4. Соединение WebSocket будет открыто, как только клиент получит успешный ответ на рукопожатие.
5. Теперь клиент и сервер могут начать отправлять данные в обоих направлениях, обеспечивая связь в реальном времени.
6. Соединение будет закрыто, как только сервер или клиент решит закрыть соединение.

### Преимущества

Ниже перечислены некоторые преимущества WebSockets:

- Полнодуплексный асинхронный обмен сообщениями.
- Лучшая модель безопасности на основе происхождения.
- Легкий вес как для клиента, так и для сервера.

### Недостатки

Давайте обсудим некоторые недостатки WebSockets:

- Прерванные соединения не восстанавливаются автоматически.
- Старые браузеры не поддерживают WebSockets (становится менее актуальным).

## События, отправляемые сервером (SSE)

Server-Sent Events (SSE) - это способ установления долгосрочной связи между клиентом и сервером, который позволяет серверу проактивно передавать данные клиенту.

![server-sent-events](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/server-sent-events.png)

Он является однонаправленным, то есть после отправки запроса клиент может только получать ответы, не имея возможности отправлять новые запросы по тому же соединению.

### Устройство

Давайте разберемся, как работают события, отправляемые сервером:

1. Клиент делает запрос к серверу.
2. Устанавливается соединение между клиентом и сервером, которое остается открытым.
3. Сервер отправляет ответы или события клиенту, когда появляются новые данные.

### Преимущества

- Простота реализации и использования как для клиента, так и для сервера.
- Поддерживается большинством браузеров.
- Нет проблем с брандмауэрами.

### Недостатки

- Однонаправленная природа может быть ограничивающей.
- Ограничение на максимальное количество открытых соединений.
- Не поддерживает двоичные данные.

# Geohashing and Quadtrees

# # Geohashing

Geohashing - это метод [геокодирования](https://en.wikipedia.org/wiki/Address_geocoding), используемый для кодирования географических координат, таких как широта и долгота, в короткие буквенно-цифровые строки. Он был создан [Gustavo Niemeyer](https://twitter.com/gniemeyer) в 2008 году.

Например, Сан-Франциско с координатами `37.7564, -122.4016` может быть представлен в геохеше как `9q8yy9mf`.

### Как работает геохеширование?

Geohash - это иерархический пространственный индекс, использующий кодировку алфавита Base-32. Первый символ в geohash идентифицирует начальное местоположение как одну из 32 ячеек. Эта ячейка также будет содержать 32 ячейки. Это означает, что для представления точки мир рекурсивно делится на все меньшие и меньшие ячейки с каждым дополнительным битом, пока не будет достигнута требуемая точность. Коэффициент точности также определяет размер ячейки.

![geohashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png)

Геохэширование гарантирует, что точки будут пространственно ближе, если их геохэши имеют более длинный префикс, то есть чем больше символов в строке, тем точнее местоположение. Например, геохэши `9q8yy9mf` и `9q8yy9vx` пространственно ближе, так как имеют общий префикс `9q8yy9`.

Геохеширование также может использоваться для обеспечения некоторой степени анонимности, поскольку нам не нужно раскрывать точное местоположение пользователя, так как в зависимости от длины геохеша мы просто знаем, что он находится в определенном районе.

Размеры ячеек геохэшей разной длины следующие:

| Длина Geohash | Ширина ячейки | Высота ячейки |
| -------------- | ---------- | ----------- |
| 1 | 5000 км | 5000 км |
| 2 | 1250 км | 1250 км |
| 3 | 156 км | 156 км |
| 4 | 39,1 км | 19,5 км |
| 5 | 4,89 км | 4,89 км |
6 | | 1,22 км | 0,61 км |
| 7 | 153 м | 153 м |
| 8 | 38,2 м | 19,1 м |
| 9 | 4,77 м | 4,77 м |
| 10 | 1,19 м | 0,596 м |
| 11 | 149 мм | 149 мм |
| 12 | 37,2 мм | 18,6 мм |

### Примеры использования

Вот несколько распространенных вариантов использования Geohashing:

- Это простой способ представления и хранения местоположения в базе данных.
- Им также можно делиться в социальных сетях в виде URL, поскольку им легче поделиться и запомнить, чем широту и долготу.
- Мы можем эффективно находить ближайших соседей точки с помощью очень простых сравнений строк и эффективного поиска по индексам.

### Примеры

Геохашинг широко используется и поддерживается популярными базами данных.

- [MySQL](https://www.mysql.com)
- [Redis](http://redis.io)
- [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
- [Google Cloud Firestore](https://cloud.google.com/firestore)

## Quadtrees.

Квадтри - это древовидная структура данных, в которой каждый внутренний узел имеет ровно четыре дочерних. Они часто используются для разбиения двумерного пространства путем рекурсивного деления его на четыре квадранта или области. Каждый дочерний или листовой узел хранит пространственную информацию. Квадтри - это двумерный аналог [Octrees](https://en.wikipedia.org/wiki/Octree), который используется для разбиения трехмерного пространства.

![quadtree](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png)

### Типы Quadtrees.

Квадродеревья можно классифицировать по типу данных, которые они представляют, включая области, точки, линии и кривые. Ниже перечислены распространенные типы квадтреков:

- Точечные квадтрики
- Квадтрики "точка-область" (PR)
- Квадтрики полигональной карты (PM)
- Сжатые квадтрики
- Краевые квадтрики

### Зачем нам нужны квадтрики?

Разве широты и долготы не достаточно? Зачем нам нужны квадтрики? Хотя теоретически, используя широту и долготу, мы можем определить, насколько близки точки друг к другу, используя [евклидово расстояние](https://en.wikipedia.org/wiki/Euclidean_distance), для практического использования этот метод просто не подходит, поскольку он требует больших затрат процессора при работе с большими наборами данных.

![quadtree-subdivision](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png)

Квадродеревья позволяют эффективно искать точки в двумерном диапазоне, где эти точки определены как координаты широты/долготы или как декартовы координаты (x, y). Кроме того, мы можем сэкономить на вычислениях, разбивая узел только после определенного порога. А применение алгоритмов отображения, таких как [кривая Гильберта] (https://en.wikipedia.org/wiki/Hilbert_curve), позволяет легко повысить производительность запросов к диапазонам.

### Примеры использования

Ниже перечислены некоторые распространенные случаи использования квадтри:

- Представление, обработка и сжатие изображений.
- Пространственное индексирование и запросы к диапазонам.
- Сервисы, основанные на местоположении, такие как Google Maps, Uber и т. д.
- Генерация сетки и компьютерная графика.
- Хранение разреженных данных.

# Автоматический выключатель (Circuit breaker)

Автоматический выключатель - это шаблон проектирования, используемый для обнаружения сбоев и заключающий в себе логику предотвращения постоянного повторения сбоя во время технического обслуживания, временного внешнего сбоя системы или неожиданных трудностей в работе системы.

![circuit-breaker](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/circuit-breaker/circuit-breaker.png)

Основная идея, лежащая в основе автоматического выключателя, очень проста. Мы оборачиваем вызов защищенной функции в объект автоматического выключателя, который отслеживает сбои. Как только количество отказов достигает определенного порога, выключатель срабатывает, и все дальнейшие обращения к нему возвращаются с ошибкой, при этом защищенный вызов вообще не выполняется. Как правило, при срабатывании автоматического выключателя нам также требуется какое-то оповещение монитора.

## Зачем нам нужен разрыв цепи?

Обычно программные системы выполняют удаленные вызовы программ, запущенных в разных процессах, возможно, на разных машинах в сети. Одно из главных различий между вызовами в памяти и удаленными вызовами заключается в том, что удаленные вызовы могут не работать или висеть без ответа до тех пор, пока не будет достигнут некоторый предел таймаута. Что еще хуже, так это то, что если у нас много абонентов на не отвечающем поставщике, то мы можем исчерпать критические ресурсы, что приведет к каскадным сбоям в нескольких системах.

## Состояния

Давайте обсудим состояния автоматического выключателя:

### Замкнуто

Когда все нормально, автоматические выключатели остаются закрытыми, и все запросы проходят через службы в обычном режиме. Если количество отказов превышает пороговое значение, автоматический выключатель срабатывает и переходит в открытое состояние.

### Open

В этом состоянии автоматический выключатель сразу же возвращает ошибку, даже не обращаясь к службам. Автоматические выключатели переходят в полуоткрытое состояние по истечении определенного времени ожидания. Как правило, в системе мониторинга указывается время ожидания.

### Полуоткрытое состояние

В этом состоянии автоматический выключатель пропускает через себя ограниченное количество запросов от службы и вызывает операцию. Если запросы будут успешными, то выключатель перейдет в закрытое состояние. Однако если запросы продолжают терпеть неудачу, то он возвращается в открытое состояние.

# Ограничение скорости

Ограничение скорости - это предотвращение превышения частоты операций над заданным пределом. В крупномасштабных системах ограничение скорости обычно используется для защиты базовых служб и ресурсов. Ограничение скорости обычно используется в качестве защитного механизма в распределенных системах, чтобы общие ресурсы могли поддерживать доступность. Оно также защищает наши API от непреднамеренного или злонамеренного чрезмерного использования, ограничивая количество запросов, которые могут поступить к нашему API за определенный период времени.

![rate-limiting](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/rate-limiting/rate-limiting.png)

## Зачем нам нужно ограничение скорости?

Ограничение скорости - очень важная часть любой крупномасштабной системы, и оно может быть использовано для достижения следующих целей:

- Избежать голодания ресурсов в результате атак типа "отказ в обслуживании" (DoS).
- Ограничение скорости помогает контролировать эксплуатационные расходы, устанавливая виртуальный лимит на автоматическое масштабирование ресурсов, которое, если за ним не следить, может привести к экспоненциальным счетам.
- Ограничение скорости может использоваться в качестве защиты или смягчения последствий некоторых распространенных атак.
- Для API, обрабатывающих огромные объемы данных, ограничение скорости может быть использовано для контроля потока этих данных.

## Алгоритмы

Существуют различные алгоритмы ограничения скорости API, каждый из которых имеет свои преимущества и недостатки. Давайте вкратце обсудим некоторые из этих алгоритмов:

### Leaky Bucket

Leaky Bucket - это алгоритм, который обеспечивает простой и интуитивно понятный подход к ограничению скорости с помощью очереди. При регистрации запроса система добавляет его в конец очереди. Обработка первого элемента в очереди происходит с регулярным интервалом или по принципу "первый пришел - первый ушел" (FIFO). Если очередь переполнена, то дополнительные запросы отбрасываются (или просачиваются).

### Token Bucket

Здесь мы используем концепцию _ведра_. Когда поступает запрос, токен из ведра должен быть взят и обработан. Если в ведре нет токена, запрос будет отклонен, и запросчику придется повторить попытку позже. В результате ведро токенов обновляется через определенный промежуток времени.

### Фиксированное окно

Система использует окно размером в `n` секунд для отслеживания скорости работы алгоритма с фиксированным окном. Каждый входящий запрос увеличивает счетчик для этого окна. Система отбрасывает запрос, если счетчик превышает пороговое значение.

### Скользящий журнал

Ограничение скорости по скользящему журналу включает в себя отслеживание журнала с временной меткой для каждого запроса. Система хранит эти журналы в хэш-наборе или таблице с временной сортировкой. Она также отбрасывает журналы с временными метками, превышающими пороговое значение. Когда поступает новый запрос, мы подсчитываем сумму журналов, чтобы определить частоту запросов. Если запрос превышает пороговое значение, то он задерживается.

### Скользящее окно

Sliding Window - это гибридный подход, который сочетает в себе низкую стоимость обработки алгоритма фиксированного окна и улучшенные граничные условия скользящего журнала. Как и в алгоритме фиксированного окна, мы отслеживаем счетчик для каждого фиксированного окна. Затем мы учитываем взвешенное значение частоты запросов предыдущего окна, основанное на текущей временной метке, чтобы сгладить всплески трафика.

## Ограничение скорости в распределенных системах

Ограничение скорости усложняется, когда речь идет о распределенных системах. Две основные проблемы, возникающие при ограничении скорости в распределенных системах, таковы:

### Несоответствия

При использовании кластера из нескольких узлов нам может потребоваться глобальная политика ограничения скорости. Поскольку если каждый узел будет отслеживать свой лимит скорости, потребитель может превысить глобальный лимит скорости при отправке запросов на разные узлы. Чем больше узлов, тем больше вероятность того, что пользователь превысит глобальный лимит.

Самый простой способ решить эту проблему - использовать липкие сессии в наших балансировщиках нагрузки, чтобы каждый потребитель отправлялся ровно на один узел, но это приводит к недостаточной отказоустойчивости и проблемам масштабирования. Другим подходом может быть использование централизованного хранилища данных, например [Redis](https://redis.io), но это приведет к увеличению задержек и возникновению условий гонки.

### Race Conditions

This issue happens when we use a naive _"get-then-set"_ approach, in which we retrieve the current rate limit counter, increment it, and then push it back to the datastore. This model's problem is that additional requests can come through in the time it takes to perform a full cycle of read-increment-store, each attempting to store the increment counter with an invalid (lower) counter value. This allows a consumer to send a very large number of requests to bypass the rate limiting controls.

One way to avoid this problem is to use some sort of distributed locking mechanism around the key, preventing any other processes from accessing or writing to the counter. Though the lock will become a significant bottleneck and will not scale well. A better approach might be to use a _"set-then-get"_ approach, allowing us to quickly increment and check counter values without letting the atomic operations get in the way.

# Service Discovery

Service discovery is the detection of services within a computer network. Service Discovery Protocol (SDP) is a networking standard that accomplishes the detection of networks by identifying resources.


## Why do we need Service Discovery?

In a monolithic application, services invoke one another through language-level methods or procedure calls. However, modern microservices-based applications typically run in virtualized or containerized environments where the number of instances of a service and their locations change dynamically. Consequently, we need a mechanism that enables the clients of service to make requests to a dynamically changing set of ephemeral service instances.

## Implementations

There are two main service discovery patterns:

### Client-side discovery

![client-side-service-discovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/client-side-service-discovery.png)

In this approach, the client obtains the location of another service by querying a service registry which is responsible for managing and storing the network locations of all the services.

### Server-side discovery

![server-side-service-discovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/server-side-service-discovery.png)

In this approach, we use an intermediate component such as a load balancer. The client makes a request to the service via a load balancer which then forwards the request to an available service instance.

## Service Registry

A service registry is basically a database containing the network locations of service instances to which the clients can reach out. A Service Registry must be highly available and up-to-date.

## Service Registration

We also need a way to obtain service information, often known as service registration. Let's look at two possible service registration approaches:

### Self-Registration

When using the self-registration model, a service instance is responsible for registering and de-registering itself in the Service Registry. In addition, if necessary, a service instance sends heartbeat requests to keep its registration alive.

### Third-party Registration

The registry keeps track of changes to running instances by polling the deployment environment or subscribing to events. When it detects a newly available service instance, it records it in its database. The Service Registry also de-registers terminated service instances.

## Service mesh

Service-to-service communication is essential in a distributed application but routing this communication, both within and across application clusters, becomes increasingly complex as the number of services grows. Service mesh enables managed, observable, and secure communication between individual services. It works with a service discovery protocol to detect services. [Istio](https://istio.io/latest/about/service-mesh) and [envoy](https://www.envoyproxy.io) are some of the most commonly used service mesh technologies.

## Examples

Here are some commonly used service discovery infrastructure tools:

- [etcd](https://etcd.io)
- [Consul](https://www.consul.io)
- [Apache Thrift](https://thrift.apache.org)
- [Apache Zookeeper](https://zookeeper.apache.org)

# SLA, SLO, SLI

Let's briefly discuss SLA, SLO, and SLI. These are mostly related to the business and site reliability side of things but good to know nonetheless.

## Why are they important?

SLAs, SLOs, and SLIs allow companies to define, track and monitor the promises made for a service to its users. Together, SLAs, SLOs, and SLIs should help teams generate more user trust in their services with an added emphasis on continuous improvement to incident management and response processes.

## SLA

An SLA, or Service Level Agreement, is an agreement made between a company and its users of a given service. The SLA defines the different promises that the company makes to users regarding specific metrics, such as service availability.

_SLAs are often written by a company's business or legal team._

## SLO

An SLO, or Service Level Objective, is the promise that a company makes to users regarding a specific metric such as incident response or uptime. SLOs exist within an SLA as individual promises contained within the full user agreement. The SLO is the specific goal that the service must meet in order to comply with the SLA. SLOs should always be simple, clearly defined, and easily measured to determine whether or not the objective is being fulfilled.

## SLI

An SLI, or Service Level Indicator, is a key metric used to determine whether or not the SLO is being met. It is the measured value of the metric described within the SLO. In order to remain in compliance with the SLA, the SLI's value must always meet or exceed the value determined by the SLO.

# Disaster recovery

Disaster recovery (DR) is a process of regaining access and functionality of the infrastructure after events like a natural disaster, cyber attack, or even business disruptions.

Disaster recovery relies upon the replication of data and computer processing in an off-premises location not affected by the disaster. When servers go down because of a disaster, a business needs to recover lost data from a second location where the data is backed up. Ideally, an organization can transfer its computer processing to that remote location as well in order to continue operations.

_Disaster Recovery is often not actively discussed during system design interviews but it's important to have some basic understanding of this topic. You can learn more about disaster recovery from [AWS Well-Architected Framework](https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html)._

## Why is disaster recovery important?

Disaster recovery can have the following benefits:

- Minimize interruption and downtime
- Limit damages
- Fast restoration
- Better customer retention

## Terms

Let's discuss some important terms relevantly for disaster recovery:

![disaster-recovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/disaster-recovery/disaster-recovery.png)

### RTO

Recovery Time Objective (RTO) is the maximum acceptable delay between the interruption of service and restoration of service. This determines what is considered an acceptable time window when service is unavailable.

### RPO

Recovery Point Objective (RPO) is the maximum acceptable amount of time since the last data recovery point. This determines what is considered an acceptable loss of data between the last recovery point and the interruption of service.

## Strategies

A variety of disaster recovery (DR) strategies can be part of a disaster recovery plan.

### Back-up

This is the simplest type of disaster recovery and involves storing data off-site or on a removable drive.

### Cold Site

In this type of disaster recovery, an organization sets up basic infrastructure in a second site.

### Hot site

A hot site maintains up-to-date copies of data at all times. Hot sites are time-consuming to set up and more expensive than cold sites, but they dramatically reduce downtime.

# Virtual Machines (VMs) and Containers

Before we discuss virtualization vs containerization, let's learn what are virtual machines (VMs) and Containers.

## Virtual Machines (VM)

A Virtual Machine (VM) is a virtual environment that functions as a virtual computer system with its own CPU, memory, network interface, and storage, created on a physical hardware system. A software called a hypervisor separates the machine's resources from the hardware and provisions them appropriately so they can be used by the VM.

VMs are isolated from the rest of the system, and multiple VMs can exist on a single piece of hardware, like a server. They can be moved between host servers depending on the demand or to use resources more efficiently.

### What is a Hypervisor?

A Hypervisor sometimes called a Virtual Machine Monitor (VMM), isolates the operating system and resources from the virtual machines and enables the creation and management of those VMs. The hypervisor treats resources like CPU, memory, and storage as a pool of resources that can be easily reallocated between existing guests or new virtual machines.

### Why use a Virtual Machine?

Server consolidation is a top reason to use VMs. Most operating system and application deployments only use a small amount of the physical resources available. By virtualizing our servers, we can place many virtual servers onto each physical server to improve hardware utilization. This keeps us from needing to purchase additional physical resources.

A VM provides an environment that is isolated from the rest of a system, so whatever is running inside a VM won't interfere with anything else running on the host hardware. Because VMs are isolated, they are a good option for testing new applications or setting up a production environment. We can also run a single-purpose VM to support a specific use case.

## Containers

A container is a standard unit of software that packages up code and all its dependencies such as specific versions of runtimes and libraries so that the application runs quickly and reliably from one computing environment to another. Containers offer a logical packaging mechanism in which applications can be abstracted from the environment in which they actually run. This decoupling allows container-based applications to be deployed easily and consistently, regardless of the target environment.

### Why do we need containers?

Let's discuss some advantages of using containers:

**Separation of responsibility**

Containerization provides a clear separation of responsibility, as developers focus on application logic and dependencies, while operations teams can focus on deployment and management.

**Workload portability**

Containers can run virtually anywhere, greatly easing development and deployment.

**Application isolation**

Containers virtualize CPU, memory, storage, and network resources at the operating system level, providing developers with a view of the OS logically isolated from other applications.

**Agile development**

Containers allow developers to move much more quickly by avoiding concerns about dependencies and environments.

**Efficient operations**

Containers are lightweight and allow us to use just the computing resources we need.

## Virtualization vs Containerization

![virtualization-vs-containerization](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/virtual-machines-and-containers/virtualization-vs-containerization.png)

In traditional virtualization, a hypervisor virtualizes physical hardware. The result is that each virtual machine contains a guest OS, a virtual copy of the hardware that the OS requires to run, and an application and its associated libraries and dependencies.

Instead of virtualizing the underlying hardware, containers virtualize the operating system so each container contains only the application and its dependencies making them much more lightweight than VMs. Containers also share the OS kernel and use a fraction of the memory VMs require.

# OAuth 2.0 and OpenID Connect (OIDC)

## OAuth 2.0

OAuth 2.0, which stands for Open Authorization, is a standard designed to provide consented access to resources on behalf of the user, without ever sharing the user's credentials. OAuth 2.0 is an authorization protocol and not an authentication protocol, it is designed primarily as a means of granting access to a set of resources, for example, remote APIs or user's data.

### Concepts

The OAuth 2.0 protocol defines the following entities:

- **Resource Owner**: The user or system that owns the protected resources and can grant access to them.
- **Client**: The client is the system that requires access to the protected resources.
- **Authorization Server**: This server receives requests from the Client for Access Tokens and issues them upon successful authentication and consent by the Resource Owner.
- **Resource Server**: A server that protects the user's resources and receives access requests from the Client. It accepts and validates an Access Token from the Client and returns the appropriate resources.
- **Scopes**: They are used to specify exactly the reason for which access to resources may be granted. Acceptable scope values, and which resources they relate to, are dependent on the Resource Server.
- **Access Token**: A piece of data that represents the authorization to access resources on behalf of the end-user.

### How does OAuth 2.0 work?

Let's learn how OAuth 2.0 works:

![oauth2](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/oauth2-and-openid-connect/oauth2.png)

1. The client requests authorization from the Authorization Server, supplying the client id and secret as identification. It also provides the scopes and an endpoint URI to send the Access Token or the Authorization Code.
2. The Authorization Server authenticates the client and verifies that the requested scopes are permitted.
3. The resource owner interacts with the authorization server to grant access.
4. The Authorization Server redirects back to the client with either an Authorization Code or Access Token, depending on the grant type. A Refresh Token may also be returned.
5. With the Access Token, the client can request access to the resource from the Resource Server.

### Disadvantages

Here are the most common disadvantages of OAuth 2.0:

- Lacks built-in security features.
- No standard implementation.
- No common set of scopes.

## OpenID Connect

OAuth 2.0 is designed only for _authorization_, for granting access to data and features from one application to another. OpenID Connect (OIDC) is a thin layer that sits on top of OAuth 2.0 that adds login and profile information about the person who is logged in.

When an Authorization Server supports OIDC, it is sometimes called an Identity Provider (IdP), since it provides information about the Resource Owner back to the Client. OpenID Connect is relatively new, resulting in lower adoption and industry implementation of best practices compared to OAuth.

### Concepts

The OpenID Connect (OIDC) protocol defines the following entities:

- **Relying Party**: The current application.
- **OpenID Provider**: This is essentially an intermediate service that provides a one-time code to the Relying Party.
- **Token Endpoint**: A web server that accepts the One-Time Code (OTC) and provides an access code that's valid for an hour. The main difference between OIDC and OAuth 2.0 is that the token is provided using JSON Web Token (JWT).
- **UserInfo Endpoint**: The Relying Party communicates with this endpoint, providing a secure token and receiving information about the end-user

Both OAuth 2.0 and OIDC are easy to implement and are JSON based, which is supported by most web and mobile applications. However, the OpenID Connect (OIDC) specification is more strict than that of basic OAuth.

# Single Sign-On (SSO)

Single Sign-On (SSO) is an authentication process in which a user is provided access to multiple applications or websites by using only a single set of login credentials. This prevents the need for the user to log separately into the different applications.

The user credentials and other identifying information are stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider is a trusted system that provides access to other websites and applications.

Single Sign-On (SSO) based authentication systems are commonly used in enterprise environments where employees require access to multiple applications of their organizations.

## Components

Let's discuss some key components of Single Sign-On (SSO).

### Identity Provider (IdP)

User Identity information is stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider authenticates the user and provides access to the service provider.

The identity provider can directly authenticate the user by validating a username and password or by validating an assertion about the user's identity as presented by a separate identity provider. The identity provider handles the management of user identities in order to free the service provider from this responsibility.

### Service Provider

A service provider provides services to the end-user. They rely on identity providers to assert the identity of a user, and typically certain attributes about the user are managed by the identity provider. Service providers may also maintain a local account for the user along with attributes that are unique to their service.

### Identity Broker

An identity broker acts as an intermediary that connects multiple service providers with various different identity providers. Using Identity Broker, we can perform single sign-on over any application without the hassle of the protocol it follows.

## SAML

Security Assertion Markup Language is an open standard that allows clients to share security information about identity, authentication, and permission across different systems. SAML is implemented with the Extensible Markup Language (XML) standard for sharing data.

SAML specifically enables identity federation, making it possible for identity providers (IdPs) to seamlessly and securely pass authenticated identities and their attributes to service providers.

## How does SSO work?

Now, let's discuss how Single Sign-On works:

![sso](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/single-sign-on/sso.png)

1. The user requests a resource from their desired application.
2. The application redirects the user to the Identity Provider (IdP) for authentication.
3. The user signs in with their credentials (usually, username and password).
4. Identity Provider (IdP) sends a Single Sign-On response back to the client application.
5. The application grants access to the user.

## SAML vs OAuth 2.0 and OpenID Connect (OIDC)

There are many differences between SAML, OAuth, and OIDC. SAML uses XML to pass messages, while OAuth and OIDC use JSON. OAuth provides a simpler experience, while SAML is geared towards enterprise security.

OAuth and OIDC use RESTful communication extensively, which is why mobile, and modern web applications find OAuth and OIDC a better experience for the user. SAML, on the other hand, drops a session cookie in a browser that allows a user to access certain web pages. This is great for short-lived workloads.

OIDC is developer-friendly and simpler to implement, which broadens the use cases for which it might be implemented. It can be implemented from scratch pretty fast, via freely available libraries in all common programming languages. SAML can be complex to install and maintain, which only enterprise-size companies can handle well.

OpenID Connect is essentially a layer on top of the OAuth framework. Therefore, it can offer a built-in layer of permission that asks a user to agree to what the service provider might access. Although SAML is also capable of allowing consent flow, it achieves this by hard-coding carried out by a developer and not as part of its protocol.

_Both of these authentication protocols are good at what they do. As always, a lot depends on our specific use cases and target audience._

## Advantages

Following are the benefits of using Single Sign-On:

- Ease of use as users only need to remember one set of credentials.
- Ease of access without having to go through a lengthy authorization process.
- Enforced security and compliance to protect sensitive data.
- Simplifying the management with reduced IT support cost and admin time.

## Disadvantages

Here are some disadvantages of Single Sign-On:

- Single Password Vulnerability, if the main SSO password gets compromised, all the supported applications get compromised.
- The authentication process using Single Sign-On is slower than traditional authentication as every application has to request the SSO provider for verification.

## Examples

These are some commonly used Identity Providers (IdP):

- [Okta](https://www.okta.com)
- [Google](https://cloud.google.com/architecture/identity/single-sign-on)
- [Auth0](https://auth0.com)
- [OneLogin](https://www.onelogin.com)

# SSL, TLS, mTLS

Let's briefly discuss some important communication security protocols such as SSL, TLS, and mTLS. I would say that from a _"big picture"_ system design perspective, this topic is not very important but still good to know about.

## SSL

SSL stands for Secure Sockets Layer, and it refers to a protocol for encrypting and securing communications that take place on the internet. It was first developed in 1995 but since has been deprecated in favor of TLS (Transport Layer Security).

### Why is it called an SSL certificate if it is deprecated?

Most major certificate providers still refer to certificates as SSL certificates, which is why the naming convention persists.

### Why was SSL so important?

Originally, data on the web was transmitted in plaintext that anyone could read if they intercepted the message. SSL was created to correct this problem and protect user privacy. By encrypting any data that goes between the user and a web server, SSL also stops certain kinds of cyber attacks by preventing attackers from tampering with data in transit.

## TLS

Transport Layer Security, or TLS, is a widely adopted security protocol designed to facilitate privacy and data security for communications over the internet. TLS evolved from a previous encryption protocol called Secure Sockets Layer (SSL). A primary use case of TLS is encrypting the communication between web applications and servers.

There are three main components to what the TLS protocol accomplishes:

- **Encryption**: hides the data being transferred from third parties.
- **Authentication**: ensures that the parties exchanging information are who they claim to be.
- **Integrity**: verifies that the data has not been forged or tampered with.

## mTLS

Mutual TLS, or mTLS, is a method for mutual authentication. mTLS ensures that the parties at each end of a network connection are who they claim to be by verifying that they both have the correct private key. The information within their respective TLS certificates provides additional verification.

### Why use mTLS?

mTLS helps ensure that the traffic is secure and trusted in both directions between a client and server. This provides an additional layer of security for users who log in to an organization's network or applications. It also verifies connections with client devices that do not follow a login process, such as Internet of Things (IoT) devices.

Nowadays, mTLS is commonly used by microservices or distributed systems in a [zero trust security model](https://en.wikipedia.org/wiki/Zero_trust_security_model) to verify each other.

# System Design Interviews

System design is a very extensive topic and system design interviews are designed to evaluate your capability to produce technical solutions to abstract problems, as such, they're not designed for a specific answer. The unique aspect of system design interviews is the two-way nature between the candidate and the interviewer.

Expectations are quite different at different engineering levels as well. This is because someone with a lot of practical experience will approach it quite differently from someone who's new in the industry. As a result, it's hard to come up with a single strategy that will help us stay organized during the interview.

Let's look at some common strategies for system design interviews:

## Requirements clarifications

System design interview questions, by nature, are vague or abstract. Asking questions about the exact scope of the problem, and clarifying functional requirements early in the interview is essential. Usually, requirements are divided into three parts:

### Functional requirements

These are the requirements that the end user specifically demands as basic functionalities that the system should offer. All these functionalities need to be necessarily incorporated into the system as part of the contract.

For example:

- "What are the features that we need to design for this system?"
- "What are the edge cases we need to consider, if any, in our design?"

### Non-functional requirements

These are the quality constraints that the system must satisfy according to the project contract. The priority or extent to which these factors are implemented varies from one project to another. They are also called non-behavioral requirements. For example, portability, maintainability, reliability, scalability, security, etc.

For example:

- "Each request should be processed with the minimum latency"
- "System should be highly available"

### Extended requirements

These are basically "nice to have" requirements that might be out of the scope of the system.

For example:

- "Our system should record metrics and analytics"
- "Service health and performance monitoring?"

## Estimation and Constraints

Estimate the scale of the system we're going to design. It is important to ask questions such as:

- "What is the desired scale that this system will need to handle?"
- "What is the read/write ratio of our system?"
- "How many requests per second?"
- "How much storage will be needed?"

These questions will help us scale our design later.

## Data model design

Once we have the estimations, we can start with defining the database schema. Doing so in the early stages of the interview would help us to understand the data flow which is the core of every system. In this step, we basically define all the entities and relationships between them.

- "What are the different entities in the system?"
- "What are the relationships between these entities?"
- "How many tables do we need?"
- "Is NoSQL a better choice here?"

## API design

Next, we can start designing APIs for the system. These APIs will help us define the expectations from the system explicitly. We don't have to write any code, just a simple interface defining the API requirements such as parameters, functions, classes, types, entities, etc.

For example:

```tsx
createUser(name: string, email: string): User
```

It is advised to keep the interface as simple as possible and come back to it later when covering extended requirements.

## High-level component design

Now we have established our data model and API design, it's time to identify system components (such as Load Balancers, API Gateway, etc.) that are needed to solve our problem and draft the first design of our system.

- "Is it best to design a monolithic or a microservices architecture?"
- "What type of database should we use?"

Once we have a basic diagram, we can start discussing with the interviewer how the system will work from the client's perspective.

## Detailed design

Now it's time to go into detail about the major components of the system we designed. As always discuss with the interviewer which component may need further improvements.

Here is a good opportunity to demonstrate your experience in the areas of your expertise. Present different approaches, advantages, and disadvantages. Explain your design decisions, and back them up with examples. This is also a good time to discuss any additional features the system might be able to support, though this is optional.

- "How should we partition our data?"
- "What about load distribution?"
- "Should we use cache?"
- "How will we handle a sudden spike in traffic?"

Also, try not to be too opinionated about certain technologies, statements like "I believe that NoSQL databases are just better, SQL databases are not scalable" reflect poorly. As someone who has interviewed a lot of people over the years, my two cents here would be to be humble about what you know and what you do not. Use your existing knowledge with examples to navigate this part of the interview.

## Identify and resolve bottlenecks

Finally, it's time to discuss bottlenecks and approaches to mitigate them. Here are some important questions to ask:

- "Do we have enough database replicas?"
- "Is there any single point of failure?"
- "Is database sharding required?"
- "How can we make our system more robust?"
- "How to improve the availability of our cache?"

Make sure to read the engineering blog of the company you're interviewing with. This will help you get a sense of what technology stack they're using and which problems are important to them.

# URL Shortener

Let's design a URL shortener, similar to services like [Bitly](https://bitly.com), [TinyURL](https://tinyurl.com/app).

## What is a URL Shortener?

A URL shortener service creates an alias or a short URL for a long URL. Users are redirected to the original URL when they visit these short links.

For example, the following long URL can be changed to a shorter URL.

**Long URL**: [https://karanpratapsingh.com/courses/system-design/url-shortener](https://karanpratapsingh.com/courses/system-design/url-shortener)

**Short URL**: [https://bit.ly/3I71d3o](https://bit.ly/3I71d3o)

## Why do we need a URL shortener?

URL shortener saves space in general when we are sharing URLs. Users are also less likely to mistype shorter URLs. Moreover, we can also optimize links across devices, this allows us to track individual links.

## Requirements

Our URL shortening system should meet the following requirements:

### Functional requirements

- Given a URL, our service should generate a _shorter and unique_ alias for it.
- Users should be redirected to the original URL when they visit the short link.
- Links should expire after a default timespan.

### Non-functional requirements

- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Prevent abuse of services.
- Record analytics and metrics for redirections.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic related assumptions with your interviewer._

### Traffic

This will be a read-heavy system, so let's assume a `100:1` read/write ratio with 100 million links generated per month.

**Reads/Writes Per month**

For reads per month:

$$
100 \times 100 \space million = 10 \space billion/month
$$

Similarly for writes:

$$
1 \times 100 \space million = 100 \space million/month
$$

**What would be Requests Per Second (RPS) for our system?**

100 million requests per month translate into 40 requests per second.

$$
\frac{100 \space million}{(30 \space days \times 24 \space hrs \times 3600 \space seconds)} = \sim 40 \space URLs/second
$$

And with a `100:1` read/write ratio, the number of redirections will be:

$$
100 \times 40 \space URLs/second = 4000 \space requests/second
$$

### Bandwidth

Since we expect about 40 URLs every second, and if we assume each request is of size 500 bytes then the total incoming data for write requests would be:

$$
40 \times 500 \space bytes = 20 \space KB/second
$$

Similarly, for the read requests, since we expect about 4K redirections, the total outgoing data would be:

$$
4000 \space URLs/second \times 500 \space bytes = \sim 2 \space MB/second
$$

### Storage

For storage, we will assume we store each link or record in our database for 10 years. Since we expect around 100M new requests every month, the total number of records we will need to store would be:

$$
100 \space million \times 10\space years \times 12 \space months = 12 \space billion
$$

Like earlier, if we assume each stored record will be approximately 500 bytes. We will need around 6TB of storage:

$$
12 \space billion \times 500 \space bytes = 6 \space TB
$$

### Cache

For caching, we will follow the classic [Pareto principle](https://en.wikipedia.org/wiki/Pareto_principle) also known as the 80/20 rule. This means that 80% of the requests are for 20% of the data, so we can cache around 20% of our requests.

Since we get around 4K read or redirection requests each second, this translates into 350M requests per day.

$$
4000 \space URLs/second \times 24 \space hours \times 3600 \space seconds = \sim 350 \space million \space requests/day
$$

Hence, we will need around 35GB of memory per day.

$$
20 \space percent \times 350 \space million \times 500 \space bytes = 35 \space GB/day
$$

### High-level estimate

Here is our high-level estimate:

| Type                 | Estimate   |
| -------------------- | ---------- |
| Writes (New URLs)    | 40/s       |
| Reads (Redirection)  | 4K/s       |
| Bandwidth (Incoming) | 20 KB/s    |
| Bandwidth (Outgoing) | 2 MB/s     |
| Storage (10 years)   | 6 TB       |
| Memory (Caching)     | ~35 GB/day |

## Data model design

Next, we will focus on the data model design. Here is our database schema:

![url-shortener-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-datamodel.png)

Initially, we can get started with just two tables:

**users**

Stores user's details such as `name`, `email`, `createdAt`, etc.

**urls**

Contains the new short URL's properties such as `expiration`, `hash`, `originalURL`, and `userID` of the user who created the short URL. We can also use the `hash` column as an [index](https://karanpratapsingh.com/courses/system-design/indexes) to improve the query performance.

### What kind of database should we use?

Since the data is not strongly relational, NoSQL databases such as [Amazon DynamoDB](https://aws.amazon.com/dynamodb), [Apache Cassandra](https://cassandra.apache.org/_/index.html), or [MongoDB](https://www.mongodb.com) will be a better choice here, if we do decide to use an SQL database then we can use something like [Azure SQL Database](https://azure.microsoft.com/en-in/products/azure-sql/database) or [Amazon RDS](https://aws.amazon.com/rds).

_For more details, refer to [SQL vs NoSQL](https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases)._

## API design

Let us do a basic API design for our services:

### Create URL

This API should create a new short URL in our system given an original URL.

```tsx
createURL(apiKey: string, originalURL: string, expiration?: Date): string
```

**Parameters**

API Key (`string`): API key provided by the user.

Original URL (`string`): Original URL to be shortened.

Expiration (`Date`): Expiration date of the new URL _(optional)_.

**Returns**

Short URL (`string`): New shortened URL.

### Get URL

This API should retrieve the original URL from a given short URL.

```tsx
getURL(apiKey: string, shortURL: string): string
```

**Parameters**

API Key (`string`): API key provided by the user.

Short URL (`string`): Short URL mapped to the original URL.

**Returns**

Original URL (`string`): Original URL to be retrieved.

### Delete URL

This API should delete a given shortURL from our system.

```tsx
deleteURL(apiKey: string, shortURL: string): boolean
```

**Parameters**

API Key (`string`): API key provided by the user.

Short URL (`string`): Short URL to be deleted.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Why do we need an API key?

As you must've noticed, we're using an API key to prevent abuse of our services. Using this API key we can limit the users to a certain number of requests per second or minute. This is quite a standard practice for developer APIs and should cover our extended requirement.

## High-level design

Now let us do a high-level design of our system.

### URL Encoding

Our system's primary goal is to shorten a given URL, let's look at different approaches:

**Base62 Approach**

In this approach, we can encode the original URL using [Base62](https://en.wikipedia.org/wiki/Base62) which consists of the capital letters A-Z, the lower case letters a-z, and the numbers 0-9.

$$
Number \space of \space URLs = 62^N
$$

Where,

`N`: Number of characters in the generated URL.

So, if we want to generate a URL that is 7 characters long, we will generate ~3.5 trillion different URLs.

$$
\begin{gather*}
62^5 = \sim 916 \space million \space URLs \\
62^6 = \sim 56.8 \space billion \space URLs \\
62^7 = \sim 3.5 \space trillion \space URLs
\end{gather*}
$$

This is the simplest solution here, but it does not guarantee non-duplicate or collision-resistant keys.

**MD5 Approach**

The [MD5 message-digest algorithm](https://en.wikipedia.org/wiki/MD5) is a widely used hash function producing a 128-bit hash value (or 32 hexadecimal digits). We can use these 32 hexadecimal digits for generating 7 characters long URL.

$$
MD5(original\_url) \rightarrow base62encode \rightarrow hash
$$

However, this creates a new issue for us, which is duplication and collision. We can try to re-compute the hash until we find a unique one but that will increase the overhead of our systems. It's better to look for more scalable approaches.

**Counter Approach**

In this approach, we will start with a single server which will maintain the count of the keys generated. Once our service receives a request, it can reach out to the counter which returns a unique number and increments the counter. When the next request comes the counter again returns the unique number and this goes on.

$$
Counter(0-3.5 \space trillion) \rightarrow base62encode \rightarrow hash
$$

The problem with this approach is that it can quickly become a single point for failure. And if we run multiple instances of the counter we can have collision as it's essentially a distributed system.

To solve this issue we can use a distributed system manager such as [Zookeeper](https://zookeeper.apache.org) which can provide distributed synchronization. Zookeeper can maintain multiple ranges for our servers.

$$
\begin{align*}
& Range \space 1: \space 1 \rightarrow 1,000,000 \\
& Range \space 2: \space 1,000,001 \rightarrow 2,000,000 \\
& Range \space 3: \space 2,000,001 \rightarrow 3,000,000 \\
& ...
\end{align*}
$$

Once a server reaches its maximum range Zookeeper will assign an unused counter range to the new server. This approach can guarantee non-duplicate and collision-resistant URLs. Also, we can run multiple instances of Zookeeper to remove the single point of failure.

### Key Generation Service (KGS)

As we discussed, generating a unique key at scale without duplication and collisions can be a bit of a challenge. To solve this problem, we can create a standalone Key Generation Service (KGS) that generates a unique key ahead of time and stores it in a separate database for later use. This approach can make things simple for us.

**How to handle concurrent access?**

Once the key is used, we can mark it in the database to make sure we don't reuse it, however, if there are multiple server instances reading data concurrently, two or more servers might try to use the same key.

The easiest way to solve this would be to store keys in two tables. As soon as a key is used, we move it to a separate table with appropriate locking in place. Also, to improve reads, we can keep some of the keys in memory.

**KGS database estimations**

As per our discussion, we can generate up to ~56.8 billion unique 6 character long keys which will result in us having to store 300 GB of keys.

$$
6 \space characters \times 56.8 \space billion = \sim 390 \space GB
$$

While 390 GB seems like a lot for this simple use case, it is important to remember this is for the entirety of our service lifetime and the size of the keys database would not increase like our main database.

### Caching

Now, let's talk about [caching](https://karanpratapsingh.com/courses/system-design/caching). As per our estimations, we will require around ~35 GB of memory per day to cache 20% of the incoming requests to our services. For this use case, we can use [Redis](https://redis.io) or [Memcached](https://memcached.org) servers alongside our API server.

_For more details, refer to [caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Design

Now that we have identified some core components, let's do the first draft of our system design.

![url-shortener-basic-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-basic-design.png)

Here's how it works:

**Creating a new URL**

1. When a user creates a new URL, our API server requests a new unique key from the Key Generation Service (KGS).
2. Key Generation Service provides a unique key to the API server and marks the key as used.
3. API server writes the new URL entry to the database and cache.
4. Our service returns an HTTP 201 (Created) response to the user.

**Accessing a URL**

1. When a client navigates to a certain short URL, the request is sent to the API servers.
2. The request first hits the cache, and if the entry is not found there then it is retrieved from the database and an HTTP 301 (Redirect) is issued to the original URL.
3. If the key is still not found in the database, an HTTP 404 (Not found) error is sent to the user.

## Detailed design

It's time to discuss the finer details of our design.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Database cleanup

This is more of a maintenance step for our services and depends on whether we keep the expired entries or remove them. If we do decide to remove expired entries, we can approach this in two different ways:

**Active cleanup**

In active cleanup, we will run a separate cleanup service which will periodically remove expired links from our storage and cache. This will be a very lightweight service like a [cron job](https://en.wikipedia.org/wiki/Cron).

**Passive cleanup**

For passive cleanup, we can remove the entry when a user tries to access an expired link. This can ensure a lazy cleanup of our database and cache.

### Cache

Now let us talk about [caching](https://karanpratapsingh.com/courses/system-design/caching).

**Which cache eviction policy to use?**

As we discussed before, we can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. We can store and update metadata like visitor's country, platform, the number of views, etc alongside the URL entry in our database.

### Security

For security, we can introduce private URLs and authorization. A separate table can be used to store user ids that have permission to access a specific URL. If a user does not have proper permissions, we can return an HTTP 401 (Unauthorized) error.

We can also use an [API Gateway](https://karanpratapsingh.com/courses/system-design/api-gateway) as they can support capabilities like authorization, rate limiting, and load balancing out of the box.

## Identify and resolve bottlenecks

![url-shortener-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if the API service or Key Generation Service crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "What if the key database used by KGS fails?"
- "How to improve the availability of our cache?"

To make our system more resilient we can do the following:

- Running multiple instances of our Servers and Key Generation Service.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our database as it's a read-heavy system.
- Standby replica for our key database in case it fails.
- Multiple instances and replicas for our distributed cache.

# WhatsApp

Let's design a [WhatsApp](https://whatsapp.com) like instant messaging service, similar to services like [Facebook Messenger](https://www.messenger.com), and [WeChat](https://www.wechat.com).

## What is WhatsApp?

WhatsApp is a chat application that provides instant messaging services to its users. It is one of the most used mobile applications on the planet, connecting over 2 billion users in 180+ countries. WhatsApp is also available on the web.

## Requirements

Our system should meet the following requirements:

### Functional requirements

- Should support one-on-one chat.
- Group chats (max 100 people).
- Should support file sharing (image, video, etc.).

### Non-functional requirements

- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Sent, Delivered, and Read receipts of the messages.
- Show the last seen time of users.
- Push notifications.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

Let us assume we have 50 million daily active users (DAU) and on average each user sends at least 10 messages to 4 different people every day. This gives us 2 billion messages per day.

$$
50 \space million \times 40 \space messages = 2 \space billion/day
$$

Messages can also contain media such as images, videos, or other files. We can assume that 5 percent of messages are media files shared by the users, which gives us additional 100 million files we would need to store.

$$
5 \space percent \times 2 \space billion = 100 \space million/day
$$

**What would be Requests Per Second (RPS) for our system?**

2 billion requests per day translate into 24K requests per second.

$$
\frac{2 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 24K \space requests/second
$$

### Storage

If we assume each message on average is 100 bytes, we will require about 200 GB of database storage every day.

$$
2 \space billion \times 100 \space bytes = \sim 200 \space GB/day
$$

As per our requirements, we also know that around 5 percent of our daily messages (100 million) are media files. If we assume each file is 100 KB on average, we will require 10 TB of storage every day.

$$
100 \space million \times 100 \space KB = 10 \space TB/day
$$

And for 10 years, we will require about 38 PB of storage.

$$
(10 \space TB + 0.2 \space TB) \times 10 \space years \times 365 \space days = \sim 38 \space PB
$$

### Bandwidth

As our system is handling 10.2 TB of ingress every day, we will require a minimum bandwidth of around 120 MB per second.

$$
\frac{10.2 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 120 \space MB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate   |
| ------------------------- | ---------- |
| Daily active users (DAU)  | 50 million |
| Requests per second (RPS) | 24K/s      |
| Storage (per day)         | ~10.2 TB   |
| Storage (10 years)        | ~38 PB     |
| Bandwidth                 | ~120 MB/s  |

## Data model design

This is the general data model which reflects our requirements.

![whatsapp-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-datamodel.png)

We have the following tables:

**users**

This table will contain a user's information such as `name`, `phoneNumber`, and other details.

**messages**

As the name suggests, this table will store messages with properties such as `type` (text, image, video, etc.), `content`, and timestamps for message delivery. The message will also have a corresponding `chatID` or `groupID`.

**chats**

This table basically represents a private chat between two users and can contain multiple messages.

**users_chats**

This table maps users and chats as multiple users can have multiple chats (N:M relationship) and vice versa.

**groups**

This table represents a group made up of multiple users.

**users_groups**

This table maps users and groups as multiple users can be a part of multiple groups (N:M relationship) and vice versa.

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Get all chats or groups

This API will get all chats or groups for a given `userID`.

```tsx
getAll(userID: UUID): Chat[] | Group[]
```

**Parameters**

User ID (`UUID`): ID of the current user.

**Returns**

Result (`Chat[] | Group[]`): All the chats and groups the user is a part of.

### Get messages

Get all messages for a user given the `channelID` (chat or group id).

```tsx
getMessages(userID: UUID, channelID: UUID): Message[]
```

**Parameters**

User ID (`UUID`): ID of the current user.

Channel ID (`UUID`): ID of the channel (chat or group) from which messages need to be retrieved.

**Returns**

Messages (`Message[]`): All the messages in a given chat or group.

### Send message

Send a message from a user to a channel (chat or group).

```tsx
sendMessage(userID: UUID, channelID: UUID, message: Message): boolean
```

**Parameters**

User ID (`UUID`): ID of the current user.

Channel ID (`UUID`): ID of the channel (chat or group) user wants to send a message to.

Message (`Message`): The message (text, image, video, etc.) that the user wants to send.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Join or leave a channel

Allows the user to join or leave a channel (chat or group).

```tsx
joinGroup(userID: UUID, channelID: UUID): boolean
leaveGroup(userID: UUID, channelID: UUID): boolean
```

**Parameters**

User ID (`UUID`): ID of the current user.

Channel ID (`UUID`): ID of the channel (chat or group) the user wants to join or leave.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**User Service**

This is an HTTP-based service that handles user-related concerns such as authentication and user information.

**Chat Service**

The chat service will use WebSockets and establish connections with the client to handle chat and group message-related functionality. We can also use cache to keep track of all the active connections sort of like sessions which will help us determine if the user is online or not.

**Notification Service**

This service will simply send push notifications to the users. It will be discussed in detail separately.

**Presence Service**

The presence service will keep track of the _last seen_ status of all users. It will be discussed in detail separately.

**Media service**

This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### Real-time messaging

How do we efficiently send and receive messages? We have two different options:

**Pull model**

The client can periodically send an HTTP request to servers to check if there are any new messages. This can be achieved via something like [Long polling](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling).

**Push model**

The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) or [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) for this.

The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) is a better choice because then we can push data to the client once it's available without any delay, given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) which are only unidirectional.

_Note: Learn more about [Long polling, WebSockets, Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events)._

### Last seen

To implement the last seen functionality, we can use a [heartbeat](<https://en.wikipedia.org/wiki/Heartbeat_(computing)>) mechanism, where the client can periodically ping the servers indicating its liveness. Since this needs to be as low overhead as possible, we can store the last active timestamp in the cache as follows:

| Key    | Value               |
| ------ | ------------------- |
| User A | 2022-07-01T14:32:50 |
| User B | 2022-07-05T05:10:35 |
| User C | 2022-07-10T04:33:25 |

This will give us the last time the user was active. This functionality will be handled by the presence service combined with [Redis](https://redis.io) or [Memcached](https://memcached.org) as our cache.

Another way to implement this is to track the latest action of the user, once the last activity crosses a certain threshold, such as _"user hasn't performed any action in the last 30 seconds"_, we can show the user as offline and last seen with the last recorded timestamp. This will be more of a lazy update approach and might benefit us over heartbeat in certain cases.

### Notifications

Once a message is sent in a chat or a group, we will first check if the recipient is active or not, we can get this information by taking the user's active connection and last seen into consideration.

If the recipient is not active, the chat service will add an event to a [message queue](https://karanpratapsingh.com/courses/system-design/message-queues) with additional metadata such as the client's device platform which will be used to route the notification to the correct platform later on.

The notification service will then consume the event from the message queue and forward the request to [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) or [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications) based on the client's device platform (Android, iOS, web, etc). We can also add support for email and SMS.

**Why are we using a message queue?**

Since most message queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they're sent and that a message is delivered at least once which is an important part of our service functionality.

While this seems like a classic [publish-subscribe](https://karanpratapsingh.com/courses/system-design/publish-subscribe) use case, it is actually not as mobile devices and browsers each have their own way of handling push notifications. Usually, notifications are handled externally via Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) unlike message fan-out which we commonly see in backend services. We can use something like [Amazon SQS](https://aws.amazon.com/sqs) or [RabbitMQ](https://www.rabbitmq.com) to support this functionality.

### Read receipts

Handling read receipts can be tricky, for this use case we can wait for some sort of [Acknowledgment (ACK)](<https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)>) from the client to determine if the message was delivered and update the corresponding `deliveredAt` field. Similarly, we will mark the message as seen once the user opens the chat and update the corresponding `seenAt` timestamp field.

### Design

Now that we have identified some core components, let's do the first draft of our system design.

![whatsapp-basic-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-basic-design.png)

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Caching

In a messaging application, we have to be careful about using cache as our users expect the latest data, but many users will be requesting the same messages, especially in a group chat. So, to prevent usage spikes from our resources we can cache older messages.

Some group chats can have thousands of messages and sending that over the network will be really inefficient, to improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won't have to retrieve old messages unless requested.

**Which cache eviction policy to use?**

We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Media access and storage

As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.

But where can we store files at scale? Well, [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) is what we're looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs) or [GlusterFS](https://www.gluster.org).

_Fun fact: WhatsApp deletes media on its servers once it has been downloaded by the user._

We can use object stores like [Amazon S3](https://aws.amazon.com/s3), [Azure Blob Storage](https://azure.microsoft.com/en-in/services/storage/blobs), or [Google Cloud Storage](https://cloud.google.com/storage) for this use case.

### Content Delivery Network (CDN)

[Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) or [Cloudflare CDN](https://www.cloudflare.com/cdn) for this use case.

### API gateway

Since we will be using multiple protocols like HTTP, WebSocket, TCP/IP, deploying multiple L4 (transport layer) or L7 (application layer) type load balancers separately for each protocol will be expensive. Instead, we can use an [API Gateway](https://karanpratapsingh.com/courses/system-design/api-gateway) that supports multiple protocols without any issues.

API Gateway can also offer other features such as authentication, authorization, rate limiting, throttling, and API versioning which will improve the quality of our services.

We can use services like [Amazon API Gateway](https://aws.amazon.com/api-gateway) or [Azure API Gateway](https://azure.microsoft.com/en-in/services/api-management) for this use case.

## Identify and resolve bottlenecks

![whatsapp-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"
- "Wouldn't API Gateway be a single point of failure?"
- "How can we make our notification system more robust?"
- "How can we reduce media storage costs"?
- "Does chat service has too much responsibility?"

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.
- We can have a standby replica of our API Gateway.
- Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated [message broker](https://karanpratapsingh.com/courses/system-design/message-brokers) such as [Apache Kafka](https://kafka.apache.org) or [NATS](https://nats.io) to make our notification system more robust.
- We can add media processing and compression capabilities to the media service to compress large files similar to WhatsApp which will save a lot of storage space and reduce cost.
- We can create a group service separate from the chat service to further decouple our services.

# Twitter

Let's design a [Twitter](https://twitter.com) like social media service, similar to services like [Facebook](https://facebook.com), [Instagram](https://instagram.com), etc.

## What is Twitter?

Twitter is a social media service where users can read or post short messages (up to 280 characters) called tweets. It is available on the web and mobile platforms such as Android and iOS.

## Requirements

Our system should meet the following requirements:

### Functional requirements

- Should be able to post new tweets (can be text, image, video, etc.).
- Should be able to follow other users.
- Should have a newsfeed feature consisting of tweets from the people the user is following.
- Should be able to search tweets.

### Non-Functional requirements

- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Metrics and analytics.
- Retweet functionality.
- Favorite tweets.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user tweets 5 times a day. This gives us 1 billion tweets per day.

$$
200 \space million \times 5 \space tweets = 1 \space billion/day
$$

Tweets can also contain media such as images, or videos. We can assume that 10 percent of tweets are media files shared by the users, which gives us additional 100 million files we would need to store.

$$
10 \space percent \times 1 \space billion = 100 \space million/day
$$

**What would be Requests Per Second (RPS) for our system?**

1 billion requests per day translate into 12K requests per second.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Storage

If we assume each message on average is 100 bytes, we will require about 100 GB of database storage every day.

$$
1 \space billion \times 100 \space bytes = \sim 100 \space GB/day
$$

We also know that around 10 percent of our daily messages (100 million) are media files per our requirements. If we assume each file is 50 KB on average, we will require 5 TB of storage every day.

$$
100 \space million \times 50 \space KB = 5 \space TB/day
$$

And for 10 years, we will require about 19 PB of storage.

$$
(5 \space TB + 0.1 \space TB) \times 365 \space days \times 10 \space years = \sim 19 \space PB
$$

### Bandwidth

As our system is handling 5.1 TB of ingress every day, we will require a minimum bandwidth of around 60 MB per second.

$$
\frac{5.1 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 60 \space MB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate    |
| ------------------------- | ----------- |
| Daily active users (DAU)  | 100 million |
| Requests per second (RPS) | 12K/s       |
| Storage (per day)         | ~5.1 TB     |
| Storage (10 years)        | ~19 PB      |
| Bandwidth                 | ~60 MB/s    |

## Data model design

This is the general data model which reflects our requirements.

![twitter-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-datamodel.png)

We have the following tables:

**users**

This table will contain a user's information such as `name`, `email`, `dob`, and other details.

**tweets**

As the name suggests, this table will store tweets and their properties such as `type` (text, image, video, etc.), `content`, etc. We will also store the corresponding `userID`.

**favorites**

This table maps tweets with users for the favorite tweets functionality in our application.

**followers**

This table maps the followers and [followees](https://en.wiktionary.org/wiki/followee) as users can follow each other (N:M relationship).

**feeds**

This table stores feed properties with the corresponding `userID`.

**feeds_tweets**

This table maps tweets and feed (N:M relationship).

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Post a tweet

This API will allow the user to post a tweet on the platform.

```tsx
postTweet(userID: UUID, content: string, mediaURL?: string): boolean
```

**Parameters**

User ID (`UUID`): ID of the user.

Content (`string`): Contents of the tweet.

Media URL (`string`): URL of the attached media _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Follow or unfollow a user

This API will allow the user to follow or unfollow another user.

```tsx
follow(followerID: UUID, followeeID: UUID): boolean
unfollow(followerID: UUID, followeeID: UUID): boolean
```

**Parameters**

Follower ID (`UUID`): ID of the current user.

Followee ID (`UUID`): ID of the user we want to follow or unfollow.

Media URL (`string`): URL of the attached media _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Get newsfeed

This API will return all the tweets to be shown within a given newsfeed.

```tsx
getNewsfeed(userID: UUID): Tweet[]
```

**Parameters**

User ID (`UUID`): ID of the user.

**Returns**

Tweets (`Tweet[]`): All the tweets to be shown within a given newsfeed.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**User Service**

This service handles user-related concerns such as authentication and user information.

**Newsfeed Service**

This service will handle the generation and publishing of user newsfeeds. It will be discussed in detail separately.

**Tweet Service**

The tweet service will handle tweet-related use cases such as posting a tweet, favorites, etc.

**Search Service**

The service is responsible for handling search-related functionality. It will be discussed in detail separately.

**Media service**

This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.

**Notification Service**

This service will simply send push notifications to the users.

**Analytics Service**

This service will be used for metrics and analytics use cases.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### Newsfeed

When it comes to the newsfeed, it seems easy enough to implement, but there are a lot of things that can make or break this feature. So, let's divide our problem into two parts:

**Generation**

Let's assume we want to generate the feed for user A, we will perform the following steps:

1. Retrieve the IDs of all the users and entities (hashtags, topics, etc.) user A follows.
2. Fetch the relevant tweets for each of the retrieved IDs.
3. Use a ranking algorithm to rank the tweets based on parameters such as relevance, time, engagement, etc.
4. Return the ranked tweets data to the client in a paginated manner.

Feed generation is an intensive process and can take quite a lot of time, especially for users following a lot of people. To improve the performance, the feed can be pre-generated and stored in the cache, then we can have a mechanism to periodically update the feed and apply our ranking algorithm to the new tweets.

**Publishing**

Publishing is the step where the feed data is pushed according to each specific user. This can be a quite heavy operation, as a user may have millions of friends or followers. To deal with this, we have three different approaches:

- Pull Model (or Fan-out on load)

![newsfeed-pull-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-pull-model.png)

When a user creates a tweet, and a follower reloads their newsfeed, the feed is created and stored in memory. The most recent feed is only loaded when the user requests it. This approach reduces the number of write operations on our database.

The downside of this approach is that the users will not be able to view recent feeds unless they "pull" the data from the server, which will increase the number of read operations on the server.

- Push Model (or Fan-out on write)

![newsfeed-push-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-push-model.png)

In this model, once a user creates a tweet, it is "pushed" to all the follower's feeds immediately. This prevents the system from having to go through a user's entire followers list to check for updates.

However, the downside of this approach is that it would increase the number of write operations on the database.

- Hybrid Model

A third approach is a hybrid model between the pull and push model. It combines the beneficial features of the above two models and tries to provide a balanced approach between the two.

The hybrid model allows only users with a lesser number of followers to use the push model. For users with a higher number of followers such as celebrities, the pull model is used.

### Ranking Algorithm

As we discussed, we will need a ranking algorithm to rank each tweet according to its relevance to each specific user.

For example, Facebook used to utilize an [EdgeRank](https://en.wikipedia.org/wiki/EdgeRank) algorithm. Here, the rank of each feed item is described by:

$$
Rank = Affinity \times Weight \times Decay
$$

Where,

`Affinity`: is the "closeness" of the user to the creator of the edge. If a user frequently likes, comments, or messages the edge creator, then the value of affinity will be higher, resulting in a higher rank for the post.

`Weight`: is the value assigned according to each edge. A comment can have a higher weightage than likes, and thus a post with more comments is more likely to get a higher rank.

`Decay`: is the measure of the creation of the edge. The older the edge, the lesser will be the value of decay and eventually the rank.

Nowadays, algorithms are much more complex and ranking is done using machine learning models which can take thousands of factors into consideration.

### Retweets

Retweets are one of our extended requirements. To implement this feature, we can simply create a new tweet with the user id of the user retweeting the original tweet and then modify the `type` enum and `content` property of the new tweet to link it with the original tweet.

For example, the `type` enum property can be of type tweet, similar to text, video, etc and `content` can be the id of the original tweet. Here the first row indicates the original tweet while the second row is how we can represent a retweet.

| id                  | userID              | type  | content                      | createdAt     |
| ------------------- | ------------------- | ----- | ---------------------------- | ------------- |
| ad34-291a-45f6-b36c | 7a2c-62c4-4dc8-b1bb | text  | Hey, this is my first tweet… | 1658905644054 |
| f064-49ad-9aa2-84a6 | 6aa2-2bc9-4331-879f | tweet | ad34-291a-45f6-b36c          | 1658906165427 |

This is a very basic implementation. To improve this we can create a separate table itself to store retweets.

### Search

Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. [Elasticsearch](https://www.elastic.co) can help us with this use case.

[Elasticsearch](https://www.elastic.co) is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of [Apache Lucene](https://lucene.apache.org).

**How do we identify trending topics?**

Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries, hashtags, and topics in the last `N` seconds and update them every `M` seconds using some sort of batch job mechanism. Our ranking algorithm can also be applied to the trending topics to give them more weight and personalize them for the user.

### Notifications

Push notifications are an integral part of any social media platform. We can use a message queue or a message broker such as [Apache Kafka](https://kafka.apache.org) with the notification service to dispatch requests to [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) or [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications) which will handle the delivery of the push notifications to user devices.

_For more details, refer to the [WhatsApp](https://karanpratapsingh.com/courses/system-design/whatsapp#notifications) system design where we discuss push notifications in detail._

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Mutual friends

For mutual friends, we can build a social graph for every user. Each node in the graph will represent a user and a directional edge will represent followers and followees. After that, we can traverse the followers of a user to find and suggest a mutual friend. This would require a graph database such as [Neo4j](https://neo4j.com) and [ArangoDB](https://www.arangodb.com).

This is a pretty simple algorithm, to improve our suggestion accuracy, we will need to incorporate a recommendation model which uses machine learning as part of our algorithm.

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. As we will be using [Apache Kafka](https://kafka.apache.org) to publish all sorts of events, we can process these events and run analytics on the data using [Apache Spark](https://spark.apache.org) which is an open-source unified analytics engine for large-scale data processing.

### Caching

In a social media application, we have to be careful about using cache as our users expect the latest data. So, to prevent usage spikes from our resources we can cache the top 20% of the tweets.

To further improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won't have to retrieve old messages unless requested.

**Which cache eviction policy to use?**

We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Media access and storage

As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.

But where can we store files at scale? Well, [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) is what we're looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs) or [GlusterFS](https://www.gluster.org).

### Content Delivery Network (CDN)

[Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) or [Cloudflare CDN](https://www.cloudflare.com/cdn) for this use case.

## Identify and resolve bottlenecks

![twitter-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"
- "How can we make our notification system more robust?"
- "How can we reduce media storage costs"?

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.
- Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated [message broker](https://karanpratapsingh.com/courses/system-design/message-brokers) such as [Apache Kafka](https://kafka.apache.org) or [NATS](https://nats.io) to make our notification system more robust.
- We can add media processing and compression capabilities to the media service to compress large files which will save a lot of storage space and reduce cost.

# Netflix

Let's design a [Netflix](https://netflix.com) like video streaming service, similar to services like [Amazon Prime Video](https://www.primevideo.com), [Disney Plus](https://www.disneyplus.com), [Hulu](https://www.hulu.com), [Youtube](https://youtube.com), [Vimeo](https://vimeo.com), etc.

## What is Netflix?

Netflix is a subscription-based streaming service that allows its members to watch TV shows and movies on an internet-connected device. It is available on platforms such as the Web, iOS, Android, TV, etc.

## Requirements

Our system should meet the following requirements:

### Functional requirements

- Users should be able to stream and share videos.
- The content team (or users in YouTube's case) should be able to upload new videos (movies, tv shows episodes, and other content).
- Users should be able to search for videos using titles or tags.
- Users should be able to comment on a video similar to YouTube.

### Non-Functional requirements

- High availability with minimal latency.
- High reliability, no uploads should be lost.
- The system should be scalable and efficient.

### Extended requirements

- Certain content should be [geo-blocked](https://en.wikipedia.org/wiki/Geo-blocking).
- Resume video playback from the point user left off.
- Record metrics and analytics of videos.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user watches 5 videos a day. This gives us 1 billion videos watched per day.

$$
200 \space million \times 5 \space videos = 1 \space billion/day
$$

Assuming a `200:1` read/write ratio, about 5 million videos will be uploaded every day.

$$
\frac{1}{200} \times 1 \space billion = 5 \space million/day
$$

**What would be Requests Per Second (RPS) for our system?**

1 billion requests per day translate into 12K requests per second.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Storage

If we assume each video is 100 MB on average, we will require about 500 TB of storage every day.

$$
5 \space million \times 100 \space MB = 500 \space TB/day
$$

And for 10 years, we will require an astounding 1,825 PB of storage.

$$
500 \space TB \times 365 \space days \times 10 \space years = \sim 1,825 \space PB
$$

### Bandwidth

As our system is handling 500 TB of ingress every day, we will require a minimum bandwidth of around 5.8 GB per second.

$$
\frac{500 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 5.8 \space GB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate    |
| ------------------------- | ----------- |
| Daily active users (DAU)  | 200 million |
| Requests per second (RPS) | 12K/s       |
| Storage (per day)         | ~500 TB     |
| Storage (10 years)        | ~1,825 PB   |
| Bandwidth                 | ~5.8 GB/s   |

## Data model design

This is the general data model which reflects our requirements.

![netflix-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-datamodel.png)

We have the following tables:

**users**

This table will contain a user's information such as `name`, `email`, `dob`, and other details.

**videos**

As the name suggests, this table will store videos and their properties such as `title`, `streamURL`, `tags`, etc. We will also store the corresponding `userID`.

**tags**

This table will simply store tags associated with a video.

**views**

This table helps us to store all the views received on a video.

**comments**

This table stores all the comments received on a video (like YouTube).

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Upload a video

Given a byte stream, this API enables video to be uploaded to our service.

```tsx
uploadVideo(title: string, description: string, data: Stream<byte>, tags?: string[]): boolean
```

**Parameters**

Title (`string`): Title of the new video.

Description (`string`): Description of the new video.

Data (`Byte[]`): Byte stream of the video data.

Tags (`string[]`): Tags for the video _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Streaming a video

This API allows our users to stream a video with the preferred codec and resolution.

```tsx
streamVideo(videoID: UUID, codec: Enum<string>, resolution: Tuple<int>, offset?: int): VideoStream
```

**Parameters**

Video ID (`UUID`): ID of the video that needs to be streamed.

Codec (`Enum<string>`): Required [codec](https://en.wikipedia.org/wiki/Video_codec) of the requested video, such as `h.265`, `h.264`, `VP9`, etc.

Resolution (`Tuple<int>`): [Resolution](https://en.wikipedia.org/wiki/Display_resolution) of the requested video.

Offset (`int`): Offset of the video stream in seconds to stream data from any point in the video _(optional)_.

**Returns**

Stream (`VideoStream`): Data stream of the requested video.

### Search for a video

This API will enable our users to search for a video based on its title or tags.

```tsx
searchVideo(query: string, nextPage?: string): Video[]
```

**Parameters**

Query (`string`): Search query from the user.

Next Page (`string`): Token for the next page, this can be used for pagination _(optional)_.

**Returns**

Videos (`Video[]`): All the videos available for a particular search query.

### Add a comment

This API will allow our users to post a comment on a video (like YouTube).

```tsx
comment(videoID: UUID, comment: string): boolean
```

**Parameters**

VideoID (`UUID`): ID of the video user wants to comment on.

Comment (`string`): The text content of the comment.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**User Service**

This service handles user-related concerns such as authentication and user information.

**Stream Service**

The stream service will handle video streaming-related functionality.

**Search Service**

The service is responsible for handling search-related functionality. It will be discussed in detail separately.

**Media service**

This service will handle the video uploads and processing. It will be discussed in detail separately.

**Analytics Service**

This service will be used for metrics and analytics use cases.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### Video processing

![video-processing-pipeline](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/video-processing-pipeline.png)

There are so many variables in play when it comes to processing a video. For example, an average data size of two-hour raw 8K footage from a high-end camera can easily be up to 4 TB, thus we need to have some kind of processing to reduce both storage and delivery costs.

Here's how we can process videos once they're uploaded by the content team (or users in YouTube's case) and are queued for processing in our [message queue](https://karanpratapsingh.com/courses/system-design/message-queues).

Let's discuss how this works:

- **File Chunker**

![file-chunking](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/file-chunking.png)

This is the first step of our processing pipeline. File chunking is the process of splitting a file into smaller pieces called chunks. It can help us eliminate duplicate copies of repeating data on storage, and reduces the amount of data sent over the network by only selecting changed chunks.

Usually, a video file can be split into equal size chunks based on timestamps but Netflix instead splits chunks based on scenes. This slight variation becomes a huge factor for a better user experience since whenever the client requests a chunk from the server, there is a lower chance of interruption as a complete scene will be retrieved.

- **Content Filter**

This step checks if the video adheres to the content policy of the platform. This can be pre-approved as in the case of Netflix according to [content rating](https://en.wikipedia.org/wiki/Motion_picture_content_rating_system) of the media or can be strictly enforced like by YouTube.

This entire process is done by a machine learning model which performs copyright, piracy, and NSFW checks. If issues are found, we can push the task to a [dead-letter queue (DLQ)](https://karanpratapsingh.com/courses/system-design/message-queues#dead-letter-queues) and someone from the moderation team can do further inspection.

- **Transcoder**

[Transcoding](https://en.wikipedia.org/wiki/Transcoding) is a process in which the original data is decoded to an intermediate uncompressed format, which is then encoded into the target format. This process uses different [codecs](https://en.wikipedia.org/wiki/Video_codec) to perform bitrate adjustment, image downsampling, or re-encoding the media.

This results in a smaller size file and a much more optimized format for the target devices. Standalone solutions such as [FFmpeg](https://ffmpeg.org) or cloud-based solutions like [AWS Elemental MediaConvert](https://aws.amazon.com/mediaconvert) can be used to implement this step of the pipeline.

- **Quality Conversion**

This is the last step of the processing pipeline and as the name suggests, this step handles the conversion of the transcoded media from the previous step into different resolutions such as 4K, 1440p, 1080p, 720p, etc.

It allows us to fetch the desired quality of the video as per the user's request, and once the media file finishes processing, it gets uploaded to a distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs), [GlusterFS](https://www.gluster.org), or an [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) such as [Amazon S3](https://aws.amazon.com/s3) for later retrieval during streaming.

_Note: We can add additional steps such as subtitles and thumbnails generation as part of our pipeline._

**Why are we using a message queue?**

Processing videos as a long-running task and using a [message queue](https://karanpratapsingh.com/courses/system-design/message-queues) makes much more sense. It also decouples our video processing pipeline from the upload functionality. We can use something like [Amazon SQS](https://aws.amazon.com/sqs) or [RabbitMQ](https://www.rabbitmq.com) to support this.

### Video streaming

Video streaming is a challenging task from both the client and server perspectives. Moreover, internet connection speeds vary quite a lot between different users. To make sure users don't re-fetch the same content, we can use a [Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network).

Netflix takes this a step further with its [Open Connect](https://openconnect.netflix.com) program. In this approach, they partner with thousands of Internet Service Providers (ISPs) to localize their traffic and deliver their content more efficiently.

**What is the difference between Netflix's Open Connect and a traditional Content Delivery Network (CDN)?**

Netflix Open Connect is a purpose-built [Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) responsible for serving Netflix's video traffic. Around 95% of the traffic globally is delivered via direct connections between Open Connect and the ISPs their customers use to access the internet.

Currently, they have Open Connect Appliances (OCAs) in over 1000 separate locations around the world. In case of issues, Open Connect Appliances (OCAs) can failover, and the traffic can be re-routed to Netflix servers.

Additionally, we can use [Adaptive bitrate streaming](https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming) protocols such as [HTTP Live Streaming (HLS)](https://en.wikipedia.org/wiki/HTTP_Live_Streaming) which is designed for reliability and it dynamically adapts to network conditions by optimizing playback for the available speed of the connections.

Lastly, for playing the video from where the user left off (part of our extended requirements), we can simply use the `offset` property we stored in the `views` table to retrieve the scene chunk at that particular timestamp and resume the playback for the user.

### Searching

Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. [Elasticsearch](https://www.elastic.co) can help us with this use case.

[Elasticsearch](https://www.elastic.co) is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of [Apache Lucene](https://lucene.apache.org).

**How do we identify trending content?**

Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries in the last `N` seconds and update them every `M` seconds using some sort of batch job mechanism.

### Sharing

Sharing content is an important part of any platform, for this, we can have some sort of URL shortener service in place that can generate short URLs for the users to share.

_For more details, refer to the [URL Shortener](https://karanpratapsingh.com/courses/system-design/url-shortener) system design._

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Geo-blocking

Platforms like Netflix and YouTube use [Geo-blocking](https://en.wikipedia.org/wiki/Geo-blocking) to restrict content in certain geographical areas or countries. This is primarily done due to legal distribution laws that Netflix has to adhere to when they make a deal with the production and distribution companies. In the case of YouTube, this will be controlled by the user during the publishing of the content.

We can determine the user's location either using their [IP](https://karanpratapsingh.com/courses/system-design/ip) or region settings in their profile then use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) which supports a geographic restrictions feature or a [geolocation routing policy](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html) with [Amazon Route53](https://aws.amazon.com/route53) to restrict the content and re-route the user to an error page if the content is not available in that particular region or country.

### Recommendations

Netflix uses a machine learning model which uses the user's viewing history to predict what the user might like to watch next, an algorithm like [Collaborative Filtering](https://en.wikipedia.org/wiki/Collaborative_filtering) can be used.

However, Netflix (like YouTube) uses its own algorithm called Netflix Recommendation Engine which can track several data points such as:

- User profile information like age, gender, and location.
- Browsing and scrolling behavior of the user.
- Time and date a user watched a title.
- The device which was used to stream the content.
- The number of searches and what terms were searched.

_For more detail, refer to [Netflix recommendation research](https://research.netflix.com/research-area/recommendations)._

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using [Apache Spark](https://spark.apache.org) which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.

### Caching

In a streaming platform, caching is important. We have to be able to cache as much static media content as possible to improve user experience. We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) but what kind of cache eviction policy would best fit our needs?

**Which cache eviction policy to use?**

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Media streaming and storage

As most of our storage space will be used for storing media files such as thumbnails and videos. Per our discussion earlier, the media service will be handling both the upload and processing of media files.

We will use distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs), [GlusterFS](https://www.gluster.org), or an [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) such as [Amazon S3](https://aws.amazon.com/s3) for storage and streaming of the content.

### Content Delivery Network (CDN)

[Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) or [Cloudflare CDN](https://www.cloudflare.com/cdn) for this use case.

## Identify and resolve bottlenecks

![netflix-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.

# Uber

Let's design an [Uber](https://uber.com) like ride-hailing service, similar to services like [Lyft](https://www.lyft.com), [OLA Cabs](https://www.olacabs.com), etc.

## What is Uber?

Uber is a mobility service provider, allowing users to book rides and a driver to transport them in a way similar to a taxi. It is available on the web and mobile platforms such as Android and iOS.

## Requirements

Our system should meet the following requirements:

### Functional requirements

We will design our system for two types of users: Customers and Drivers.

**Customers**

- Customers should be able to see all the cabs in the vicinity with an ETA and pricing information.
- Customers should be able to book a cab to a destination.
- Customers should be able to see the location of the driver.

**Drivers**

- Drivers should be able to accept or deny the customer-requested ride.
- Once a driver accepts the ride, they should see the pickup location of the customer.
- Drivers should be able to mark the trip as complete on reaching the destination.

### Non-Functional requirements

- High reliability.
- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Customers can rate the trip after it's completed.
- Payment processing.
- Metrics and analytics.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

Let us assume we have 100 million daily active users (DAU) with 1 million drivers and on average our platform enables 10 million rides daily.

If on average each user performs 10 actions (such as request a check available rides, fares, book rides, etc.) we will have to handle 1 billion requests daily.

$$
100 \space million \times 10 \space actions = 1 \space billion/day
$$

**What would be Requests Per Second (RPS) for our system?**

1 billion requests per day translate into 12K requests per second.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Storage

If we assume each message on average is 400 bytes, we will require about 400 GB of database storage every day.

$$
1 \space billion \times 400 \space bytes = \sim 400 \space GB/day
$$

And for 10 years, we will require about 1.4 PB of storage.

$$
400 \space GB \times 10 \space years \times 365 \space days = \sim 1.4 \space PB
$$

### Bandwidth

As our system is handling 400 GB of ingress every day, we will require a minimum bandwidth of around 4 MB per second.

$$
\frac{400 \space GB}{(24 \space hrs \times 3600 \space seconds)} = \sim 5 \space MB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate    |
| ------------------------- | ----------- |
| Daily active users (DAU)  | 100 million |
| Requests per second (RPS) | 12K/s       |
| Storage (per day)         | ~400 GB     |
| Storage (10 years)        | ~1.4 PB     |
| Bandwidth                 | ~5 MB/s     |

## Data model design

This is the general data model which reflects our requirements.

![uber-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-datamodel.png)

We have the following tables:

**customers**

This table will contain a customer's information such as `name`, `email`, and other details.

**drivers**

This table will contain a driver's information such as `name`, `email`, `dob` and other details.

**trips**

This table represents the trip taken by the customer and stores data such as `source`, `destination`, and `status` of the trip.

**cabs**

This table stores data such as the registration number, and type (like Uber Go, Uber XL, etc.) of the cab that the driver will be driving.

**ratings**

As the name suggests, this table stores the `rating` and `feedback` for the trip.

**payments**

The payments table contains the payment-related data with the corresponding `tripID`.

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Request a Ride

Through this API, customers will be able to request a ride.

```tsx
requestRide(customerID: UUID, source: Tuple<float>, destination: Tuple<float>, cabType: Enum<string>, paymentMethod: Enum<string>): Ride
```

**Parameters**

Customer ID (`UUID`): ID of the customer.

Source (`Tuple<float>`): Tuple containing the latitude and longitude of the trip's starting location.

Destination (`Tuple<float>`): Tuple containing the latitude and longitude of the trip's destination.

**Returns**

Result (`Ride`): Associated ride information of the trip.

### Cancel the Ride

This API will allow customers to cancel the ride.

```tsx
cancelRide(customerID: UUID, reason?: string): boolean
```

**Parameters**

Customer ID (`UUID`): ID of the customer.

Reason (`UUID`): Reason for canceling the ride _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Accept or Deny the Ride

This API will allow the driver to accept or deny the trip.

```tsx
acceptRide(driverID: UUID, rideID: UUID): boolean
denyRide(driverID: UUID, rideID: UUID): boolean
```

**Parameters**

Driver ID (`UUID`): ID of the driver.

Ride ID (`UUID`): ID of the customer requested ride.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Start or End the Trip

Using this API, a driver will be able to start and end the trip.

```tsx
startTrip(driverID: UUID, tripID: UUID): boolean
endTrip(driverID: UUID, tripID: UUID): boolean
```

**Parameters**

Driver ID (`UUID`): ID of the driver.

Trip ID (`UUID`): ID of the requested trip.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Rate the Trip

This API will enable customers to rate the trip.

```tsx
rateTrip(customerID: UUID, tripID: UUID, rating: int, feedback?: string): boolean
```

**Parameters**

Customer ID (`UUID`): ID of the customer.

Trip ID (`UUID`): ID of the completed trip.

Rating (`int`): Rating of the trip.

Feedback (`string`): Feedback about the trip by the customer _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**Customer Service**

This service handles customer-related concerns such as authentication and customer information.

**Driver Service**

This service handles driver-related concerns such as authentication and driver information.

**Ride Service**

This service will be responsible for ride matching and quadtree aggregation. It will be discussed in detail separately.

**Trip Service**

This service handles trip-related functionality in our system.

**Payment Service**

This service will be responsible for handling payments in our system.

**Notification Service**

This service will simply send push notifications to the users. It will be discussed in detail separately.

**Analytics Service**

This service will be used for metrics and analytics use cases.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### How is the service expected to work?

Here's how our service is expected to work:

![uber-working](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-working.png)

1. Customer requests a ride by specifying the source, destination, cab type, payment method, etc.
2. Ride service registers this request, finds nearby drivers, and calculates the estimated time of arrival (ETA).
3. The request is then broadcasted to the nearby drivers for them to accept or deny.
4. If the driver accepts, the customer is notified about the live location of the driver with the estimated time of arrival (ETA) while they wait for pickup.
5. The customer is picked up and the driver can start the trip.
6. Once the destination is reached, the driver will mark the ride as complete and collect payment.
7. After the payment is complete, the customer can leave a rating and feedback for the trip if they like.

### Location Tracking

How do we efficiently send and receive live location data from the client (customers and drivers) to our backend? We have two different options:

**Pull model**

The client can periodically send an HTTP request to servers to report its current location and receive ETA and pricing information. This can be achieved via something like [Long polling](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling).

**Push model**

The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) or [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) for this.

The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) is a better choice because then we can push data to the client once it's available without any delay, given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) which are only unidirectional.

Additionally, the client application should have some sort of background job mechanism to ping GPS location while the application is in the background.

_Note: Learn more about [Long polling, WebSockets, Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events)._

### Ride Matching

We need a way to efficiently store and query nearby drivers. Let's explore different solutions we can incorporate into our design.

**SQL**

We already have access to the latitude and longitude of our customers, and with databases like [PostgreSQL](https://www.postgresql.org) and [MySQL](https://www.mysql.com) we can perform a query to find nearby driver locations given a latitude and longitude (X, Y) within a radius (R).

```sql
SELECT * FROM locations WHERE lat BETWEEN X-R AND X+R AND long BETWEEN Y-R AND Y+R
```

However, this is not scalable, and performing this query on large datasets will be quite slow.

**Geohashing**

[Geohashing](/courses/sytem-design/geohashing-and-quadtrees#geohashing) is a [geocoding](https://en.wikipedia.org/wiki/Address_geocoding) method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by [Gustavo Niemeyer](https://twitter.com/gniemeyer) in 2008.

Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.

![geohashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png)

For example, San Francisco with coordinates `37.7564, -122.4016` can be represented in geohash as `9q8yy9mf`.

Now, using the customer's geohash we can determine the nearest available driver by simply comparing it with the driver's geohash. For better performance, we will index and store the geohash of the driver in memory for faster retrieval.

**Quadtrees**

A [Quadtree](/courses/sytem-design/geohashing-and-quadtrees#quadtrees) is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of [Octrees](https://en.wikipedia.org/wiki/Octree) which are used to partition three-dimensional space.

![quadtree](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png)

Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates.

We can save further computation by only subdividing a node after a certain threshold.

![quadtree-subdivision](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png)

[Quadtree](/courses/sytem-design/geohashing-and-quadtrees#quadtrees) seems perfect for our use case, we can update the Quadtree every time we receive a new location update from the driver. To reduce the load on the quadtree servers we can use an in-memory datastore such as [Redis](https://redis.io) to cache the latest updates. And with the application of mapping algorithms such as the [Hilbert curve](https://en.wikipedia.org/wiki/Hilbert_curve), we can perform efficient range queries to find nearby drivers for the customer.

**What about race conditions?**

Race conditions can easily occur when a large number of customers will be requesting rides simultaneously. To avoid this, we can wrap our ride matching logic in a [Mutex](<https://en.wikipedia.org/wiki/Lock_(computer_science)>) to avoid any race conditions. Furthermore, every action should be transactional in nature.

_For more details, refer to [Transactions](https://karanpratapsingh.com/courses/system-design/transactions) and [Distributed Transactions](https://karanpratapsingh.com/courses/system-design/distributed-transactions)._

**How to find the best drivers nearby?**

Once we have a list of nearby drivers from the Quadtree servers, we can perform some sort of ranking based on parameters like average ratings, relevance, past customer feedback, etc. This will allow us to broadcast notifications to the best available drivers first.

**Dealing with high demand**

In cases of high demand, we can use the concept of Surge Pricing. Surge pricing is a dynamic pricing method where prices are temporarily increased as a reaction to increased demand and mostly limited supply. This surge price can be added to the base price of the trip.

_For more details, learn how [surge pricing works](https://www.uber.com/us/en/drive/driver-app/how-surge-works) with Uber._

### Payments

Handling payments at scale is challenging, to simplify our system we can use a third-party payment processor like [Stripe](https://stripe.com) or [PayPal](https://www.paypal.com). Once the payment is complete, the payment processor will redirect the user back to our application and we can set up a [webhook](https://en.wikipedia.org/wiki/Webhook) to capture all the payment-related data.

### Notifications

Push notifications will be an integral part of our platform. We can use a message queue or a message broker such as [Apache Kafka](https://kafka.apache.org) with the notification service to dispatch requests to [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) or [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications) which will handle the delivery of the push notifications to user devices.

_For more details, refer to the [WhatsApp](https://karanpratapsingh.com/courses/system-design/whatsapp#notifications) system design where we discuss push notifications in detail._

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can shard our database either based on existing [partition schemes](https://karanpratapsingh.com/courses/system-design/sharding#partitioning-criteria) or regions. If we divide the locations into regions using let's say zip codes, we can effectively store all the data in a given region on a fixed node. But this can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using [Apache Spark](https://spark.apache.org) which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.

### Caching

In a location services-based platform, caching is important. We have to be able to cache the recent locations of the customers and drivers for fast retrieval. We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) but what kind of cache eviction policy would best fit our needs?

**Which cache eviction policy to use?**

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

## Identify and resolve bottlenecks

![uber-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"
- "How can we make our notification system more robust?"

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.
- Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated [message broker](https://karanpratapsingh.com/courses/system-design/message-brokers) such as [Apache Kafka](https://kafka.apache.org) or [NATS](https://nats.io) to make our notification system more robust.

# Next Steps

Congratulations, you've finished the course!

Now that you know the fundamentals of System Design, here are some additional resources:

- [Distributed Systems](https://www.youtube.com/watch?v=UEAMfLPZZhE&list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB) (by Dr. Martin Kleppmann)
- [System Design Interview: An Insider's Guide](https://www.amazon.in/System-Design-Interview-insiders-Second/dp/B08CMF2CQF)
- [Microservices](https://microservices.io) (by Chris Richardson)
- [Serverless computing](https://en.wikipedia.org/wiki/Serverless_computing)
- [Kubernetes](https://kubernetes.io)

It is also recommended to actively follow engineering blogs of companies putting what we learned in the course into practice at scale:

- [Microsoft Engineering](https://engineering.microsoft.com)
- [Google Research Blog](http://googleresearch.blogspot.com)
- [Netflix Tech Blog](http://techblog.netflix.com)
- [AWS Blog](https://aws.amazon.com/blogs/aws)
- [Facebook Engineering](https://www.facebook.com/Engineering)
- [Uber Engineering Blog](http://eng.uber.com)
- [Airbnb Engineering](http://nerds.airbnb.com)
- [GitHub Engineering Blog](https://github.blog/category/engineering)
- [Intel Software Blog](https://software.intel.com/en-us/blogs)
- [LinkedIn Engineering](http://engineering.linkedin.com/blog)
- [Paypal Developer Blog](https://medium.com/paypal-engineering)
- [Twitter Engineering](https://blog.twitter.com/engineering)

Last but not least, volunteer for new projects at your company, and learn from senior engineers and architects to further improve your system design skills.

I hope this course was a great learning experience. I would love to hear feedback from you.

Wishing you all the best for further learning!

# References

Here are the resources that were referenced while creating this course.

- [Cloudflare learning center](https://www.cloudflare.com/learning)
- [IBM Blogs](https://www.ibm.com/blogs)
- [Fastly Blogs](https://www.fastly.com/blog)
- [NS1 Blogs](https://ns1.com/blog)
- [Grokking the System Design Interview](https://www.designgurus.io/course/grokking-the-system-design-interview)
- [Grokking Microservices Design Patterns](https://www.designgurus.io/course/grokking-microservices-design-patterns)
- [System Design Primer](https://github.com/donnemartin/system-design-primer)
- [AWS Blogs](https://aws.amazon.com/blogs)
- [Architecture Patterns by Microsoft](https://learn.microsoft.com/en-us/azure/architecture/patterns)
- [Martin Fowler](https://martinfowler.com)
- [PagerDuty resources](https://www.pagerduty.com/resources)
- [VMWare Blogs](https://blogs.vmware.com/learning)

_All the diagrams were made using [Excalidraw](https://excalidraw.com) and are available [here](https://github.com/karanpratapsingh/system-design/tree/main/diagrams)._
