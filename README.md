WIP: Это перевод основного репозитория по системному дизайну.

# Системный дизайн

Добро пожаловать на курс. Надеюсь, вы получите удовольствие от обучения.

_Этот курс также доступен по ссылке [website](https://karanpratapsingh.com/courses/system-design) и в виде электронной книги [leanpub](https://leanpub.com/systemdesign). Пожалуйста поставьте ⭐ для мотивации, если этот курс был полезным для вас!_

# Содержание

- **Приступая к работе**

  - [Что такое системный дизайн](#what-is-system-design)

- **Часть I**

  - [IP](#ip)
  - [Модель OSI](#osi-model)
  - [TCP и UDP](#tcp-and-udp)
  - [Система доменных имён (DNS)](#domain-name-system-dns)
  - [Балансировка нагрузки](#load-balancing)
  - [Кластеры](#clustering)
  - [Кеширование](#caching)
  - [Content Delivery Network (CDN)](#content-delivery-network-cdn)
  - [Прокси](#proxy)
  - [Доступность](#availability)
  - [Масштабируемость](#scalability)
  - [Хранилище](#storage)

- **Часть II**

  - [Базы данных и СУБД](#databases-and-dbms)
  - [SQL базы данных](#sql-databases)
  - [NoSQL базы данных](#nosql-databases)
  - [SQL vs NoSQL](#sql-vs-nosql-databases)
  - [Реплицирование баз данных](#database-replication)
  - [Индексы](#indexes)
  - [Нормализация и денормализация](#normalization-and-denormalization)
  - [ACID и BASE модели согласованности](#acid-and-base-consistency-models)
  - [CAP теорема](#cap-theorem)
  - [PACELC теорема](#pacelc-theorem)
  - [Транзакции](#transactions)
  - [Распределённые транзакции](#distributed-transactions)
  - [Шардирование](#sharding)
  - [Согласованное хеширование](#consistent-hashing)
  - [Федерация баз данных](#database-federation)

- **Часть III**

  - [N-уровневая архитектура](#n-tier-architecture)
  - [Брокеры сообщений](#message-brokers)
  - [Очереди сообщений](#message-queues)
  - [Модель Издатель — подписчик(PUB-SUB)](#publish-subscribe)
  - [Корпоративная сервисная шина (ESB)](#enterprise-service-bus-esb)
  - [Монолиты и Микросервисы](#monoliths-and-microservices)
  - [Событийно-ориентированная архитектура (EDA)](#event-driven-architecture-eda)
  - [Источники событий](#event-sourcing)
  - [Command and Query Responsibility Segregation (CQRS)](#command-and-query-responsibility-segregation-cqrs)
  - [API Gateway](#api-gateway)
  - [REST, GraphQL, gRPC](#rest-graphql-grpc)
  - [Длинные опросы, Web сокеты, Server-Sent Events (SSE)](#long-polling-websockets-server-sent-events-sse)

- **Часть IV**

  - [Геохеширование и квадродерево](#geohashing-and-quadtrees)
  - [Circuit breaker](#circuit-breaker)
  - [Rate Limiting](#rate-limiting)
  - [Service Discovery](#service-discovery)
  - [SLA, SLO, SLI](#sla-slo-sli)
  - [Disaster recovery](#disaster-recovery)
  - [Virtual Machines (VMs) and Containers](#virtual-machines-vms-and-containers)
  - [OAuth 2.0 and OpenID Connect (OIDC)](#oauth-20-and-openid-connect-oidc)
  - [Single Sign-On (SSO)](#single-sign-on-sso)
  - [SSL, TLS, mTLS](#ssl-tls-mtls)

- **Часть V**

  - [System Design Interviews](#system-design-interviews)
  - [URL Shortener](#url-shortener)
  - [WhatsApp](#whatsapp)
  - [Twitter](#twitter)
  - [Netflix](#netflix)
  - [Uber](#uber)

- **Дополнения**

  - [Next Steps](#next-steps)
  - [References](#references)

# Что такое системный дизайн?

Прежде чем мы начнем этот курс, давайте поговорим о том, что вообще такое системный дизайн.

Проектирование системы - это процесс определения архитектуры, интерфейсов и данных для системы, удовлетворяющей определенным требованиям. Системный дизайн удовлетворяет потребности вашего бизнеса или организации с помощью слаженных и эффективных систем. Он требует систематического подхода к созданию и проектированию систем. Хороший системный дизайн требует, чтобы мы думали обо всем, начиная с инфраструктуры и заканчивая данными и способами их хранения.


## Why is System Design so important?

Проектирование системы помогает нам определить решение, которое отвечает требованиям бизнеса. Это
одно из самых ранних решений, которые мы можем принять при создании системы. Часто очень важно
мыслить на высоком уровне, поскольку эти решения очень сложно исправить впоследствии. Это
также облегчает рассуждения и управление архитектурными изменениями по мере развития системы.

# IP

IP-адрес - это уникальный адрес, идентифицирующий устройство в Интернете или локальной сети. IP расшифровывается как _"Интернет-протокол"_, который представляет собой набор правил, определяющих формат данных, передаваемых через Интернет или локальную сеть.

По сути, IP-адреса - это идентификатор, позволяющий пересылать информацию между устройствами в сети. Они содержат информацию о местоположении и делают устройства доступными для связи. Интернету необходим способ различать разные компьютеры, маршрутизаторы и веб-сайты. IP-адреса обеспечивают такой способ и являются важной частью работы интернета.

## Versions

Теперь давайте узнаем о различных версиях IP-адресов:

### IPv4

Оригинальный протокол Интернета - IPv4, использующий 32-битную цифровую десятичную систему счисления, которая позволяет использовать только около 4 миллиардов IP-адресов. Изначально этого было более чем достаточно, но по мере распространения Интернета нам потребовалось что-то лучшее.

_Пример: `102.22.192.181`._

### IPv6

IPv6 - это новый протокол, который был представлен в 1998 году. Его развертывание началось в середине 2000-х годов, а поскольку число пользователей Интернета растет в геометрической прогрессии, оно продолжается до сих пор.

Этот новый протокол использует 128-битную буквенно-цифровую шестнадцатеричную нотацию. Это означает, что IPv6 может предоставить около ~340e+36 IP-адресов. Этого более чем достаточно, чтобы удовлетворить растущий спрос на годы вперед.

_Пример: `2001:0db8:85a3:0000:0000:8a2e:0370:7334`_

## Types

Давайте обсудим типы IP-адресов:

### Public

Публичный IP-адрес - это адрес, в котором один основной адрес связан со всей вашей сетью. При таком типе IP-адреса каждое из подключенных устройств имеет один и тот же IP-адрес.

Пример: IP-адрес, предоставленный вашему маршрутизатору интернет-провайдером.

### Private

Частный IP-адрес - это уникальный IP-номер, присваиваемый каждому устройству, которое подключается к вашей интернет-сети, включая такие устройства, как компьютеры, планшеты и смартфоны, используемые в вашем доме.

Пример: IP-адреса, генерируемые домашним маршрутизатором для ваших устройств.

### Static

Статический IP-адрес не меняется и создается вручную, а не назначается. Такие адреса обычно стоят дороже, но они более надежны.

_Пример: Они обычно используются для таких важных вещей, как надежные службы геолокации, удаленный доступ, хостинг серверов и т. д._

### Dynamic

Динамический IP-адрес время от времени меняется и не всегда является одним и тем же. Он назначается сервером [Dynamic Host Configuration Protocol (DHCP)](https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol). Динамические IP-адреса - самый распространенный тип адресов интернет-протокола. Они дешевле в развертывании и позволяют нам повторно использовать IP-адреса в сети по мере необходимости.

_Пример: Они чаще всего используются для потребительского оборудования и личного пользования._

# OSI Model

Модель OSI - это логическая и концептуальная модель, определяющая сетевые коммуникации, используемые системами, открытыми для взаимодействия и связи с другими системами. Модель OSI (Open System Interconnection) также определяет логическую сеть и эффективно описывает передачу компьютерных пакетов с помощью протоколов различных уровней.

Модель OSI можно рассматривать как универсальный язык для компьютерных сетей. В ее основе лежит концепция разделения коммуникационной системы на семь абстрактных уровней, каждый из которых накладывается на предыдущий.

## Why does the OSI model matter?

Модель Open System Interconnection (OSI) определила общую терминологию, используемую в обсуждениях и документации по сетевым технологиям. Это позволяет нам разобрать очень сложный коммуникационный процесс на части и оценить его компоненты.

Хотя эта модель не реализована напрямую в наиболее распространенных сегодня сетях TCP/IP, она все равно может помочь нам сделать гораздо больше, например:

- Облегчить поиск и устранение неисправностей и помочь выявить угрозы во всем стеке.
- Поощрять производителей оборудования к созданию сетевых продуктов, которые могут взаимодействовать друг с другом по сети.
- Очень важно для развития мышления, ориентированного на безопасность.
- Разделение сложной функции на более простые компоненты.
  
## Layers

Семь уровней абстракции модели OSI можно определить следующим образом, сверху вниз:

![osi-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/osi-model/osi-model.png)

### Application

Это единственный уровень, который напрямую взаимодействует с данными, поступающими от пользователя. Программные приложения, такие как веб-браузеры и почтовые клиенты, полагаются на прикладной уровень для инициирования взаимодействия. Однако следует уточнить, что клиентские приложения не являются частью прикладного уровня, скорее, прикладной уровень отвечает за протоколы и манипуляции с данными, на которые опирается программное обеспечение для представления значимых данных пользователю. К протоколам прикладного уровня относятся такие как HTTP иSMTP.

### Presentation

Презентационный уровень также называют уровнем трансляции. Данные с прикладного уровня извлекаются здесь и манипулируются в соответствии с требуемым форматом для передачи по сети. Функции презентационного уровня - перевод, шифрование/дешифрование и сжатие.

### Session

Это уровень, отвечающий за открытие и закрытие связи между двумя устройствами. Время между открытием и закрытием связи называется сессией. Сессионный уровень обеспечивает, чтобы сессия оставалась открытой достаточно долго, чтобы передать все данные, которыми обмениваются, а затем быстро закрывает сессию, чтобы не тратить ресурсы впустую. Сессионный уровень также синхронизирует передачу данных с контрольными точками.

### Transport

Транспортный уровень (также известный как уровень 4) отвечает за сквозную передачу данных между двумя устройствами. Он включает в себя получение данных от сеансового уровня и разбиение их на фрагменты, называемые сегментами, перед отправкой на сетевой уровень (уровень 3). Он также отвечает за сборку сегментов на принимающем устройстве в данные, которые может использовать сеансовый уровень.

### Network

Сетевой уровень отвечает за передачу данных между двумя различными сетями. Сетевой уровень разбивает сегменты транспортного уровня на более мелкие единицы, называемые пакетами, на устройстве отправителя и собирает эти пакеты на устройстве получателя. Сетевой уровень также находит наилучший физический путь для передачи данных к месту назначения, что называется маршрутизацией. Если два взаимодействующих устройства находятся в одной сети, то сетевой уровень не нужен.

### Data Link

Канальный уровень очень похож на сетевой уровень, за исключением того, что канальный уровень облегчает передачу данных между двумя устройствами в одной сети. Канальный уровень получает пакеты с сетевого уровня и разбивает их на более мелкие фрагменты, называемые кадрами.

### Physical

Этот уровень включает в себя физическое оборудование, участвующее в передаче данных, например кабели и коммутаторы. Именно на этом уровне данные преобразуются в битовый поток, представляющий собой последовательность 1 и 0. Физический уровень обоих устройств также должен согласовать сигнальные соглашения, чтобы 1 и 0 можно было отличить на обоих устройствах.

# TCP and UDP

## TCP

Протокол управления передачей (TCP) ориентирован на соединение, то есть после установления соединения данные могут передаваться в обоих направлениях. TCP имеет встроенные системы проверки на наличие ошибок и гарантирует, что данные будут доставлены в том порядке, в котором они были отправлены, что делает его идеальным протоколом для передачи такой информации, как неподвижные изображения, файлы данных и веб-страницы.
![tcp](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/tcp.png)

Но хотя TCP инстинктивно надежен, его механизмы обратной связи также приводят к большим накладным расходам, что приводит к большему использованию доступной полосы пропускания в сети.

## UDP

User Datagram Protocol (UDP) - это более простой интернет-протокол без соединений, в котором не требуются службы проверки и восстановления ошибок. В UDP нет накладных расходов на открытие соединения, поддержание соединения или его прерывание. Данные постоянно отправляются получателю, независимо от того, получены они или нет.

![udp](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/udp.png)

Его предпочитают использовать для связи в реальном времени, например, для широковещательной или многоадресной передачи данных по сети. Мы должны использовать UDP вместо TCP, когда нам нужна наименьшая задержка, а задержка данных хуже, чем их потеря.

## TCP vs UDP

TCP - это протокол, ориентированный на соединение, в то время как UDP - протокол без соединения. Ключевым различием между TCP и UDP является скорость, поскольку TCP сравнительно медленнее UDP. В целом UDP является более быстрым, простым и эффективным протоколом, однако повторная передача потерянных пакетов данных возможна только при использовании TCP.

TCP обеспечивает упорядоченную доставку данных от пользователя к серверу (и наоборот), в то время как UDP не предназначен для сквозной передачи данных и не проверяет готовность получателя.

| Характеристика | TCP | UDP |
| ------------------- | ------------------------------------------- | ---------------------------------- |
Соединение | Требуется установленное соединение | Протокол без соединения | Гарантированная доставка | Может гарантировать доставку.
| Гарантированная доставка | Может гарантировать доставку данных | Не может гарантировать доставку данных |
| Повторная передача | Повторная передача потерянных пакетов возможна | Повторная передача потерянных пакетов невозможна |
| Скорость | Медленнее, чем UDP | Быстрее, чем TCP |
| Широковещание | Не поддерживает широковещание | Поддерживает широковещание |

# Domain Name System (DNS)

Ранее мы узнали об IP-адресах, которые позволяют каждой машине соединяться с другими машинами. Но, как мы знаем, людям удобнее работать с именами, чем с цифрами. Легче запомнить такое имя, как `google.com`, чем что-то вроде `122.250.192.232`.

Это привело нас к системе доменных имен (DNS), которая представляет собой иерархическую и децентрализованную систему именования, используемую для преобразования человекочитаемых доменных имен в IP-адреса.

## How DNS works

![how-dns-works](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/domain-name-system/how-dns-works.png)

Поиск DNS включает в себя следующие восемь шагов:

1. Клиент набирает [example.com](http://example.com) в веб-браузере, запрос отправляется в Интернет и поступает на DNS-резольвер.
2. Затем резолвер рекурсивно запрашивает корневой сервер имен DNS.
3. Корневой сервер отвечает на запрос с адресом домена верхнего уровня (TLD).
4. Затем преобразователь делает запрос к ДВУ `.com`.
5. Сервер ДВУ отвечает IP-адресом сервера имен домена [example.com](http://example.com).
6. Наконец, рекурсивный преобразователь отправляет запрос серверу имен домена.
7. IP-адрес [example.com](http://example.com) возвращается на преобразователь с сервера имен.
8. Затем DNS-резольвер отвечает веб-браузеру IP-адресом домена, запрошенного изначально.

После разрешения IP-адреса клиент должен иметь возможность запрашивать содержимое с разрешенного IP-адреса. Например, разрешенный IP-адрес может вернуть веб-страницу для отображения в браузере.

## Server types

Теперь давайте рассмотрим четыре основные группы серверов, составляющих инфраструктуру DNS.

### DNS Resolver

DNS-резольвер (также известный как рекурсивный DNS-резольвер) - это первая остановка при выполнении DNS-запроса. Рекурсивный резолвер выступает в роли посредника между клиентом и сервером имен DNS. После получения DNS-запроса от веб-клиента рекурсивный преобразователь либо отвечает кэшированными данными, либо отправляет запрос на корневой сервер имен, затем еще один запрос на сервер имен ДВУ, а затем последний запрос на авторитетный сервер имен. После получения ответа от авторитетного сервера имен, содержащего запрашиваемый IP-адрес, рекурсивный преобразователь отправляет ответ клиенту.

### DNS root server

Корневой сервер принимает запрос рекурсивного распознавателя, включающий доменное имя, а корневой сервер имен отвечает на него, направляя рекурсивный распознаватель на сервер имен ДВУ, основанный на расширении этого домена (`.com`, `.net`, `.org` и т. д.). Корневые серверы имен контролируются некоммерческой организацией под названием [Internet Corporation for Assigned Names and Numbers (ICANN)](https://www.icann.org).

Каждому рекурсивному преобразователю известно 13 корневых серверов имен DNS. Обратите внимание, что, хотя существует 13 корневых серверов имен, это не означает, что в системе корневых серверов имен только 13 машин. Существует 13 типов корневых серверов имен, но каждый из них имеет несколько копий по всему миру, которые используют [Anycast routing](https://en.wikipedia.org/wiki/Anycast) для обеспечения быстрых ответов.

### TLD nameserver

Сервер имен TLD хранит информацию обо всех доменных именах, имеющих общее расширение домена, например `.com`, `.net` или то, что идет после последней точки в URL.

Управлением серверами имен TLD занимается [Internet Assigned Numbers Authority (IANA)](https://www.iana.org), который является подразделением [ICANN](https://www.icann.org). IANA разделяет серверы TLD на две основные группы:

- **Общие домены верхнего уровня**: Это домены типа `.com`, `.org`, `.net`, `.edu` и `.gov`.
- **Домены верхнего уровня с кодом страны**: К ним относятся любые домены, относящиеся к определенной стране или государству. Примеры: `.uk`, `.us`, `.ru` и `.jp`.

### Authoritative DNS server

Авторитативный сервер имен обычно является последним шагом в поиске IP-адреса. Авторитативный сервер имен содержит информацию, специфичную для обслуживаемого им доменного имени (например, [google.com](http://google.com)), и он может предоставить рекурсивному резолверу IP-адрес этого сервера, найденный в записи A DNS, или, если домен имеет запись CNAME (псевдоним), он предоставит рекурсивному резолверу псевдоним домена, и тогда рекурсивному резолверу придется выполнить новый поиск DNS, чтобы получить запись от авторитетного сервера имен (часто это запись A, содержащая IP-адрес). Если он не может найти домен, возвращается сообщение NXDOMAIN.

## Query Types

В системе DNS существует три типа запросов:

### Recursive

При рекурсивном запросе DNS-клиент требует, чтобы DNS-сервер (обычно рекурсивный преобразователь DNS) ответил клиенту либо запрошенной записью ресурса, либо сообщением об ошибке, если преобразователь не может найти эту запись.

### Iterative

При итеративном запросе DNS-клиент указывает имя хоста, а DNS-резольвер возвращает наилучший ответ. Если DNS-резольвер имеет соответствующие записи DNS в своем кэше, он возвращает их. Если нет, он направляет клиента DNS к корневому серверу или другому авторитетному серверу имен, который находится ближе всего к требуемой зоне DNS. Затем DNS-клиент должен повторить запрос непосредственно к DNS-серверу, на который он был направлен.

### Non-recursive

Нерекурсивный запрос - это запрос, в котором DNS-резольвер уже знает ответ. Он либо сразу возвращает запись DNS, поскольку уже хранит ее в локальном кэше, либо запрашивает сервер имен DNS, который является авторитетным для этой записи, то есть у него точно есть правильный IP для этого имени хоста. В обоих случаях нет необходимости в дополнительных раундах запросов (как в рекурсивных или итеративных запросах). Вместо этого клиенту сразу же возвращается ответ.

## Record Types

DNS-записи (они же файлы зон) - это инструкции, которые хранятся на авторитетных DNS-серверах и предоставляют информацию о домене, в том числе о том, какой IP-адрес связан с этим доменом и как обрабатывать запросы для этого домена.

Эти записи состоят из серии текстовых файлов, записанных в так называемом _синтаксисе DNS_. Синтаксис DNS - это просто строка символов, используемых в качестве команд, которые указывают DNS-серверу, что делать. Все записи DNS также имеют значение _"TTL"_, что означает "время жизни" и указывает, как часто DNS-сервер будет обновлять эту запись.

Существует больше типов записей, но сейчас мы рассмотрим некоторые из наиболее часто используемых:

- **A (Address record)**: Это запись, содержащая IP-адрес домена.
- **AAA (запись адреса IP версии 6)**: Запись, содержащая IPv6-адрес домена (в отличие от A-записей, в которых хранится IPv4-адрес).
- **CNAME (запись канонического имени)**: Перенаправляет один домен или поддомен на другой домен, НЕ предоставляет IP-адрес.
- **MX (запись почтового обменника)**: Направляет почту на почтовый сервер.
- **TXT (текстовая запись)**: Эта запись позволяет администратору хранить в ней текстовые заметки. Эти записи часто используются для обеспечения безопасности электронной почты.
- **NS (записи сервера имен)**: Хранит сервер имен для записи DNS.
- **SOA (Start of Authority)**: Хранит информацию администратора о домене.
- **SRV (Service Location record)**: Определяет порт для определенных служб.
- **PTR (Reverse-lookup Pointer record)**: Указывает доменное имя при обратном поиске.
- **CERT (запись сертификата)**: Хранит сертификаты открытых ключей.

## Subdomains

Поддомен - это дополнительная часть основного доменного имени. Обычно он используется для логического разделения сайта на разделы. Мы можем создать несколько поддоменов или дочерних доменов на основном домене.

Например, `blog.example.com`, где `blog` - это поддомен, `example` - основной домен, а `.com` - домен верхнего уровня (TLD). Аналогичными примерами могут быть `support.example.com` или `careers.example.com`.

## DNS Zones

Зона DNS - это отдельная часть пространства доменных имен, которая делегируется юридическому лицу, например человеку, организации или компании, которые отвечают за поддержание зоны DNS. Зона DNS - это также административная функция, позволяющая осуществлять детальный контроль над компонентами DNS, такими как авторитативные серверы имен.

## DNS Caching

Кэш DNS (иногда называемый кэшем DNS-резольвера) - это временная база данных, поддерживаемая операционной системой компьютера, которая содержит записи обо всех последних посещениях и попытках посещения веб-сайтов и других интернет-доменов. Другими словами, кэш DNS - это просто память последних обращений к DNS, к которой наш компьютер может быстро обратиться, когда пытается понять, как загрузить веб-сайт.

Система доменных имен устанавливает время жизни (TTL) для каждой записи DNS. TTL определяет количество секунд, в течение которых запись может кэшироваться клиентом или сервером DNS. Когда запись сохраняется в кэше, вместе с ней сохраняется и значение TTL. Сервер продолжает обновлять TTL записи, хранящейся в кэше, отсчитывая каждую секунду. Когда оно достигнет нуля, запись будет удалена или очищена из кэша. В этот момент, если поступает запрос на эту запись, DNS-сервер должен начать процесс разрешения.

## Reverse DNS

Обратный поиск DNS - это запрос DNS на получение доменного имени, связанного с заданным IP-адресом. Это противоположно более распространенному прямому DNS-поиску, при котором система DNS запрашивается для возврата IP-адреса. В процессе обратного преобразования IP-адреса используются записи PTR. Если у сервера нет PTR-записи, он не сможет выполнить обратный поиск.

Обратный поиск обычно используется серверами электронной почты. Серверы электронной почты проверяют, пришло ли сообщение электронной почты с действительного сервера, прежде чем принять его в свою сеть. Многие серверы электронной почты будут отклонять сообщения с серверов, не поддерживающих обратный поиск, или с серверов, которые с большой вероятностью не являются легитимными.

_Примечание: обратный поиск DNS не является общепринятым, поскольку он не является критическим для нормального функционирования Интернета._

## Examples

Вот некоторые широко используемые управляемые решения для DNS:

- [Route53](https://aws.amazon.com/route53)
- [Cloudflare DNS](https://www.cloudflare.com/dns)
- [Google Cloud DNS](https://cloud.google.com/dns)
- [Azure DNS](https://azure.microsoft.com/en-in/services/dns)
- [NS1](https://ns1.com/products/managed-dns)

# Load Balancing

Балансировка нагрузки позволяет распределять входящий сетевой трафик между несколькими ресурсами, обеспечивая высокую доступность и надежность за счет отправки запросов только на те ресурсы, которые находятся в режиме онлайн. Это позволяет добавлять или убирать ресурсы в зависимости от потребностей.

![Балансировка нагрузки](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer.png)

Для дополнительной масштабируемости и избыточности мы можем попытаться сбалансировать нагрузку на каждом уровне нашей системы:

![load-balancing-layers](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer-layers.png)

## But why?

Современные веб-сайты с высокой посещаемостью должны обслуживать сотни тысяч, а то и миллионы одновременных запросов от пользователей или клиентов. Чтобы экономически эффективно масштабироваться для удовлетворения таких больших объемов, современные вычислительные технологии обычно требуют добавления дополнительных серверов.

Балансировщик нагрузки может находиться перед серверами и направлять запросы клиентов между всеми серверами, способными выполнить эти запросы, таким образом, чтобы максимально увеличить скорость и загрузку мощностей. Это гарантирует, что ни один сервер не будет перегружен, что может привести к снижению производительности. Если один сервер выходит из строя, балансировщик нагрузки перенаправляет трафик на оставшиеся серверы. Когда в группу серверов добавляется новый сервер, балансировщик нагрузки автоматически начинает отправлять на него запросы.

## Workload distribution

Это основной функционал, предоставляемый балансировщиком нагрузки, который имеет несколько общих вариаций:

- **На основе хоста**: Распределяет запросы на основе запрашиваемого имени хоста.
- **На основе пути**: Использование всего URL для распределения запросов, а не только имени хоста.
- **На основе содержимого**: Проверяет содержимое сообщения в запросе. Это позволяет распределять запросы на основе содержимого, например значения параметра.

## Layers

Как правило, балансировщики нагрузки работают на одном из двух уровней:

### Сетевой уровень

Это балансировщик нагрузки, работающий на транспортном уровне сети, также известном как уровень 4. Он выполняет маршрутизацию на основе сетевой информации, такой как IP-адреса, и не может выполнять маршрутизацию на основе контента. Часто это специализированные аппаратные устройства, способные работать на высокой скорости.

### Прикладной уровень

Это балансировщик нагрузки, работающий на прикладном уровне, также известном как уровень 7. Балансировщики нагрузки могут читать запросы целиком и выполнять маршрутизацию на основе содержимого. Это позволяет управлять нагрузкой на основе полного понимания трафика.

## Типы

Давайте рассмотрим различные типы балансировщиков нагрузки:

### Программные

Программные балансировщики нагрузки обычно проще развернуть, чем аппаратные. Они также более экономичны и гибки, и их используют вместе со средами разработки программного обеспечения. Программный подход дает нам возможность гибко настраивать балансировщик нагрузки в соответствии с конкретными потребностями нашей среды. Повышение гибкости может быть связано с необходимостью выполнять больше работы по настройке балансировщика нагрузки. По сравнению с аппаратными версиями, которые предлагают более закрытый подход, программные балансировщики дают нам больше свободы для внесения изменений и обновлений.

Программные балансировщики нагрузки широко распространены и предлагаются либо в виде устанавливаемых решений, требующих настройки и управления, либо в виде управляемых облачных сервисов.

### Аппаратные

Как следует из названия, аппаратный балансировщик нагрузки опирается на физическое, локальное оборудование для распределения приложений и сетевого трафика. Эти устройства могут обрабатывать большой объем трафика, но часто имеют высокую цену и довольно ограничены в гибкости.

Аппаратные балансировщики нагрузки имеют собственное встроенное программное обеспечение, которое требует обслуживания и обновления по мере выхода новых версий и исправлений безопасности.

Балансировка нагрузки DNS - это практика настройки домена в системе доменных имен (DNS) таким образом, чтобы клиентские запросы к домену распределялись между группой серверных машин.

К сожалению, балансировка нагрузки DNS имеет присущие ей проблемы, ограничивающие ее надежность и эффективность. Прежде всего, DNS не проверяет серверы и сети на наличие сбоев или ошибок. Он всегда возвращает один и тот же набор IP-адресов для домена, даже если серверы не работают или недоступны.

## Алгоритмы распределения запросов

Теперь давайте обсудим часто используемые алгоритмы маршрутизации:

- **Round-robin**: Запросы распределяются между серверами приложений по очереди.
- **Weighted Round-robin**: Развивает простую технику Round-robin для учета различий в характеристиках серверов, таких как производительность вычислений и обработка трафика, с помощью весов, которые могут быть назначены администратором через DNS-записи.
- **Наименьшие соединения**: Новый запрос отправляется на сервер с наименьшим количеством текущих соединений с клиентами. Относительная вычислительная мощность каждого сервера учитывается при определении сервера с наименьшим количеством соединений.
- **Наименьшее время отклика**: Отправляет запросы на сервер, выбранный по формуле, сочетающей самое быстрое время отклика и наименьшее количество активных соединений.
- **Наименьшая пропускная способность**: Этот метод измеряет трафик в мегабитах в секунду (Мбит/с), отправляя запросы клиентов на сервер с наименьшим трафиком в Мбит/с.
- **Хеширование**: Распределяет запросы на основе определенного нами ключа, например IP-адреса клиента или URL-адреса запроса.

## Преимущества

Балансировка нагрузки также играет ключевую роль в предотвращении простоев. Среди других преимуществ балансировки нагрузки можно выделить следующие:

- Масштабируемость
- Избыточность
- Гибкость
- Эффективность

## Избыточные балансировщики нагрузки

Как вы уже, наверное, догадались, сам балансировщик нагрузки может быть единственной точкой отказа. Чтобы преодолеть это, можно использовать второй или `N` количество балансировщиков нагрузки в режиме кластера.

И если произойдет сбой и _активный_ балансировщик нагрузки выйдет из строя, другой _резервный_ балансировщик нагрузки сможет взять на себя его функции, что сделает нашу систему более отказоустойчивой.

![redundant-load-balancing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/redundant-load-balancer.png)

## Особенности

Вот некоторые часто востребованные функции балансировщиков нагрузки:

- **Автомасштабирование**: Запуск и отключение ресурсов в зависимости от спроса.
- **Липкие сессии**: Возможность назначить одного и того же пользователя или устройство на один и тот же ресурс, чтобы сохранить состояние сессии на ресурсе.
- **Проверка здоровья**: Возможность определить, что ресурс не работает или работает плохо, чтобы удалить его из пула балансировки нагрузки.
- **Персистентные соединения**: Позволяет серверу открывать постоянное соединение с клиентом, например WebSocket.
- **Шифрование**: Работа с зашифрованными соединениями, такими как TLS и SSL.
- **Сертификаты**: Представление сертификатов клиенту и проверка подлинности клиентских сертификатов.
- **Сжатие**: Сжатие ответов.
- **Кэширование**: Балансировщик нагрузки прикладного уровня может предлагать возможность кэширования ответов.
- **Запись в журнал**: Ведение журнала метаданных запросов и ответов может служить важным аудиторским следом или источником аналитических данных.
- **Отслеживание запросов**: Присвоение каждому запросу уникального идентификатора для целей ведения журнала, мониторинга и устранения неполадок.
- **Переадресация**: Возможность перенаправления входящего запроса на основе таких факторов, как запрашиваемый путь.
- **Фиксированный ответ**: Возвращение статического ответа на запрос, например сообщения об ошибке.
## Examples

Ниже перечислены некоторые решения по балансировке нагрузки, широко используемые в отрасли:

- [Amazon Elastic Load Balancing](https://aws.amazon.com/elasticloadbalancing)
- [Azure Load Balancing](https://azure.microsoft.com/en-in/services/load-balancer)
- [GCP Load Balancing](https://cloud.google.com/load-balancing)
- [DigitalOcean Load Balancer](https://www.digitalocean.com/products/load-balancer)
- [Nginx](https://www.nginx.com)
- [HAProxy](http://www.haproxy.org)

# Кластеризация

В общем случае компьютерный кластер - это группа из двух или более компьютеров, или узлов, которые работают параллельно для достижения общей цели. Это позволяет распределять между узлами кластера рабочие нагрузки, состоящие из большого количества отдельных, распараллеливаемых задач. В результате эти задачи могут использовать совокупную память и вычислительную мощность каждого компьютера для повышения общей производительности.

Для создания компьютерного кластера отдельные узлы должны быть подключены к сети, чтобы обеспечить межузловое взаимодействие. Затем с помощью программного обеспечения можно объединить узлы вместе и сформировать кластер. Он может иметь общее устройство хранения данных и/или локальное хранилище на каждом узле.

![cluster](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/cluster.png)

Как правило, хотя бы один узел назначается лидером и выступает в качестве точки входа в кластер. Ведущий узел может отвечать за делегирование входящей работы другим узлам и, при необходимости, агрегировать результаты и возвращать ответ пользователю.

В идеале кластер функционирует как единая система. Пользователь, обращающийся к кластеру, не должен знать, является ли система кластером или отдельной машиной. Кроме того, кластер должен быть спроектирован таким образом, чтобы минимизировать задержки и предотвратить узкие места в коммуникации между узлами.


## Типы

Компьютерные кластеры можно разделить на три типа:

- Высокая доступность или отказоустойчивость
- Балансировка нагрузки
- Высокопроизводительные вычисления

## Конфигурации

Две наиболее часто используемые конфигурации кластеризации высокой доступности (HA) - активно-активная и активно-пассивная.

### Active-Active

![active-active](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-active.png)

Активно-активный кластер обычно состоит как минимум из двух узлов, на которых одновременно активно работает один и тот же вид сервиса. Основная цель активно-активного кластера - добиться балансировки нагрузки. Балансировщик нагрузки распределяет рабочие нагрузки между всеми узлами, чтобы предотвратить перегрузку какого-либо одного узла. Поскольку для обслуживания доступно больше узлов, повышается пропускная способность и время отклика.

### Active-Passive

![active-passive](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-passive.png)

Как и конфигурация активно-пассивного кластера, активно-пассивный кластер также состоит как минимум из двух узлов. Однако, как следует из названия _активно-пассивный_, не все узлы будут активными. Например, в случае двух узлов, если первый узел уже активен, то второй узел должен быть пассивным или находиться в режиме ожидания.

## Преимущества

Ниже перечислены четыре ключевых преимущества кластерных вычислений:

- Высокая доступность
- Масштабируемость
- Производительность
- Экономичность

## Балансировка нагрузки и кластеризация

Балансировка нагрузки имеет некоторые общие черты с кластеризацией, но это разные процессы. Кластеризация обеспечивает избыточность и повышает производительность и доступность. Серверы в кластере знают друг о друге и работают вместе для достижения общей цели. При балансировке нагрузки серверы не знают друг о друге. Вместо этого они реагируют на запросы, которые получают от балансировщика нагрузки.

Мы можем использовать балансировку нагрузки в сочетании с кластеризацией, но она также применима в случаях с независимыми серверами, объединенными общей целью, например, для запуска веб-сайта, бизнес-приложения, веб-службы или другого ИТ-ресурса.

## Проблемы

Наиболее очевидной проблемой кластеризации является повышенная сложность установки и обслуживания. Операционная система, приложение и его зависимости должны быть установлены и обновлены на каждом узле.

Это становится еще сложнее, если узлы в кластере неоднородны. Также необходимо тщательно следить за использованием ресурсов на каждом узле и агрегировать журналы, чтобы убедиться в правильности поведения программного обеспечения.

Кроме того, усложняется управление хранением данных: общее устройство хранения должно предотвращать перезапись узлов друг другом, а распределенные хранилища данных должны синхронизироваться.
## Примеры

Кластеризация широко используется в промышленности, и зачастую многие технологии предлагают тот или иной режим кластеризации. Например:

- Контейнеры ([Kubernetes](https://kubernetes.io), [Amazon ECS](https://aws.amazon.com/ecs)).
- Базы данных ([Cassandra](https://cassandra.apache.org/_/index.html), [MongoDB](https://www.mongodb.com))
- Кэш ([Redis](https://redis.io/docs/manual/scaling))

# Кэширование

_ "В компьютерных науках есть только две трудные вещи: инвалидация кэша и именование вещей". - Фил Карлтон_

![кэширование](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/caching.png)

Основная задача кэша - повысить производительность поиска данных за счет снижения необходимости обращаться к более медленному слою хранения. В отличие от баз данных, в которых данные обычно полные и долговременные, кэш обычно хранит подмножество данных на временной основе.

Кэши используют принцип _"недавно запрошенные данные, скорее всего, будут запрошены снова"._

## Кэширование и память

Как и память компьютера, кэш - это компактная, быстродействующая память, которая хранит данные в виде иерархии уровней, начиная с первого и последовательно переходя от него. Они обозначаются как L1, L2, L3 и так далее. Кэш также записывается по запросу, например, когда произошло обновление и новое содержимое необходимо сохранить в кэше, заменив им старое.

Независимо от того, читается или записывается кэш, это происходит по одному блоку за раз. Каждый блок также имеет тег, который содержит место, где данные были сохранены в кэше. Когда данные запрашиваются из кэша, происходит поиск по тегам, чтобы найти нужное содержимое в памяти первого уровня (L1). Если нужные данные не найдены, поиск ведется еще в L2.

Если данные не найдены и там, поиск продолжается в L3, затем в L4 и так далее, пока они не будут найдены, после чего они считываются и загружаются. Если данные вообще не найдены в кэше, то они записываются в него для быстрого извлечения в следующий раз.

## Попадание в кэш и пропуск кэша

### Попадание в кэш

Попадание в кэш описывает ситуацию, когда содержимое успешно обслуживается из кэша. Метки быстро перебираются в памяти, и когда данные найдены и прочитаны, это считается попаданием в кэш.

**Холодный, теплый и горячий кэш**.

Попадание в кэш также можно назвать холодным, теплым или горячим. В каждом из этих случаев описывается скорость считывания данных.

Горячий кэш - это случай, когда данные были считаны из памяти с максимально возможной скоростью. Это происходит, когда данные извлекаются из L1.

Холодный кэш - это чтение данных с _самой_ медленной возможной скоростью, однако оно все равно успешно, поэтому оно все равно считается попаданием в кэш. Данные просто находятся ниже в иерархии памяти, например в L3 или ниже.

Теплый кэш используется для описания данных, которые находятся в L2 или L3. Он не так быстр, как горячий кэш, но все же быстрее, чем холодный. Как правило, называя кэш теплым, вы хотите сказать, что он медленнее и ближе к холодному кэшу, чем к горячему.

### Пропуск кэша

Под пропуском кэша понимается случай, когда в памяти выполняется поиск, но данные не найдены. Когда это происходит, содержимое передается и записывается в кэш.

## Инвалидизация кэша

Признание кэша недействительным - это процесс, в ходе которого компьютерная система объявляет записи в кэше недействительными и удаляет или заменяет их. Если данные были изменены, они должны быть аннулированы в кэше, если нет, это может привести к непоследовательной работе приложения. Существует три вида систем кэширования:

###  Запись через кэш (Write-through cache)

![write-through-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-through-cache.png)

Данные записываются в кэш и соответствующую базу данных одновременно.

**Плюсы**: Быстрый поиск, полная согласованность данных между кэшем и хранилищем.

**Минусы**:Более высокая задержка при операциях записи.

### Кэш  с обходом записи (Write-around cache)

![write-around-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-around-cache.png)

Когда запись идет напрямую в базу данных или постоянное хранилище, минуя кэш.

**Плюсы**:Это может уменьшить задержку.

**Минусы**:Увеличивает количество пропусков кэша, поскольку в случае пропусков кэша системе приходится считывать информацию из базы данных. В результате это может привести к увеличению задержки чтения в случае приложений, которые быстро записывают и перечитывают информацию. Чтение происходит из более медленного внутреннего хранилища, что приводит к увеличению задержки.

### Кэш с обратной записью (Write-back cache)

![write-back-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-back-cache.png)

В этом случае запись выполняется только в слой кэширования, и запись подтверждается, как только запись в кэш завершается. Затем кэш асинхронно синхронизирует эту запись с базой данных.

**Плюсы**: Это приведет к снижению задержек и высокой пропускной способности приложений, интенсивно работающих с записью.

**Минусы**: Существует риск потери данных в случае сбоя слоя кэширования. Мы можем улучшить эту ситуацию, имея более одной реплики, подтверждающей запись в кэш.

## Политики вытеснения

Ниже перечислены наиболее распространенные политики вытеснения кэша:

- **First In First Out (FIFO)**: Кэш вытесняет первый блок, к которому обратились первым, не обращая внимания на то, как часто или сколько раз к нему обращались до этого.
- **Last In First Out (LIFO)**: Кэш вытесняет блок, доступ к которому был получен последним, без учета того, как часто или сколько раз к нему обращались до этого.
- **Least Recently Used (LRU)**: В первую очередь удаляются наименее часто используемые элементы.
- **Most Recently Used (MRU)**: В отличие от LRU, в первую очередь отбрасываются наиболее часто используемые элементы.
- **Least Frequently Used (LFU)**: Подсчитывает, как часто требуется тот или иной элемент. Те, которые используются реже всего, отбрасываются первыми.
- **Random Replacement(RR)**: Случайно выбирает элемент-кандидат и выбрасывает его, чтобы освободить место, когда это необходимо.

## Распределённый кэш

![distributed-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/distributed-cache.png)

Распределенный кэш - это система, объединяющая память с произвольным доступом (RAM) нескольких компьютеров, подключенных к сети, в единое хранилище данных в памяти, используемое в качестве кэша для обеспечения быстрого доступа к данным. В то время как большинство кэшей традиционно находятся в одном физическом сервере или аппаратном компоненте, распределенный кэш может выходить за пределы памяти одного компьютера, объединяя несколько компьютеров.

## Глобальный кэш

![global-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/global-cache.png)

Как следует из названия, у нас будет один общий кэш, который будут использовать все узлы приложения. Если запрашиваемые данные не найдены в глобальном кэше, кэш отвечает за поиск недостающей части данных из базового хранилища данных.

## Примеры использования

Кэширование может иметь множество реальных вариантов использования, например:

- Кэширование баз данных
- Сеть доставки контента (CDN)
- Кэширование системы доменных имен (DNS)
- Кэширование API


**Когда не стоит использовать кэширование?**

Давайте также рассмотрим некоторые сценарии, в которых не следует использовать кэш:

- Кэширование не помогает, если доступ к кэшу занимает столько же времени, сколько и доступ к основному хранилищу данных.
- Кэширование не работает так же хорошо, когда запросы имеют низкую повторяемость (большую случайность), потому что производительность кэша зависит от повторяющихся шаблонов доступа к памяти.
- Кэширование не помогает при частых изменениях данных, так как кэшированная версия выходит из синхронизации, а к первичному хранилищу данных приходится обращаться каждый раз.

_Важно отметить, что кэш не следует использовать в качестве постоянного хранилища данных. Они почти всегда реализуются в энергонезависимой памяти, потому что она быстрее, и поэтому должны рассматриваться как временные._

## Преимущества

Ниже перечислены некоторые преимущества кэширования:

- Повышает производительность
- Сокращение задержки
- Снижение нагрузки на базу данных
- Снижение затрат на сеть
- Повышение пропускной способности при чтении

## Примеры

Вот несколько часто используемых технологий для кэширования:

- [Redis](https://redis.io)
- [Memcached](https://memcached.org)
- [Amazon Elasticache](https://aws.amazon.com/elasticache)
- [Aerospike](https://aerospike.com)

# Сеть доставки контента (CDN)

Сеть доставки контента (CDN) - это географически распределенная группа серверов, которые работают вместе, чтобы обеспечить быструю доставку интернет-контента. Как правило, статические файлы, такие как HTML/CSS/JS, фотографии и видео, обслуживаются из CDN.

![cdn-map](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn-map.png)

## Зачем использовать CDN?

Сеть доставки контента (CDN) повышает доступность и избыточность контента, снижает затраты на пропускную способность и повышает безопасность. Обслуживание контента из CDN может значительно повысить производительность, поскольку пользователи получают контент из близких к ним центров обработки данных, а нашим серверам не приходится обслуживать запросы, которые выполняет CDN.

## Как работает CDN?

![cdn](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn.png)

В CDN оригинальный сервер содержит оригинальные версии контента, в то время как пограничные серверы многочисленны и распределены по различным точкам мира.

Чтобы минимизировать расстояние между посетителями и сервером сайта, CDN хранит кэшированную версию своего контента в нескольких географических точках, известных как граничные точки. В каждой граничной точке расположено несколько кэширующих серверов, отвечающих за доставку контента посетителям в пределах своей близости.

После того как статические активы кэшируются на всех серверах CDN для определенного местоположения, все последующие запросы посетителей сайта на статические активы будут доставляться с этих граничных серверов, а не с исходного, что снижает нагрузку на исходный сервер и улучшает масштабируемость.

Например, когда кто-то из жителей Великобритании запрашивает наш сайт, который может быть размещен в США, он будет обслуживаться с ближайшего граничного сервера, например с граничного сервера в Лондоне. Это гораздо быстрее, чем если бы посетитель делал полный запрос к исходному серверу, что увеличивает задержку.

## Типы

CDN обычно делятся на два типа:

### Push CDNs

Push CDN получают новый контент каждый раз, когда на сервере происходят изменения. Мы берем на себя полную ответственность за предоставление контента, загрузку непосредственно в CDN и переписывание URL-адресов для указания на CDN. Мы можем настроить время истечения срока действия контента и время его обновления. Контент загружается только тогда, когда он новый или измененный, что минимизирует трафик, но максимизирует хранение.

Сайты с небольшим объемом трафика или сайты с нечасто обновляемым контентом хорошо работают с push CDN. Контент размещается в CDN один раз, а не извлекается заново через регулярные промежутки времени.

### Pull CDN

В ситуации с Pull CDN кэш обновляется на основе запроса. Когда клиент отправляет запрос, требующий статические активы из CDN, если у CDN их нет, то она получает только что обновленные активы с исходного сервера и заполняет свой кэш этими новыми активами, а затем отправляет эти новые кэшированные активы пользователю.

В отличие от Push CDN, этот способ требует меньше обслуживания, поскольку обновление кэша на узлах CDN происходит на основе запросов клиента к исходному серверу. Сайты с большим трафиком хорошо работают с pull CDN, так как трафик распределяется более равномерно, а на CDN остается только недавно запрошенный контент.

## Недостатки

Как мы все знаем, за все хорошее приходится платить, поэтому давайте обсудим некоторые недостатки CDN:

- **Дополнительные расходы**: Использование CDN может быть дорогостоящим, особенно для сервисов с высоким трафиком.
- **Ограничения**: Некоторые организации и страны блокируют домены или IP-адреса популярных CDN.
- **Местоположение**: Если большая часть нашей аудитории находится в стране, где у CDN нет серверов, данные на нашем сайте, возможно, будут перемещаться дальше, чем без использования CDN.


## Примеры

Вот несколько широко используемых CDN:

- [Amazon CloudFront](https://aws.amazon.com/cloudfront)
- [Google Cloud CDN](https://cloud.google.com/cdn)
- [Cloudflare CDN](https://www.cloudflare.com/cdn)
- [Fastly](https://www.fastly.com/products/cdn)

# Прокси

Прокси-сервер - это промежуточное оборудование/программное обеспечение, которое находится между клиентом и внутренним сервером. Он получает запросы от клиентов и передает их на исходные серверы. Обычно прокси-серверы используются для фильтрации запросов, регистрации запросов, а иногда и для преобразования запросов (добавление/удаление заголовков, шифрование/дешифрование или сжатие).

## Типы

Существует два типа прокси-серверов:

### Forward Proxy

Прокси-сервер, часто называемый прокси, прокси-сервер или веб-прокси, - это сервер, который находится перед группой клиентских компьютеров. Когда эти компьютеры делают запросы к сайтам и службам в Интернете, прокси-сервер перехватывает эти запросы и затем общается с веб-серверами от имени этих клиентов, как посредник.

![forward-proxy](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/forward-proxy.png)

**Преимущества**

Вот некоторые преимущества прямого прокси-сервера:

- Блокировка доступа к определенному контенту
- Позволяет получить доступ к [гео-ограниченному](https://en.wikipedia.org/wiki/Geo-blocking) контенту
- Обеспечивает анонимность
- Избежать других ограничений на просмотр

Хотя прокси-серверы обеспечивают анонимность, они все равно могут отслеживать нашу личную информацию. Установка и обслуживание прокси-сервера может быть дорогостоящей и требует настройки.

### Reverse Proxy

Обратный прокси-сервер - это сервер, который находится перед одним или несколькими веб-серверами и перехватывает запросы от клиентов. Когда клиенты отправляют запросы на исходный сервер веб-сайта, эти запросы перехватываются обратным прокси-сервером.

Разница между прямым и обратным прокси-сервером тонкая, но важная. Упрощенно можно сказать, что прямой прокси сидит перед клиентом и следит за тем, чтобы ни один сервер-оригинал никогда не общался напрямую с этим клиентом. С другой стороны, обратный прокси сидит перед сервером происхождения и гарантирует, что ни один клиент никогда не будет общаться напрямую с этим сервером.

![reverse-proxy](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/reverse-proxy.png)

Внедрение обратного прокси приводит к увеличению сложности. Один обратный прокси - это единственная точка отказа, настройка нескольких обратных прокси (т. е. обход отказа) еще больше увеличивает сложность.

**Преимущества**

Вот некоторые преимущества использования обратного прокси:

- Повышенная безопасность
- Кэширование
- SSL-шифрование
- Балансировка нагрузки
- Масштабируемость и гибкость

## Балансировщик нагрузки против обратного прокси

Подождите, разве обратный прокси не похож на балансировщик нагрузки? Нет, поскольку балансировщик нагрузки полезен, когда у нас есть несколько серверов. Часто балансировщики нагрузки направляют трафик на набор серверов, выполняющих одну и ту же функцию, в то время как обратные прокси могут быть полезны даже при наличии всего одного веб-сервера или сервера приложений. Обратный прокси также может выступать в роли балансировщика нагрузки, но не наоборот.

## Примеры

Ниже приведены некоторые часто используемые прокси серверы:

- [Nginx](https://www.nginx.com)
- [HAProxy](http://www.haproxy.org)
- [Traefik](https://doc.traefik.io/traefik)
- [Envoy](https://www.envoyproxy.io)

# Availability (Доступность)

Доступность - это время, в течение которого система остается работоспособной для выполнения требуемых функций в определенный период. Это простая мера процента времени, в течение которого система, услуга или машина остается работоспособной в нормальных условиях.

## Девятки доступности

Доступность часто измеряется временем работы (или простоя) в процентах от времени, в течение которого сервис доступен. Обычно она измеряется количеством девяток.

$$
Availability = \frac{Uptime}{(Uptime + Downtime)}
$$

Если доступность составляет 99,00%, говорят, что у него "2 девятки" доступности, а если 99,9%, то "3 девятки", и так далее.

| Доступность (в процентах) | Время простоя (год) | Время простоя (месяц) | Время простоя (неделя) |
| ------------------------ | ------------------ | ----------------- | ------------------ |
| 90% (одна девятка) | 36,53 дня | 72 часа | 16,8 часа |
| 99% (две девятки) | 3,65 дня | 7,20 часа | 1,68 часа |
| 99,9% (три девятки)| 8,77 часов | 43,8 минут | 10,1 минут |
| 99,99% (четыре девятки) | 52,6 минуты | 4,32 минуты | 1,01 минуты |
| 99,999% (пять девяток) | 5,25 минут | 25,9 секунд | 6,05 секунд |
| 99,9999% (шесть девяток) | 31,56 секунды | 2,59 секунды | 604,8 миллисекунды |
| 99,99999% (семь девяток) | 3,15 секунды | 263 миллисекунды | 60,5 миллисекунды |
| 99,999999% (восемь девяток) | 315,6 миллисекунд | 26,3 миллисекунд | 6 миллисекунд |
| 99,9999999% (девять девяток) | 31,6 миллисекунды | 2,6 миллисекунды | 0,6 миллисекунды |

## Последовательная и параллельная доступность

Если сервис состоит из нескольких компонентов, склонных к сбоям, общая доступность сервиса зависит от того, работают ли эти компоненты последовательно или параллельно.

### Последовательная

Общая доступность снижается, если два компонента расположены последовательно.

$$
Availability \space (Total) = Availability \space (Foo) * Availability \space (Bar)
$$

Например, если доступность `Foo` и `Bar` составляет 99,9%, то их общая доступность в последовательности будет равна 99,8%.

### Параллельная

Общая доступность повышается, когда два компонента работают параллельно.

$$
Availability \space (Total) = 1 - (1 - Availability \space (Foo)) * (1 - Availability \space (Bar))
$$

Например, если доступность `Foo` и `Bar` составляет 99,9%, то их общая доступность в параллельном режиме будет равна 99,9999%.

## Доступность в сравнении с надежностью (Availability vs Reliability)

Если система надежна, она доступна. Однако если она доступна, то не обязательно надежна. Другими словами, высокая надежность способствует высокой доступности, но можно добиться высокой доступности даже с ненадежной системой.

## Высокая доступность и отказоустойчивость (High availability vs Fault Tolerance)

Как высокая доступность, так и отказоустойчивость относятся к методам обеспечения высокого уровня работоспособности. Однако достигают они этой цели по-разному.

Отказоустойчивая система не имеет перерывов в обслуживании, но имеет значительно более высокую стоимость, в то время как высокодоступная система имеет минимальные перерывы в обслуживании. Отказоустойчивость требует полного аппаратного резервирования, поскольку в случае отказа основной системы, без потери работоспособности, ее место должна занять другая система.

# Масштабируемость

Масштабируемость - это показатель того, насколько хорошо система реагирует на изменения, добавляя или удаляя ресурсы для удовлетворения текущих потребностей.

![масштабируемость](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/scalability/scalability.png)

Давайте обсудим различные типы масштабирования:

## Вертикальное масштабирование

Вертикальное масштабирование (также известное как увеличение масштаба) расширяет возможности системы за счет увеличения мощности существующей машины. Другими словами, вертикальное масштабирование - это расширение возможностей приложения за счет увеличения мощности оборудования.

### Преимущества

- Простота внедрения
- Легче управлять
- Согласованность данных

### Недостатки

- Риск больших простоев
- Сложнее модернизировать
- Может стать единственной точкой отказа

## Горизонтальное масштабирование

Горизонтальное масштабирование (также известное как масштабирование наружу) позволяет расширить масштаб системы за счет добавления новых машин. Это повышает производительность сервера за счет добавления большего количества экземпляров к существующему пулу серверов, что позволяет распределить нагрузку более равномерно.

### Преимущества

- Увеличенная избыточность
- Повышенная отказоустойчивость
- Гибкость и эффективность
- Легче модернизировать

### Недостатки

- Повышенная сложность
- Несогласованность данных
- Повышенная нагрузка на последующие службы

# Хранилище

Хранилище - это механизм, который позволяет системе хранить данные, временно или постоянно. В контексте проектирования систем эта тема чаще всего обходится стороной, однако важно иметь базовое представление о некоторых распространенных типах методов хранения, которые помогут нам точно настроить наши компоненты хранения. Давайте обсудим некоторые важные концепции хранения данных:

## RAID

RAID (Redundant Array of Independent Disks) - это способ хранения одних и тех же данных на нескольких жестких дисках или твердотельных накопителях (SSD) для защиты данных в случае отказа диска.

Однако существуют различные уровни RAID, и не все они направлены на обеспечение избыточности. Давайте обсудим некоторые часто используемые уровни RAID:

- **RAID 0**: Также известен как чередование, данные равномерно распределяются между всеми дисками массива.
- **RAID 1**: Также известен как зеркалирование, по крайней мере два диска содержат точную копию набора данных. Если один диск выходит из строя, другие продолжают работать.
- **RAID 5**: Чередование с контролем четности. Требуется использование не менее 3 дисков, данные распределяются по нескольким дискам, как в RAID 0, но при этом четность распределяется по дискам.
- **RAID 6**: Чередование с двойной четностью. RAID 6 похож на RAID 5, но данные о четности записываются на два диска.
- **RAID 10**: Комбинирует чередование плюс зеркалирование из RAID 0 и RAID 1. Он обеспечивает безопасность за счет зеркалирования всех данных на вторичных дисках, а также использует чередование на каждом наборе дисков для ускорения передачи данных.

### Сравнение

Давайте сравним все характеристики различных уровней RAID:

| Features | RAID 0 | RAID 1 | RAID 5 | RAID 6 | RAID 10 |
| -------------------- | -------- | -------------------- | -------------------- | --------------------------- | ---------------------------------------- |
Описание | Полосовое копирование | Зеркальное копирование | Полосовое копирование с контролем четности | Полосовое копирование с двойным контролем четности | Полосовое копирование и зеркальное копирование |
| Минимальное количество дисков | 2 | 2 | 3 |  4 | 4 |
Производительность чтения | Высокая | Высокая | Высокая | Высокая | Высокая |
Производительность записи | Высокая | Средняя | Высокая | Высокая | Средняя | 
Стоимость | Низкая | Высокая | Низкая | Низкая |  Высокая |
| Отказоустойчивость | Нет | Отказ одного диска | Отказ одного диска | Отказ двух дисков | До одного отказа диска в каждом подмассиве |
| Использование емкости | 100% | 50% | 67%-94% | 50%-80% | 50% |


## Тома (Volumes)

Том - это фиксированный объем памяти на диске или ленте. Термин "том" часто используется как синоним самого хранилища, однако один диск может содержать более одного тома или том может охватывать более одного диска.

## Файловое хранилище

Файловое хранилище - это решение, позволяющее хранить данные в виде файлов и представлять их конечным пользователям в виде иерархической структуры каталогов. Основное преимущество заключается в предоставлении удобного решения для хранения и извлечения файлов. Чтобы найти файл в файловом хранилище, требуется полный путь к нему. Он экономичен и легко структурируется и обычно находится на жестких дисках, то есть для пользователя и на жестком диске они выглядят одинаково.

Пример: [Amazon EFS](https://aws.amazon.com/efs), [Azure files](https://azure.microsoft.com/en-in/services/storage/files), [Google Cloud Filestore](https://cloud.google.com/filestore) и т. д.

## Блочное хранение

При блочном хранении данные делятся на блоки (чанки) и хранятся как отдельные фрагменты. Каждому блоку данных присваивается уникальный идентификатор, что позволяет системе хранения размещать небольшие фрагменты данных там, где это удобнее всего.

Блочное хранение также отделяет данные от пользовательской среды, позволяя распределять их по нескольким средам. Это создает несколько путей к данным и позволяет пользователю быстро получить их. Когда пользователь или приложение запрашивает данные из блочной системы хранения, базовая система хранения повторно собирает блоки данных и представляет их пользователю или приложению.

Пример: [Amazon EBS](https://aws.amazon.com/ebs).

## Объектное хранилище

Объектное хранилище, которое также известно как объектно-ориентированное хранилище, разбивает файлы данных на части, называемые объектами. Затем эти объекты хранятся в едином хранилище, которое может быть распределено по нескольким сетевым системам.

Пример: [Amazon S3](https://aws.amazon.com/s3), [Azure Blob Storage](https://azure.microsoft.com/en-in/services/storage/blobs), [Google Cloud Storage](https://cloud.google.com/storage) и т. д.

## NAS

NAS (Network Attached Storage) - это устройство хранения данных, подключенное к сети, которое позволяет хранить и извлекать данные из центрального хранилища для авторизованных пользователей сети. Устройства NAS являются гибкими, то есть по мере необходимости мы можем добавлять к ним дополнительные хранилища. Это быстрее, дешевле и обеспечивает все преимущества публичного облака на месте, предоставляя нам полный контроль.

## HDFS

Распределенная файловая система Hadoop (HDFS) - это распределенная файловая система, разработанная для работы на аппаратном обеспечении. HDFS обладает высокой отказоустойчивостью и предназначена для развертывания на недорогом оборудовании. HDFS обеспечивает высокую пропускную способность доступа к данным приложений и подходит для приложений с большими массивами данных. Она имеет много общего с существующими распределенными файловыми системами.

HDFS предназначена для надежного хранения очень больших файлов на машинах в большом кластере. Каждый файл хранится в виде последовательности блоков, причем все блоки в файле, кроме последнего, имеют одинаковый размер. Блоки файла реплицируются для обеспечения отказоустойчивости.

# Базы данных и СУБД

## Что такое база данных?

База данных - это организованная коллекция структурированной информации, или данных, обычно хранящихся в электронном виде в компьютерной системе. База данных обычно управляется системой управления базами данных (СУБД). Вместе данные и СУБД, а также связанные с ними приложения называются системой баз данных, часто сокращаемой до просто базы данных.

## Что такое СУБД?

Для работы с базой данных обычно требуется комплексное программное обеспечение, известное как система управления базами данных (СУБД). СУБД служит интерфейсом между базой данных и ее конечными пользователями или программами, позволяя пользователям получать, обновлять и управлять организацией и оптимизацией информации. СУБД также облегчает надзор и контроль над базами данных, позволяя выполнять различные административные операции, такие как мониторинг производительности, настройка, резервное копирование и восстановление.

## Компоненты

Вот некоторые общие компоненты, встречающиеся в различных базах данных:

### Схема

Роль схемы заключается в определении формы структуры данных и указании того, какие типы данных могут находиться в ней. Схемы могут строго соблюдаться во всей базе данных, слабо соблюдаться в части базы данных, или их может не быть вовсе.

### Таблица

Каждая таблица содержит различные столбцы, как в электронных таблицах. В таблице может быть как всего два столбца, так и до сотни и более столбцов, в зависимости от типа информации, помещаемой в таблицу.

### Столбец

Столбец содержит набор значений данных определенного типа, по одному значению для каждой строки базы данных. Столбец может содержать текстовые значения, числа, перечисления, временные метки и т. д.

### Строка

Данные в таблице записываются в строках. В таблице могут быть тысячи или миллионы строк, содержащих определенную информацию.

## Типы

![database-types](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/databases-and-dbms/database-types.png)

Ниже приведены различные типы баз данных:

- **[SQL](https://karanpratapsingh.com/courses/system-design/sql-databases)**
- **[NoSQL](https://karanpratapsingh.com/courses/system-design/nosql-databases)**
  - Документоориентированные
  - Ключ-значение
  - Графовые
  - Временная серия
  - Wide-column
  - Multy-model

Базы данных SQL и NoSQL - это обширные темы, и они будут рассмотрены отдельно в разделах [Базы данных SQL](https://karanpratapsingh.com/courses/system-design/sql-databases) и [Базы данных NoSQL](https://karanpratapsingh.com/courses/system-design/nosql-databases). Узнайте, как они сравниваются друг с другом в [SQL vs NoSQL databases](https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases).

## Проблемы

Некоторые общие проблемы, возникающие при работе с базами данных в масштабе:

- **Принятие значительного увеличения объема данных**: Взрыв данных, поступающих от датчиков, подключенных машин и десятков других источников.
- **Обеспечение безопасности данных**: В наши дни утечки данных происходят повсеместно, и сейчас как никогда важно обеспечить безопасность данных, но в то же время их легкий доступ для пользователей.
- **Соответствие требованиям**: Компаниям необходим доступ к данным в режиме реального времени, чтобы своевременно принимать решения и использовать новые возможности.
- **Управление и поддержка базы данных и инфраструктуры**: По мере усложнения баз данных и роста объемов данных компании сталкиваются с необходимостью нанимать дополнительных специалистов для управления базами данных.
- **Устранение ограничений на масштабируемость**: Чтобы выжить, бизнес должен расти, а вместе с ним должно расти и управление данными. Но очень сложно предсказать, сколько мощностей потребуется компании, особенно в случае с локальными базами данных.
- **Обеспечение резидентности данных, суверенитета данных или требований к латентности**: В некоторых организациях есть сценарии использования, для которых лучше использовать локальные базы данных. В таких случаях идеальным вариантом являются инженерные системы, предварительно настроенные и оптимизированные для работы базы данных.

# Базы данных SQL

База данных SQL (или реляционная) - это набор элементов данных с заранее определенными связями между ними. Эти элементы организованы в виде набора таблиц со столбцами и строками. Таблицы используются для хранения информации об объектах, которые должны быть представлены в базе данных. Каждый столбец таблицы содержит определенный тип данных, а поле хранит фактическое значение атрибута. Строки таблицы представляют собой набор связанных значений одного объекта или сущности.

Каждая строка таблицы может быть помечена уникальным идентификатором, называемым первичным ключом, а строки нескольких таблиц могут быть связаны между собой с помощью внешних ключей. К этим данным можно получить доступ множеством различных способов, не перестраивая сами таблицы базы данных. Базы данных SQL обычно следуют [модели согласованности ACID](https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#acid).

## Материализованные представления

Материализованное представление - это предварительно вычисленный набор данных, полученный из спецификации запроса и сохраненный для последующего использования. Поскольку данные предварительно вычислены, запрос к материализованному представлению выполняется быстрее, чем запрос к базовой таблице представления. Эта разница в производительности может быть значительной, если запрос выполняется часто или является достаточно сложным.

Кроме того, это позволяет выполнять подмножество данных и повышает производительность сложных запросов, выполняемых на больших наборах данных, что снижает нагрузку на сеть. Существуют и другие варианты использования материализованных представлений, но в основном они применяются для повышения производительности и репликации.

## Проблема N+1 запроса

Проблема N+1 запроса возникает, когда уровень доступа к данным выполняет N дополнительных SQL-запросов для получения тех же данных, которые могли быть получены при выполнении основного SQL-запроса. Чем больше значение N, тем больше запросов будет выполнено, тем больше влияние на производительность.

Это часто встречается в GraphQL и ORM (Object-Relational Mapping) инструментах и может быть решено путем оптимизации SQL-запроса или использования dataloader, который группирует последовательные запросы и делает один запрос данных под капотом.

## Преимущества

Давайте рассмотрим некоторые преимущества использования реляционных баз данных:

- Простота и точность
- Доступность
- согласованность данных
- Гибкость

## Недостатки

Ниже перечислены недостатки реляционных баз данных:

- Дорогое обслуживание
- Сложная эволюция схемы
- Проблемы с производительностью (объединение, денормализация и т.д.)
- Сложность масштабирования из-за плохой горизонтальной масштабируемости

## Примеры

Вот некоторые широко используемые реляционные базы данных:

- [PostgreSQL](https://www.postgresql.org)
- [MySQL](https://www.mysql.com)
- [MariaDB](https://mariadb.org)
- [Amazon Aurora](https://aws.amazon.com/rds/aurora)

# Базы данных NoSQL

NoSQL - это широкая категория, в которую входят любые базы данных, не использующие SQL в качестве основного языка доступа к данным. Эти типы баз данных также иногда называют нереляционными базами данных. В отличие от реляционных баз данных, данные в базах NoSQL не должны соответствовать заранее определенной схеме. Базы данных NoSQL следуют [модели согласованности BASE] (https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#base).

Ниже представлены различные типы баз данных NoSQL:

### Документоориентированные

База данных документов (также известная как документоориентированная база данных или хранилище документов) - это база данных, хранящая информацию в документах. Это базы данных общего назначения, которые служат для различных целей, как для транзакционных, так и для аналитических приложений.

**Преимущества**

- Интуитивно понятная и гибкая
- Легкое горизонтальное масштабирование
- Бессхемность

**Недостатки**

- Бессхемность
- Нереляционный

**Примеры**

- [MongoDB](https://www.mongodb.com)
- [Amazon DocumentDB](https://aws.amazon.com/documentdb)
- [CouchDB](https://couchdb.apache.org)

### Ключ-значение

Один из самых простых типов баз данных NoSQL, базы данных "ключ-значение" сохраняют данные в виде группы пар "ключ-значение", состоящих из двух элементов данных каждый. Их также иногда называют хранилищем ключевых значений.

**Преимущества**

- Простота и производительность
- Высокая масштабируемость при больших объемах трафика
- Управление сессиями
- Оптимизированный поиск

**Недостатки**

- Базовый CRUD
- Значения не могут быть отфильтрованы
- Отсутствует возможность индексирования и сканирования
- Не оптимизирован для сложных запросов

**Примеры**

- [Redis](https://redis.io)
- [Memcached](https://memcached.org)
- [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
- [Aerospike](https://aerospike.com)

### Графовые

Графовая база данных - это база данных NoSQL, которая использует графовые структуры для семантических запросов с узлами, ребрами и свойствами для представления и хранения данных вместо таблиц или документов.

Граф связывает элементы данных в хранилище с коллекцией узлов и ребер, причем ребра представляют собой отношения между узлами. Отношения позволяют напрямую связывать данные в хранилище и, во многих случаях, извлекать их одной операцией.

**Преимущества**

- Скорость выполнения запросов
- Маневренность и гибкость
- Явное представление данных

**Недостатки**

- Сложность
- Отсутствие стандартизированного языка запросов

**Примеры использования**

- Обнаружение мошенничества
- Системы рекомендаций
- Социальные сети
- Картирование сетей

**Примеры**
- [Neo4j](https://neo4j.com)
- [ArangoDB](https://www.arangodb.com)
- [Amazon Neptune](https://aws.amazon.com/neptune)
- [JanusGraph](https://janusgraph.org)

### Временные ряды

База данных временных рядов - это база данных, оптимизированная для работы с данными с временными метками, или временными рядами.

**Преимущества**

- Быстрая вставка и извлечение данных
- Эффективное хранение данных

**Примеры использования**

- Данные IoT
- Анализ метрик
- Мониторинг приложений
- Понимание финансовых тенденций

**Примеры**

- [InfluxDB](https://www.influxdata.com)
- [Apache Druid](https://druid.apache.org)

### Wide-column

Базы данных с широкими колонками, также известные как хранилища с широкими колонками, не зависят от схемы. Данные хранятся в семействах столбцов, а не в строках и столбцах.

**Преимущества**

- Высокая масштабируемость, может обрабатывать петабайты данных.
- Идеальны для приложений, работающих с большими данными в режиме реального времени

**Недостатки**

- Дорогостоящий
- Увеличенное время записи

**Примеры использования**

- Бизнес-аналитика
- Хранение данных на основе атрибутов

**Примеры**

- [BigTable](https://cloud.google.com/bigtable)
- [Apache Cassandra](https://cassandra.apache.org)
- [ScyllaDB](https://www.scylladb.com)

### Multi-model

Многомодельные базы данных объединяют различные модели баз данных (например, реляционную, графовую, ключевую, документную и т. д.) в единый интегрированный бэкэнд. Это означает, что они могут работать с различными типами данных, индексами, запросами и хранить данные более чем в одной модели.

**Преимущества**

- Гибкость
- Подходит для сложных проектов
- Согласованность данных

**Недостатки**

- Сложность
- Менее зрелый

**Примеры**

- [ArangoDB](https://www.arangodb.com)
- [Azure Cosmos DB](https://azure.microsoft.com/en-in/services/cosmos-db)
- [Couchbase](https://www.couchbase.com)

# SQL vs NoSQL базы данных

В мире баз данных существует два основных типа решений: SQL (реляционные) и NoSQL (нереляционные) базы данных. Оба типа отличаются друг от друга тем, как они были созданы, какой тип информации они хранят и как они ее хранят. Реляционные базы данных структурированы и имеют предопределенные схемы, в то время как нереляционные базы данных неструктурированы, распределены и имеют динамическую схему.

## Высокоуровневые различия

Вот некоторые высокоуровневые различия между SQL и NoSQL:

### Хранение

В SQL данные хранятся в таблицах, где каждая строка представляет собой объект, а каждый столбец - данные об этом объекте.

Базы данных NoSQL используют различные модели хранения данных, такие как ключ-значение, граф, документ и т. д.

### Схема

В SQL каждая запись соответствует фиксированной схеме, то есть столбцы должны быть определены и выбраны до ввода данных, а каждая строка должна содержать данные для каждого столбца. Схему можно изменить позже, но для этого необходимо модифицировать базу данных с помощью миграций.

В то время как в NoSQL схемы являются динамическими. Поля можно добавлять на лету, и каждая _запись_ (или ее эквивалент) не обязательно должна содержать данные для каждого _поля_.

### Запрос

Базы данных SQL используют язык SQL (структурированный язык запросов) для определения и манипулирования данными, который является очень мощным.

В базах данных NoSQL запросы сосредоточены на коллекции документов. Различные базы данных имеют разный синтаксис для запросов.

### Масштабируемость

В большинстве ситуаций базы данных SQL масштабируются вертикально, что может оказаться очень дорого. Реляционную базу данных можно масштабировать на несколько серверов, но это сложный и трудоемкий процесс.

С другой стороны, базы данных NoSQL масштабируются горизонтально, то есть мы можем легко добавить дополнительные серверы в нашу инфраструктуру баз данных NoSQL для обработки большого трафика. Любое дешевое товарное оборудование или облачные инстансы могут служить хостингом для баз данных NoSQL, что делает их гораздо более экономичными, чем вертикальное масштабирование. Многие технологии NoSQL также автоматически распределяют данные между серверами.

### Надежность

Подавляющее большинство реляционных баз данных соответствуют стандарту ACID. Поэтому, когда речь идет о надежности данных и гарантии выполнения транзакций, SQL-базы по-прежнему остаются лучшим выбором.

Большинство решений NoSQL жертвуют соответствием ACID ради производительности и масштабируемости.

## Причины

Как всегда, мы всегда должны выбирать ту технологию, которая лучше соответствует требованиям. Итак, давайте рассмотрим некоторые причины выбора базы данных на основе SQL или NoSQL:

**Для SQL**

- Структурированные данные со строгой схемой
- Реляционные данные
- Необходимость в сложных объединениях
- Транзакции
- Поиск по индексу очень быстрый

**Для NoSQL**

- Динамическая или гибкая схема
- Нереляционные данные
- Нет необходимости в сложных объединениях
- Очень интенсивная работа с данными
- Очень высокая пропускная способность по IOPS

# Репликация баз данных

Репликация - это процесс, который включает в себя обмен информацией для обеспечения согласованности между избыточными ресурсами, такими как несколько баз данных, для повышения надежности, отказоустойчивости или доступности.

## Репликация "ведущий-ведомый

Ведущее устройство обслуживает чтение и запись, реплицируя записи на одно или несколько ведомых устройств, которые обслуживают только чтение. Ведомые также могут реплицировать дополнительные ведомые в виде дерева. Если ведущий выходит из строя, система может продолжать работать в режиме "только чтение" до тех пор, пока ведомый не будет переведен в разряд ведущих или не будет создан новый ведущий.

![master-slave-replication](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-slave-replication.png)

### Преимущества

- Резервное копирование всей базы данных относительно не влияет на работу ведущего.
- Приложения могут считывать данные с ведомых устройств без воздействия на ведущее.
- Ведомые устройства могут быть переведены в автономный режим и синхронизированы с ведущим устройством без каких-либо простоев.

### Недостатки

- Репликация добавляет больше оборудования и дополнительную сложность.
- Время простоя и возможная потеря данных при отказе ведущего устройства.
- В архитектуре "ведущий-ведомый" все записи также должны производиться на ведущий.
- Чем больше ведомых, тем больше нужно реплицировать, что увеличивает задержку репликации.

## Репликация мастер-мастер

Оба мастера обслуживают чтение/запись и координируют работу друг с другом. Если один из мастеров выходит из строя, система может продолжать работать как на чтение, так и на запись.

![master-master-replication](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-master-replication.png)

### Преимущества

- Приложения могут читать с обоих мастеров.
- Распределение нагрузки на запись между обоими ведущими узлами.
- Простое, автоматическое и быстрое восстановление работоспособности.

### Недостатки

- Не так просты в настройке и развертывании, как master-slave.
- Либо слабо согласованы, либо имеют повышенную задержку записи из-за синхронизации.
- Разрешение конфликтов становится актуальным при добавлении большего числа узлов записи и увеличении задержки.

## Синхронная и асинхронная репликация

Основное различие между синхронной и асинхронной репликацией заключается в способе записи данных в реплику. При синхронной репликации данные записываются в первичное хранилище и в реплику одновременно. Таким образом, первичная копия и реплика всегда должны оставаться синхронизированными.

В отличие от этого, при асинхронной репликации данные копируются в реплику после того, как они уже записаны в первичное хранилище. Хотя процесс репликации может происходить практически в режиме реального времени, чаще всего репликация выполняется по расписанию, и это более экономично.

# Индексы

Индексы хорошо известны в базах данных, они используются для повышения скорости операций поиска данных в хранилище. Индекс - это компромисс между увеличением накладных расходов на хранение и замедлением записи (поскольку нам приходится не только записывать данные, но и обновлять индекс) и ускорением чтения. Индексы используются для быстрого поиска данных без необходимости изучать каждую строку в таблице базы данных. Индексы могут быть созданы на основе одного или нескольких столбцов таблицы базы данных, обеспечивая основу как для быстрого случайного поиска, так и для эффективного доступа к упорядоченным записям.

![indexes](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/indexes.png)

Индекс - это структура данных, которую можно воспринимать как оглавление, указывающее нам на место, где находятся реальные данные. Так, когда мы создаем индекс на столбец таблицы, мы храним этот столбец и указатель на всю строку в индексе. Индексы также используются для создания различных представлений одних и тех же данных. Для больших наборов данных это отличный способ задать различные фильтры или схемы сортировки, не прибегая к созданию нескольких дополнительных копий данных.

Одно из качеств, которым могут обладать индексы баз данных, заключается в том, что они могут быть **плотными** или **разрозненными**. Каждое из этих качеств индекса имеет свои компромиссы. Давайте рассмотрим, как работает каждый тип индекса:

## Плотный индекс

В плотном индексе для каждой строки таблицы создается запись индекса. Записи могут быть найдены напрямую, поскольку каждая запись индекса содержит значение ключа поиска и указатель на фактическую запись.

![dense-index](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/dense-index.png)

Плотные индексы требуют большего обслуживания, чем разреженные, во время записи. Поскольку каждая строка должна иметь запись, база данных должна поддерживать индекс при вставках, обновлениях и удалениях. Наличие записи для каждого ряда также означает, что плотные индексы требуют больше памяти. Преимущество плотного индекса в том, что значения могут быть быстро найдены с помощью двоичного поиска. Плотные индексы также не накладывают никаких требований к упорядочиванию данных.

## Разреженный индекс

В разреженном индексе записи создаются только для некоторых записей.

![sparse-index](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/sparse-index.png)

Разреженные индексы требуют меньшего обслуживания, чем плотные индексы, во время записи, поскольку содержат только подмножество значений. Это меньшее бремя обслуживания означает, что вставки, обновления и удаления будут выполняться быстрее. Меньшее количество записей также означает, что индекс будет использовать меньше памяти. Поиск данных происходит медленнее, поскольку за двоичным поиском обычно следует сканирование всей страницы. Разреженные индексы также необязательны при работе с упорядоченными данными.

# Нормализация и денормализация

## Термины

Прежде чем мы продолжим, давайте рассмотрим некоторые часто используемые термины в нормализации и денормализации.

### Ключи

**Первичный ключ**: Столбец или группа столбцов, которые могут быть использованы для уникальной идентификации каждой строки таблицы.

**Композитный ключ**: Первичный ключ, состоящий из нескольких столбцов.

**Суперключ**: Набор всех ключей, которые могут однозначно идентифицировать все строки, присутствующие в таблице.

**Кандидатский ключ**: Атрибуты, которые однозначно идентифицируют строки в таблице.

**Иностранный ключ**: Это ссылка на первичный ключ другой таблицы.

**Альтернативный ключ**: Ключи, которые не являются первичными, называются альтернативными ключами.

**Замещающий ключ**: Генерируемое системой значение, которое однозначно идентифицирует каждую запись в таблице, когда ни один другой столбец не может обладать свойствами первичного ключа.

### Зависимости

**Частичная зависимость**: Возникает, когда первичный ключ определяет некоторые другие атрибуты.

**Функциональная зависимость**: Это связь, существующая между двумя атрибутами, обычно между первичным ключом и неключевым атрибутом в таблице.

**Транзитивная функциональная зависимость**: Возникает, когда неключевой атрибут определяет другой атрибут.

### Аномалии

Аномалия в базе данных возникает, когда в базе данных есть недостаток, связанный с неправильным планированием или хранением всего в плоской базе данных. Обычно это решается с помощью процесса нормализации.

Существует три типа аномалий баз данных:

**Аномалия вставки**: Возникает, когда мы не можем вставить определенные атрибуты в базу данных без наличия других атрибутов.

**Аномалия обновления**: Возникает в случае избыточности данных и частичного обновления. Другими словами, для корректного обновления базы данных необходимы другие действия, такие как добавление, удаление или и то, и другое.

**Аномалия удаления**: Возникает, когда удаление одних данных требует удаления других.

**Пример**.

Рассмотрим следующую таблицу, которая не нормализована:

| ID | Name | Role | Team |
| --- | ------ | ----------------- | ---- |
| 1 | Питер | инженер-программист | A |
| 2 | Брайан | DevOps инженер | B |
| 3 | Хейли | Product Manager | C |
| 4 | Хейли | менеджер по продукту | C |
| 5 | Стив | Frontend Engineer | D |

Представим, что мы наняли нового человека "Джон", но ему не сразу назначили команду. Это вызовет аномалию вставки, поскольку атрибут команды еще не присутствует.

Далее, допустим, Хейли из команды C получила повышение, чтобы отразить это изменение в базе данных, нам нужно будет обновить 2 строки для поддержания согласованности, что может вызвать аномалию _обновления_.

Наконец, мы хотим удалить команду B, но для этого нам также потребуется удалить дополнительную информацию, такую как имя и роль, это пример аномалии _удаления_.

## Нормализация

Нормализация - это процесс организации данных в базе данных. Он включает в себя создание таблиц и установление отношений между ними в соответствии с правилами, призванными как защитить данные, так и сделать базу данных более гибкой за счет устранения избыточности и противоречивых зависимостей.

### Зачем нужна нормализация?

Цель нормализации - устранить избыточные данные и обеспечить их согласованность. Полностью нормализованная база данных позволяет расширять ее структуру для размещения новых типов данных без сильного изменения существующей структуры. В результате приложения, взаимодействующие с базой данных, подвергаются минимальному воздействию.

### Нормальные формы

Нормальные формы - это ряд рекомендаций, обеспечивающих нормализацию базы данных. Давайте обсудим некоторые основные нормальные формы:

**1NF**

Чтобы таблица находилась в первой нормальной форме (1НФ), она должна соответствовать следующим правилам:

- Повторяющиеся группы не допускаются.
- Каждый набор связанных данных должен быть идентифицирован первичным ключом.
- Набор связанных данных должен иметь отдельную таблицу.
- Смешение типов данных в одном столбце не допускается.

**2NF**.

Чтобы таблица была во второй нормальной форме (2НФ), она должна соответствовать следующим правилам:

- Удовлетворяет первой нормальной форме (1НФ).
- Не должна иметь частичных зависимостей.

**3NF**

Чтобы таблица находилась в третьей нормальной форме (3NF), она должна соответствовать следующим правилам:

- Удовлетворяет второй нормальной форме (2НФ).
- Переходные функциональные зависимости не допускаются.

**BCNF**

Нормальная форма Бойса-Кодда (или BCNF) - это несколько более сильная версия третьей нормальной формы (3NF), используемая для решения некоторых типов аномалий, с которыми не справляется 3NF в своем первоначальном виде. Иногда ее также называют нормальной формой 3,5 (3,5НФ).

Чтобы таблица была в нормальной форме Бойса-Кодда (BCNF), она должна соответствовать следующим правилам:

- Удовлетворяет третьей нормальной форме (3НФ).
- Для каждой функциональной зависимости X → Y, X должен быть суперключом.

Существуют и другие нормальные формы, такие как 4НФ, 5НФ и 6НФ, но мы не будем обсуждать их здесь. Посмотрите это [удивительное видео](https://www.youtube.com/watch?v=GFQaEYEc8_8), где все подробно описано.

В реляционных базах данных отношение часто называют _"нормализованным"_, если оно соответствует третьей нормальной форме. Большинство 3НФ-отношений не содержат аномалий при вставке, обновлении и удалении.

Как и в случае со многими формальными правилами и спецификациями, реальные сценарии не всегда позволяют добиться идеального соответствия. Если вы решите нарушить одно из первых трех правил нормализации, убедитесь, что ваше приложение предвидит возможные проблемы, такие как избыточные данные и противоречивые зависимости.

### Преимущества

Вот некоторые преимущества нормализации:

- Уменьшение избыточности данных.
- Улучшение дизайна данных.
- Повышает согласованность данных.
- Обеспечивает ссылочную целостность.

### Недостатки

Давайте рассмотрим некоторые недостатки нормализации:

- Сложный дизайн данных.
- Замедление производительности.
- Накладные расходы на обслуживание.
- Требуется больше соединений.

## Денормализация

Денормализация - это техника оптимизации базы данных, при которой мы добавляем избыточные данные в одну или несколько таблиц. Это может помочь нам избежать дорогостоящих объединений в реляционной базе данных. Она пытается улучшить производительность чтения за счет некоторого снижения производительности записи. Избыточные копии данных записываются в несколько таблиц, чтобы избежать дорогостоящих объединений.

Когда данные становятся распределенными с помощью таких техник, как федерация и шардинг, управление соединениями по сети еще больше усложняется. Денормализация позволяет обойти необходимость в таких сложных соединениях.

_Примечание: Денормализация не означает отмену нормализации._

### Преимущества

Давайте рассмотрим некоторые преимущества денормализации:

- Получение данных происходит быстрее.
- Написание запросов стало проще.
- Сокращение числа таблиц.
- Удобство управления.

### Недостатки

Ниже перечислены некоторые недостатки денормализации:

- Дорогие вставки и обновления.
- Повышает сложность проектирования базы данных.
- Увеличение избыточности данных.
- Больше шансов на несогласованность данных.

# Модели согласованности ACID и BASE

Давайте обсудим модели согласованности ACID и BASE.

## ACID

Термин ACID расшифровывается как Atomicity, Consistency, Isolation, and Durability. Свойства ACID используются для поддержания целостности данных во время обработки транзакций.

Для того чтобы поддерживать целостность данных до и после транзакции, реляционные базы данных следуют свойствам ACID. Давайте разберемся в этих терминах:

### Атомарный

Все операции в транзакции завершаются успешно или все операции откатываются.

### Consistent

По завершении транзакции база данных становится структурно целостной.

### Изолированная

Транзакции не конфликтуют друг с другом. Спорный доступ к данным сдерживается базой данных, так что транзакции выглядят как последовательно выполняющиеся.

### Долговечность

После того как транзакция завершена и записи и обновления записаны на диск, она останется в системе, даже если произойдет сбой в системе.

## BASE

С увеличением объема данных и требований к высокой доступности подход к проектированию баз данных также значительно изменился. Чтобы увеличить способность к масштабированию и одновременно обеспечить высокую доступность, мы переносим логику из базы данных на отдельные серверы. Таким образом, база данных становится более независимой и ориентированной на реальный процесс хранения данных.

В мире баз данных NoSQL транзакции ACID встречаются реже, поскольку некоторые базы данных ослабили требования к немедленной согласованности, свежести и точности данных, чтобы получить другие преимущества, такие как масштаб и отказоустойчивость.

Свойства BASE намного слабее, чем гарантии ACID, но прямого соответствия один к одному между этими двумя моделями согласованности не существует. Давайте разберемся в этих терминах:

### Базовая доступность

База данных работает большую часть времени.

### Мягкое состояние

Хранилища не обязательно должны быть согласованными на запись, как и разные реплики не должны быть все время взаимно согласованными.

### Последовательность в конечном итоге

Данные могут не быть согласованными сразу, но со временем они становятся согласованными. Чтение в системе все еще возможно, даже если оно может не дать правильного ответа из-за несогласованности.

## Компромиссы между ACID и BASE

Не существует правильного ответа на вопрос о том, какая модель согласованности нужна нашему приложению - ACID или BASE. Обе модели были разработаны для удовлетворения различных требований. Выбирая базу данных, мы должны учитывать свойства обеих моделей и требования нашего приложения.

Учитывая слабую согласованность BASE, разработчикам необходимо быть более осведомленными и строгими в отношении согласованности данных, если они выбирают BASE-хранилище для своего приложения. Очень важно знать поведение BASE в выбранной базе данных и работать в рамках этих ограничений.

С другой стороны, планирование с учетом BASE-ограничений иногда может стать серьезным недостатком по сравнению с простотой ACID-транзакций. Полностью ACID-база данных идеально подходит для тех случаев, когда важна надежность и согласованность данных.

# CAP Теорема

Теорема CAP утверждает, что распределенная система может обеспечить только две из трех желаемых характеристик - согласованность, доступность и устойчивость к разбиению (CAP).

![cap-theorem](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/cap-theorem/cap-theorem.png)

Давайте подробно рассмотрим три характеристики распределенной системы, на которые ссылается теорема CAP.

### Согласованность

Согласованность означает, что все клиенты видят одни и те же данные в одно и то же время, независимо от того, к какому узлу они подключаются. Чтобы этого не произошло, при записи данных на один узел они должны быть мгновенно переданы или реплицированы на все узлы системы, прежде чем запись будет признана "успешной".

### Доступность

Доступность означает, что любой клиент, сделавший запрос на получение данных, получит ответ, даже если один или несколько узлов не работают.

### Толерантность к разделению

Устойчивость к разделам означает, что система продолжает работать, несмотря на потерю сообщений или частичный отказ. Система, устойчивая к разделам, может выдержать любое количество отказов сети, не приводящее к отказу всей сети. Данные в достаточной степени реплицируются между комбинациями узлов и сетей, чтобы система продолжала работать при периодических сбоях.

## Компромисс между согласованностью и доступностью

Мы живем в физическом мире и не можем гарантировать стабильность сети, поэтому распределенные базы данных должны выбирать терпимость к разделам (P). Это подразумевает компромисс между согласованностью (C) и доступностью (A).

### База данных CA

База данных CA обеспечивает согласованность и доступность на всех узлах. Она не может этого сделать, если между любыми двумя узлами в системе есть разделение, и поэтому не может обеспечить отказоустойчивость.

**Пример**: [PostgreSQL](https://www.postgresql.org), [MariaDB](https://mariadb.org).

### База данных CP

База данных CP обеспечивает согласованность и устойчивость к разделам за счет доступности. Когда между двумя узлами возникает разделение, система должна выключить несовместимый узел, пока разделение не будет устранено.

**Пример**: [MongoDB](https://www.mongodb.com), [Apache HBase](https://hbase.apache.org).

### База данных AP

База данных AP обеспечивает доступность и устойчивость к разделам за счет согласованности. Когда происходит разделение, все узлы остаются доступными, но узлы, находящиеся не на том конце раздела, могут возвращать более старую версию данных, чем другие. Когда раздел разрешается, базы данных AP обычно повторно синхронизируют узлы, чтобы устранить все несоответствия в системе.

**Пример**: [Apache Cassandra](https://cassandra.apache.org), [CouchDB](https://couchdb.apache.org).

# Теорема PACELC

Теорема PACELC является расширением теоремы CAP. Теорема CAP утверждает, что в случае разделения сети (P) в распределенной системе необходимо выбирать между доступностью (A) и согласованностью (C).

PACELC расширяет теорему CAP, вводя задержку (L) в качестве дополнительного атрибута распределенной системы. Теорема утверждает, что в противном случае (E), даже когда система работает нормально при отсутствии разделов, приходится выбирать между задержкой (L) и согласованностью (C).

_Теорема PACELC была впервые описана [Daniel J. Abadi](https://scholar.google.com/citations?user=zxeEF2gAAAAJ)._

![pacelc-theorem](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/pacelc-theorem/pacelc-theorem.png)

Теорема PACELC была разработана для устранения ключевого ограничения теоремы CAP, поскольку она не учитывает производительность и задержку.

Например, согласно теореме CAP, база данных может считаться доступной, если запрос возвращает ответ через 30 дней. Очевидно, что такая задержка неприемлема для любого реального приложения.

# Транзакции

Транзакция - это серия операций над базой данных, которые рассматриваются как "единое целое". Операции в транзакции либо все успешны, либо все неудачны. Таким образом, понятие транзакции поддерживает целостность данных, когда часть системы выходит из строя. Не все базы данных предпочитают поддерживать ACID-транзакции, обычно потому, что для них приоритетны другие оптимизации, которые трудно или теоретически невозможно реализовать вместе.

_Обычно реляционные базы данных поддерживают транзакции ACID, а нереляционные - нет (бывают исключения)._

## Состояния

Транзакция в базе данных может находиться в одном из следующих состояний:

![transaction-states](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/transactions/transaction-states.png)

### Active

В этом состоянии транзакция находится в процессе выполнения. Это начальное состояние каждой транзакции.

### Partially Committed

Когда транзакция выполняет свою заключительную операцию, считается, что она находится в состоянии частичной фиксации.

### Committed

Если транзакция успешно выполняет все свои операции, считается, что она зафиксирована. Все ее последствия теперь навсегда закреплены в системе базы данных.

### Failed

Транзакция считается неудачной, если ни одна из проверок, выполненных системой восстановления базы данных, не дала результата. Провалившаяся транзакция больше не может продолжаться.

### Aborted

Если любая из проверок не удалась и транзакция достигла состояния неудачи, менеджер восстановления откатывает все свои операции записи в базу данных, чтобы вернуть базу данных в исходное состояние, в котором она находилась до выполнения транзакции. Транзакции в этом состоянии прерываются.

Модуль восстановления базы данных может выбрать одну из двух операций после прерывания транзакции:

- Перезапустить транзакцию
- Завершить транзакцию

### Terminated

Если отката не было или транзакция пришла из состояния _committed state_, то система согласована и готова к новой транзакции, а старая транзакция завершается.

# Распределенные транзакции

Распределенная транзакция - это набор операций над данными, выполняемых в двух или более базах данных. Обычно она координируется на отдельных узлах, соединенных сетью, но может охватывать и несколько баз данных на одном сервере.

## Зачем нужны распределенные транзакции?

В отличие от ACID-транзакции в одной базе данных, распределенная транзакция предполагает изменение данных в нескольких базах данных. Следовательно, обработка распределенных транзакций сложнее, поскольку база данных должна координировать фиксацию или откат изменений в транзакции как единое целое.

Другими словами, все узлы должны зафиксировать изменения, или все должны прервать транзакцию, и вся транзакция откатывается назад. Вот почему нам нужны распределенные транзакции.

Теперь давайте рассмотрим некоторые популярные решения для распределенных транзакций:

## Двухфазный коммит

![two-phase-commit](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/two-phase-commit.png)

Протокол двухфазной фиксации (2PC) - это распределенный алгоритм, который координирует все процессы, участвующие в распределенной транзакции, по вопросу фиксации или прерывания (отката) транзакции.

Этот протокол достигает своей цели даже во многих случаях временного сбоя системы и поэтому широко используется. Однако он не устойчив ко всем возможным конфигурациям сбоев, и в редких случаях для исправления ситуации требуется ручное вмешательство.

Этот протокол требует наличия узла-координатора, который, по сути, координирует и контролирует транзакции между различными узлами. Координатор пытается установить консенсус между множеством процессов в две фазы, отсюда и название.

### Фазы

Двухфазная фиксация состоит из следующих фаз:

**Фаза подготовки**.

В фазе подготовки узел-координатор собирает консенсус от каждого из узлов-участников. Транзакция будет прервана, если каждый из узлов не ответит, что он _подготовлен_.

**Фаза фиксации**.

Если все участники ответили координатору, что они _готовятся_, то координатор просит все узлы зафиксировать транзакцию. Если произойдет сбой, транзакция будет откачена.

### Проблемы

При использовании двухфазного протокола фиксации могут возникнуть следующие проблемы:

- Что делать, если один из узлов потерпел крах?
- Что, если сломается сам координатор?
- Это блокирующий протокол.

## Трехфазная фиксация (3PC)

![three-phase-commit](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/three-phase-commit.png)

Трехфазная фиксация (3PC) - это расширение двухфазной фиксации, в котором фаза фиксации разбивается на две фазы. Это помогает решить проблему блокировки, которая возникает в протоколе двухфазной фиксации.

### Фазы

Трехфазная фиксация состоит из следующих фаз:

**Фаза подготовки**.

Эта фаза аналогична двухфазной фиксации.

**Фаза предварительной фиксации**.

Координатор выпускает сообщение pre-commit, и все участвующие узлы должны его подтвердить. Если участник не получает это сообщение вовремя, то транзакция прерывается.

**Фаза коммита**

Этот этап также похож на двухфазный протокол фиксации.

### Почему фаза предварительной фиксации полезна?

Фаза предварительной коммисии выполняет следующее:

- Если узлы-участники найдены в этой фазе, это означает, что _каждый_ участник завершил первую фазу. Завершение фазы подготовки гарантировано.
- Теперь каждая фаза может отработать по времени и избежать бесконечных ожиданий.

## Саги

![sagas](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/sagas.png)

Сага - это последовательность локальных транзакций. Каждая локальная транзакция обновляет базу данных и публикует сообщение или событие для запуска следующей локальной транзакции в саге. Если локальная транзакция терпит неудачу из-за нарушения бизнес-правил, сага выполняет серию компенсирующих транзакций, которые отменяют изменения, внесенные предыдущими локальными транзакциями.

### Координация

Существует два распространенных подхода к реализации:

- **Хореография**: Каждая локальная транзакция публикует события в домене, которые вызывают локальные транзакции в других сервисах.
- **Оркестрация**: Оркестрант указывает участникам, какие локальные транзакции выполнять.

### Проблемы

- Паттерн Saga особенно трудно отлаживать.
- Существует риск возникновения циклической зависимости между участниками саги.
- Отсутствие изоляции данных участников создает проблемы с долговечностью.
- Тестирование затруднено, поскольку для имитации транзакции должны быть запущены все службы.

# Шардинг

Прежде чем обсуждать шардинг, давайте поговорим о разделении данных:

## Разбиение данных

Разбиение данных - это техника, позволяющая разбить базу данных на множество более мелких частей. Это процесс разделения базы данных или таблицы на несколько машин для улучшения управляемости, производительности и доступности базы данных.

### Методы

Существует множество различных способов решить, как разбить базу данных приложения на несколько меньших БД. Ниже приведены два наиболее популярных метода, используемых в различных крупномасштабных приложениях:

**Горизонтальное разбиение (или шардинг)**.

В этой стратегии мы разбиваем данные таблицы по горизонтали на основе диапазона значений, определяемого _ключом раздела_. Ее также называют **разбиением базы данных на части_**.

**Вертикальное разбиение**

При вертикальном разбиении мы разделяем данные по вертикали на основе столбцов. Мы делим таблицы на относительно меньшие таблицы с небольшим количеством элементов, и каждая часть находится в отдельном разделе.

В этом руководстве мы сосредоточимся на шардинге.

## Что такое шардинг?

Шардинг - это архитектурный паттерн базы данных, связанный с _горизонтальным разделением_, которое представляет собой практику разделения строк одной таблицы на несколько различных таблиц, известных как _разделы_ или _шарды_. Каждый раздел имеет одну и ту же схему и столбцы, но также подмножество общих данных. Кроме того, данные, хранящиеся в каждом из разделов, уникальны и не зависят от данных, хранящихся в других разделах.

![sharding](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/sharding/sharding.png)

Оправданием шардинга данных является то, что после определенного момента дешевле и целесообразнее масштабировать систему по горизонтали, добавляя больше машин, чем по вертикали, добавляя мощные серверы. Разделение может быть реализовано как на уровне приложения, так и на уровне базы данных.

## Критерии разделения

Существует большое количество критериев для разделения данных. Наиболее часто используются следующие критерии:

### Hash-Based

Эта стратегия разделяет строки на различные разделы на основе алгоритма хэширования, а не группирует строки базы данных на основе непрерывных индексов.

Недостатком этого метода является то, что динамическое добавление/удаление серверов базы данных становится дорогостоящим.

### Разбиение на основе списков

При списочном разбиении каждый раздел определяется и выбирается на основе списка значений в столбце, а не набора смежных диапазонов значений.

### Range Based

Разбиение по диапазонам сопоставляет данные с различными разделами на основе диапазонов значений ключа разбиения. Другими словами, мы разбиваем таблицу таким образом, чтобы каждый раздел содержал строки в заданном диапазоне, определяемом ключом разбиения.

Диапазоны должны быть смежными, но не пересекающимися, где каждый диапазон определяет неполную нижнюю и верхнюю границу раздела. Любые значения ключа раздела, равные или превышающие верхнюю границу диапазона, добавляются к следующему разделу.

### Композитный

Как следует из названия, составное разбиение разделяет данные на основе двух или более методов разбиения. Сначала мы разбиваем данные с помощью одного метода, а затем каждый раздел делится на подразделы с помощью того же или другого метода.

## Преимущества

Но зачем нам нужно шардинг? Вот некоторые преимущества:

- **Доступность**: Обеспечивает логическую независимость разделенной на разделы базы данных, гарантируя высокую доступность нашего приложения. Отдельные разделы могут управляться независимо друг от друга.
- **Масштабируемость**: Обеспечивает увеличение масштабируемости за счет распределения данных по нескольким разделам.
- **Безопасность**: Помогает повысить безопасность системы за счет хранения чувствительных и нечувствительных данных в разных разделах. Это обеспечивает лучшую управляемость и безопасность конфиденциальных данных.
- **Производительность запросов**: Повышает производительность системы. Вместо того чтобы запрашивать всю базу данных, теперь системе нужно запрашивать только меньший раздел.
- **Управляемость данных**: Разделение таблиц и индексов на более мелкие и управляемые единицы.
  
## Недостатки

- **Сложность**: Шардинг увеличивает сложность системы в целом.
- **Соединения между шардами**: Когда база данных разбита на разделы и распределена по нескольким машинам, часто бывает нецелесообразно выполнять соединения, охватывающие несколько шардов базы данных. Такие соединения не будут эффективными с точки зрения производительности, поскольку данные придется получать с нескольких серверов.
- **Ребалансировка**: Если распределение данных неравномерно или на один шард приходится большая нагрузка, в таких случаях необходимо перебалансировать шарды, чтобы запросы распределялись между ними как можно равномернее.

## Когда использовать шардинг?

Вот несколько причин, по которым шардинг может быть правильным выбором:

- Использование существующего оборудования вместо высокопроизводительных машин.
- Хранение данных в разных географических регионах.
- Быстрое масштабирование путем добавления новых шардов.
- Более высокая производительность, поскольку каждая машина испытывает меньшую нагрузку.
- Когда требуется больше одновременных подключений.

# Последовательное хэширование

Давайте сначала разберемся, какую проблему мы пытаемся решить.

## Зачем нам это нужно?

В традиционных методах распределения, основанных на хэшировании, мы используем хэш-функцию для хэширования наших ключей раздела (т. е. идентификатора запроса или IP). Затем, если мы используем модуло против общего количества узлов (серверов или баз данных). Это даст нам узел, куда мы хотим направить наш запрос.

![simple-hashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/simple-hashing.png)

$$
\begin{align*}
& Hash(key_1) \to H_1 \bmod N = Node_0 \\
& Hash(key_2) \to H_2 \bmod N = Node_1 \\
& Hash(key_3) \to H_3 \bmod N = Node_2 \\
& ... \\
& Hash(key_n) \to H_n \bmod N = Node_{n-1}
\end{align*}
$$

Где,

`key`: Идентификатор запроса или IP.

`H`: Результат хэш-функции.

`N`: Общее количество узлов.

`Node`: Узел, на который будет направлен запрос.

Проблема в том, что если мы добавим или удалим узел, это приведет к изменению `N`, а значит, наша стратегия отображения нарушится, так как те же самые запросы теперь будут направляться на другой сервер. Как следствие, большинство запросов придется перераспределять, что очень неэффективно.

Мы хотим равномерно распределять запросы между различными узлами, чтобы можно было добавлять или удалять узлы с минимальными усилиями. Следовательно, нам нужна схема распределения, которая не зависит напрямую от количества узлов (или серверов), чтобы при добавлении или удалении узлов количество ключей, которые нужно переместить, было минимальным.

Последовательное хеширование решает эту проблему горизонтальной масштабируемости, гарантируя, что при каждом увеличении или уменьшении масштаба нам не придется переставлять все ключи или трогать все серверы.

Теперь, когда мы поняли суть проблемы, давайте обсудим последовательное хеширование более подробно.

## Как это работает

Consistent Hashing - это распределенная схема хеширования, которая работает независимо от количества узлов в распределенной хеш-таблице, присваивая им позицию на абстрактном круге, или хеш-кольце. Это позволяет масштабировать серверы и объекты без ущерба для всей системы.

![последовательное хэширование](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/consistent-hashing.png)

При использовании последовательного хэширования только данные `K/N` требуют перераспределения.

$$
R = K/N
$$

Где,

`R`: Данные, требующие повторного распространения.

`K`: Количество ключей разделов.

`N`: Количество узлов.

Выход хэш-функции - это диапазон, скажем, `0...m-1`, который мы можем представить на нашем хэш-кольце. Мы хэшируем запросы и распределяем их по кольцу в зависимости от того, что получилось на выходе. Аналогичным образом мы хэшируем узлы и распределяем их по тому же кольцу.

$$
\begin{align*}
& Hash(key_1) = P_1 \\
& Hash(key_2) = P_2 \\
& Hash(key_3) = P_3 \\
& ... \\
& Hash(key_n) = P_{m-1}
\end{align*}
$$

Где,

`ключ`: Идентификатор запроса/узла или IP.

`P`: Позиция в хэш-кольце.

`m`: Общий радиус действия хэш-кольца.

Теперь, когда поступает запрос, мы можем просто направить его на ближайший узел по часовой стрелке (можно и против часовой). Это означает, что если добавляется или удаляется новый узел, мы можем использовать ближайший узел, и только _часть_ запросов нужно будет перенаправлять.

В теории последовательное хеширование должно равномерно распределять нагрузку, однако на практике этого не происходит. Обычно нагрузка распределяется неравномерно, и один сервер может в итоге обрабатывать большую часть запросов, становясь _горячей точкой_, по сути, узким местом в системе. Это можно исправить, добавив дополнительные узлы, но это может быть дорого.

## Виртуальные узлы

Чтобы обеспечить более равномерное распределение нагрузки, мы можем ввести идею виртуального узла, иногда также называемого VNode.

Вместо того чтобы назначать узлу одну позицию, хэш-диапазон делится на несколько меньших диапазонов, и каждому физическому узлу назначается несколько таких меньших диапазонов. Каждый из этих поддиапазонов считается виртуальным узлом. Таким образом, виртуальные узлы - это, по сути, существующие физические узлы, отображенные несколько раз в хэш-кольце, чтобы минимизировать изменения в назначенном узлу диапазоне.

![virtual-nodes](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/virtual-nodes.png)

Для этого мы можем использовать `k` количество хэш-функций.

$$
\begin{align*}
& Hash_1(key_1) = P_1 \\
& Hash_2(key_2) = P_2 \\
& Hash_3(key_3) = P_3 \\
& . . . \\
& Hash_k(key_n) = P_{m-1}
\end{align*}
$$

Где,

`ключ`: Идентификатор запроса/узла или IP.

`k`: Количество хэш-функций.

`P`: Позиция в хэш-кольце.

`m`: Общий диапазон хэш-кольца.

Поскольку VNodes помогают более равномерно распределить нагрузку между физическими узлами кластера, разбивая хэш-диапазоны на более мелкие поддиапазоны, это ускоряет процесс перебалансировки после добавления или удаления узлов. Это также помогает нам уменьшить вероятность возникновения "горячих точек".

## Репликация данных

Для обеспечения высокой доступности и долговечности последовательное хеширование реплицирует каждый элемент данных на нескольких `N` узлах системы, где значение `N` эквивалентно _фактору репликации_.

Фактор репликации - это количество узлов, которые получат копию одних и тех же данных. В конечном итоге в согласованных системах это делается асинхронно.

## Преимущества

Давайте рассмотрим некоторые преимущества последовательного хеширования:

- Делает более предсказуемым быстрое масштабирование вверх и вниз.
- Облегчает разделение и репликацию между узлами.
- Обеспечивает масштабируемость и доступность.
- Уменьшает количество "горячих точек".

## Недостатки

Ниже перечислены некоторые недостатки последовательного хеширования:

- Повышение сложности.
- Каскадные сбои.
- Распределение нагрузки может быть неравномерным.
- Управление ключами может быть дорогостоящим, если узлы периодически выходят из строя.

## Примеры

Давайте рассмотрим несколько примеров использования последовательного хеширования:

- Разбиение данных в [Apache Cassandra](https://cassandra.apache.org).
- Распределение нагрузки между несколькими узлами хранения в [Amazon DynamoDB](https://aws.amazon.com/dynamodb).

# Федерация баз данных

Федерация (или функциональное разделение) разделяет базы данных по функциям. Благодаря архитектуре федерации несколько отдельных физических баз данных представляются конечным пользователям как одна логическая база данных.

Все компоненты федерации связаны между собой одной или несколькими федеративными схемами, которые выражают общность данных во всей федерации. Эти федеративные схемы используются для определения информации, которая может быть совместно использована компонентами федерации, и для обеспечения общей основы для взаимодействия между ними.

![database-federation](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-federation/database-federation.png)

Федерация также обеспечивает целостное, единое представление данных, полученных из нескольких источников. Источниками данных для федеративных систем могут быть базы данных и различные другие формы структурированных и неструктурированных данных.

## Характеристики

Давайте рассмотрим некоторые ключевые характеристики федеративной базы данных:

- **Прозрачность**: Федеративная база данных маскирует различия между пользователями и реализациями базовых источников данных. Поэтому пользователям не нужно знать, где хранятся данные.
- **Гетерогенность**: Источники данных могут различаться по многим параметрам. Система федеративных баз данных может работать с различным оборудованием, сетевыми протоколами, моделями данных и т. д.
- **Расширяемость**: Для удовлетворения меняющихся потребностей бизнеса могут потребоваться новые источники. Хорошая система федеративных баз данных должна обеспечивать простоту добавления новых источников.
- **Автономность**: Федеративная база данных не изменяет существующие источники данных, интерфейсы должны оставаться прежними.
- **Интеграция данных**: Федеративная база данных может интегрировать данные из различных протоколов, систем управления базами данных и т. д.

## Преимущества

Вот некоторые преимущества федеративных баз данных:

- Гибкое совместное использование данных.
- Автономность компонентов базы данных.
- Единый доступ к разнородным данным.
- Отсутствие жесткой связи приложений с унаследованными базами данных.

## Недостатки

Ниже перечислены некоторые недостатки федеративных баз данных:

- Добавляет больше оборудования и дополнительные сложности.
- Объединение данных из двух баз данных является сложной задачей.
- Зависимость от автономных источников данных.
- Производительность запросов и масштабируемость.

# N-уровневая архитектура

N-уровневая архитектура делит приложение на логические и физические уровни. Слои - это способ разделения ответственности и управления зависимостями. Каждый уровень несет определенную ответственность. Более высокий уровень может использовать сервисы более низкого уровня, но не наоборот.

![n-tier-architecture](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/n-tier-architecture/n-tier-architecture.png)

Уровни физически разделены, работают на разных машинах. Уровень может обращаться к другому уровню напрямую или использовать асинхронный обмен сообщениями. Хотя каждый уровень может быть размещен на отдельном уровне, это не обязательно. Несколько уровней могут быть размещены на одном ярусе. Физическое разделение уровней улучшает масштабируемость и отказоустойчивость и увеличивает задержки из-за дополнительного сетевого взаимодействия.

N-уровневая архитектура может быть двух типов:

- В архитектуре с закрытыми уровнями уровень может обращаться только к следующему уровню, расположенному сразу за ним.
- В архитектуре с открытыми уровнями уровень может вызывать любой из нижележащих уровней.

Архитектура закрытого уровня ограничивает зависимости между уровнями. Однако она может создавать ненужный сетевой трафик, если один уровень просто передает запросы следующему уровню.

## Типы N-уровневых архитектур

Давайте рассмотрим некоторые примеры N-уровневых архитектур:

### 3-уровневая архитектура

Трехуровневая архитектура широко распространена и состоит из следующих различных уровней:

- **Презентационный уровень**: Управляет взаимодействием пользователей с приложением.
- **Уровень бизнес-логики**: Принимает данные от прикладного уровня, проверяет их в соответствии с бизнес-логикой и передает их на уровень данных.
- **Уровень доступа к данным**: Получает данные от бизнес-слоя и выполняет необходимые операции с базой данных.

### Двухуровневая архитектура

В этой архитектуре презентационный слой работает на клиенте и взаимодействует с хранилищем данных. Между клиентом и сервером нет ни слоя бизнес-логики, ни непосредственного слоя.

### Одноуровневая или 1-Tier архитектура

Это самая простая архитектура, поскольку она эквивалентна запуску приложения на персональном компьютере. Все необходимые компоненты для работы приложения находятся на одном приложении или сервере.

## Преимущества

Вот некоторые преимущества использования N-уровневой архитектуры:

- Повышение доступности.
- Повышение безопасности, так как уровни могут вести себя как брандмауэр.
- Отдельные уровни позволяют масштабировать их по мере необходимости.
- Улучшение обслуживания, так как разные люди могут управлять разными уровнями.

## Недостатки

Ниже перечислены некоторые недостатки N-уровневой архитектуры:

- Повышенная сложность системы в целом.
- Увеличение сетевых задержек при увеличении числа уровней.
- Дороговизна, поскольку каждый уровень будет иметь свои собственные аппаратные затраты.
- Сложность управления сетевой безопасностью.

# Брокеры сообщений

Брокер сообщений - это программное обеспечение, которое позволяет приложениям, системам и сервисам взаимодействовать друг с другом и обмениваться информацией. Брокер сообщений делает это путем трансляции сообщений между формальными протоколами обмена сообщениями. Это позволяет взаимозависимым сервисам "разговаривать" друг с другом напрямую, даже если они написаны на разных языках или реализованы на разных платформах.

![message-broker](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-brokers/message-broker.png)

Брокеры сообщений могут проверять, хранить, маршрутизировать и доставлять сообщения по назначению. Они служат посредниками между другими приложениями, позволяя отправителям отправлять сообщения, не зная, где находятся получатели, активны ли они, и сколько их всего. Это облегчает разделение процессов и сервисов в системах.

## Модели

Брокеры сообщений предлагают две основные модели распределения сообщений или стили обмена сообщениями:

- **[Point-to-Point messaging](https://karanpratapsingh.com/courses/system-design/message-queues)**: Это схема распределения, используемая в очередях сообщений с отношениями "один к одному" между отправителем и получателем сообщения.
- **[Publish-Subscribe messaging](https://karanpratapsingh.com/courses/system-design/publish-subscribe)**: В этом шаблоне распределения сообщений, часто называемом _"pub/sub"_, производитель каждого сообщения публикует его в теме, а множество потребителей сообщений подписываются на темы, от которых они хотят получать сообщения.

_Мы подробно рассмотрим эти шаблоны обмена сообщениями в последующих уроках._

## Брокеры сообщений и потоковая передача событий

Брокеры сообщений могут поддерживать два или более шаблонов обмена сообщениями, включая очереди сообщений и pub/sub, в то время как платформы потоковой передачи событий предлагают только шаблоны распределения в стиле pub/sub. Платформы потоковой передачи событий, предназначенные для работы с большими объемами сообщений, легко масштабируются. Они способны упорядочивать потоки записей по категориям, называемым _темами_, и хранить их в течение заранее определенного времени. Однако, в отличие от брокеров сообщений, платформы потоковой передачи событий не могут гарантировать доставку сообщений или отслеживать, какие потребители получили сообщения.

Платформы потоковой передачи событий обладают большей масштабируемостью, чем брокеры сообщений, но меньшим количеством функций, обеспечивающих отказоустойчивость, таких как повторная отправка сообщений, а также более ограниченными возможностями маршрутизации и постановки сообщений в очередь.

## Message brokers vs Enterprise Service Bus (ESB)

Инфраструктура [Enterprise Service Bus (ESB)](https://karanpratapsingh.com/courses/system-design/enterprise-service-bus) сложна, ее интеграция и обслуживание могут оказаться дорогостоящими. Их сложно устранять при возникновении проблем в производственных средах, их нелегко масштабировать, а обновление является утомительным.

Брокеры сообщений - это _"облегченная"_ альтернатива ESB, которая обеспечивает аналогичную функциональность, механизм межсервисного взаимодействия, но при этом стоит дешевле. Они хорошо подходят для использования в [архитектурах микросервисов](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices), которые стали более распространенными, поскольку ESB вышли из моды

## Примеры

Вот некоторые часто используемые брокеры сообщений:

- [NATS](https://nats.io)
- [Apache Kafka](https://kafka.apache.org)
- [RabbitMQ](https://www.rabbitmq.com)
- [ActiveMQ](https://activemq.apache.org)

# Очереди сообщений

Очередь сообщений - это форма межсервисного взаимодействия, которая обеспечивает асинхронную связь. Она асинхронно получает сообщения от производителей и отправляет их потребителям.

Очереди используются для эффективного управления запросами в крупномасштабных распределенных системах. В небольших системах с минимальной нагрузкой на обработку и небольшими базами данных запись может быть предсказуемо быстрой. Однако в более сложных и больших системах запись может занимать практически недетерминированное время.

![message-queue](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-queues/message-queue.png)

## Устройство

Сообщения хранятся в очереди до тех пор, пока не будут обработаны и удалены. Каждое сообщение обрабатывается только один раз одним потребителем. Вот как это работает:

- Производитель публикует задание в очереди, а затем уведомляет пользователя о статусе задания.
- Потребитель забирает задание из очереди, обрабатывает его и сигнализирует о завершении работы.

## Преимущества

Давайте обсудим некоторые преимущества использования очереди сообщений:

- **Масштабируемость**: Очереди сообщений позволяют масштабировать именно там, где это необходимо. При пиковых нагрузках несколько экземпляров нашего приложения могут добавлять все запросы в очередь без риска столкновения.
- **Отсоединение**: Очереди сообщений устраняют зависимости между компонентами и значительно упрощают реализацию разделенных приложений.
- **Производительность**: Очереди сообщений обеспечивают асинхронную связь, что означает, что конечные точки, производящие и потребляющие сообщения, взаимодействуют с очередью, а не друг с другом. Производители могут добавлять запросы в очередь, не дожидаясь их обработки.
- **Надежность**: Очереди делают наши данные постоянными и уменьшают количество ошибок, которые возникают, когда различные части нашей системы выходят из строя.

## Особенности

Теперь давайте обсудим некоторые необходимые функции очередей сообщений:

### Push or Pull Delivery

Большинство очередей сообщений предоставляют как push, так и pull варианты получения сообщений. Pull означает постоянное обращение к очереди за новыми сообщениями. Push означает, что потребитель получает уведомление, когда сообщение доступно. Мы также можем использовать long-polling, чтобы позволить потребителям ожидать поступления новых сообщений в течение определенного времени.

### Очереди FIFO (First-In-First-Out)

В таких очередях первой обрабатывается самая старая (или первая) запись, которую иногда называют "головой" очереди.

### Расписание или задержка доставки

Многие очереди сообщений поддерживают установку определенного времени доставки сообщения. Если нам нужна общая задержка для всех сообщений, мы можем настроить очередь задержки.

### Доставка по очереди (At-Least-Once Delivery)

Очереди сообщений могут хранить несколько копий сообщений для обеспечения избыточности и высокой доступности, а также повторно отправлять сообщения в случае сбоев или ошибок связи, чтобы обеспечить их доставку хотя бы один раз.

### Exactly-Once Delivery

Когда дубликаты недопустимы, очереди сообщений FIFO (first-in-first-out) обеспечивают доставку каждого сообщения ровно один раз (и только один), автоматически отсеивая дубликаты.

### Очереди с мертвой буквой (Dead-letter Queues)

Очередь с мертвой буквой (DLQ) - это очередь, в которую другие очереди могут отправлять сообщения, которые не могут быть успешно обработаны. Это позволяет легко отложить их для дальнейшей проверки, не блокируя обработку очереди и не тратя циклы процессора на сообщение, которое, возможно, никогда не будет успешно обработано.

### Упорядочивание

Большинство очередей сообщений обеспечивают упорядочивание по принципу best-effort, что гарантирует доставку сообщений в том же порядке, в каком они были отправлены, и что сообщение будет доставлено хотя бы один раз.

### Сообщения с ядовитыми таблетками

Ядовитые таблетки - это специальные сообщения, которые могут быть получены, но не обработаны. Они являются механизмом, используемым для того, чтобы сигнализировать потребителю о завершении его работы, чтобы он больше не ждал новых входных данных, и похожи на закрытие сокета в модели клиент/сервер.

### Безопасность

Очереди сообщений аутентифицируют приложения, которые пытаются получить доступ к очереди. Это позволяет нам шифровать сообщения по сети, а также в самой очереди.

### Очереди задач

Очереди задач получают задания и связанные с ними данные, выполняют их, а затем доставляют результаты. Они могут поддерживать планирование и использоваться для выполнения вычислительно-интенсивных заданий в фоновом режиме.

## Обратное давление

Если очереди начинают сильно разрастаться, их размер может превысить объем памяти, что приведет к пропуску кэша, чтению с диска и еще большему снижению производительности. Обратное давление может помочь, ограничив размер очереди, тем самым поддерживая высокую пропускную способность и хорошее время отклика для заданий, уже находящихся в очереди. Когда очередь заполняется, клиенты получают сообщение о занятости сервера или код состояния HTTP 503, чтобы повторить попытку позже. Клиенты могут повторить запрос в более позднее время, возможно, с помощью стратегии [экспоненциального отката](https://en.wikipedia.org/wiki/Exponential_backoff).

## Примеры

Ниже приведены некоторые широко используемые очереди сообщений:

- [Amazon SQS](https://aws.amazon.com/sqs)
- [RabbitMQ](https://www.rabbitmq.com)
- [ActiveMQ](https://activemq.apache.org)
- [ZeroMQ](https://zeromq.org)

# Publish-Subscribe

Подобно очереди сообщений, публикация-подписка также является формой связи между сервисами, которая обеспечивает асинхронное взаимодействие. В модели pub/sub любое сообщение, опубликованное в теме, немедленно рассылается всем подписчикам этой темы.

![publish-subscribe](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/publish-subscribe/publish-subscribe.png)

Подписчики темы сообщения часто выполняют разные функции, и каждый из них может параллельно делать с сообщением что-то свое. Издателю не нужно знать, кто использует передаваемую им информацию, а подписчикам не нужно знать, откуда пришло сообщение. Такой стиль обмена сообщениями немного отличается от очередей сообщений, где компонент, отправляющий сообщение, часто знает, кому оно отправляется.

## Устройство

В отличие от очередей сообщений, которые хранят сообщения до тех пор, пока они не будут получены, темы сообщений передают сообщения практически без очереди и сразу же рассылают их всем подписчикам. Вот как это работает:

- Тема сообщений предоставляет легкий механизм для передачи асинхронных уведомлений о событиях и конечные точки, которые позволяют программным компонентам подключаться к теме для отправки и получения этих сообщений.
- Чтобы передать сообщение, компонент, называемый _издателем_, просто отправляет сообщение в тему.
- Все компоненты, подписанные на эту тему (известные как _подписчики_), получат каждое сообщение, которое было передано.

## Преимущества

Давайте обсудим некоторые преимущества использования publish-subscribe:

- **Устранение опроса**: Темы сообщений обеспечивают мгновенную доставку на основе push, устраняя необходимость для потребителей сообщений периодически проверять или _"опрашивать"_ новую информацию и обновления. Это способствует ускорению времени отклика и уменьшению задержки доставки, которая может быть особенно проблематичной в системах, где задержки недопустимы.
- **Динамическое нацеливание**: Pub/Sub делает процесс обнаружения сервисов более простым, естественным и менее подверженным ошибкам. Вместо того чтобы вести реестр пиров, которым приложение может отправлять сообщения, издатель просто публикует сообщения в теме. Затем любая заинтересованная сторона подписывает свою конечную точку на эту тему и начинает получать эти сообщения. Подписчики могут меняться, обновляться, множиться или исчезать, и система динамически подстраивается.
- **Разделённое и независимое масштабирование**: Издатели и подписчики разделены и работают независимо друг от друга, что позволяет нам развивать и масштабировать их независимо друг от друга.
- **Упрощение коммуникации**: Модель Publish-Subscribe снижает сложность, устраняя все соединения "точка-точка" с помощью одного соединения с темой сообщений, которая будет управлять подписками и решать, какие сообщения должны быть доставлены на конечные точки.

## Features

Теперь давайте обсудим некоторые необходимые функции publish-subscribe:

### Push Delivery

Сообщения Pub/Sub мгновенно отправляют асинхронные уведомления о событиях, когда сообщения публикуются в теме сообщения. Подписчики получают уведомления, когда сообщение становится доступным.

### Несколько протоколов доставки

В модели Publish-Subscribe темы, как правило, могут подключаться к нескольким типам конечных точек, таким как очереди сообщений, бессерверные функции, HTTP-серверы и т. д.

### Fanout

В этом случае сообщение отправляется в тему, а затем реплицируется и рассылается по нескольким конечным точкам. Fanout обеспечивает асинхронные уведомления о событиях, что, в свою очередь, позволяет выполнять параллельную обработку.

### Фильтрация

Эта функция позволяет подписчику создать политику фильтрации сообщений, чтобы он получал только те уведомления, которые его интересуют, а не все сообщения, опубликованные в данной теме.

### Долговечность

Службы обмена сообщениями Pub/Sub часто обеспечивают очень высокую долговечность и, по крайней мере, однократную доставку, храня копии одного и того же сообщения на нескольких серверах.

### Безопасность

Темы сообщений аутентифицируют приложения, которые пытаются опубликовать содержимое, что позволяет нам использовать зашифрованные конечные точки и шифровать сообщения при передаче по сети.

## Примеры

Вот некоторые часто используемые технологии публикации-подписки:

- [Amazon SNS](https://aws.amazon.com/sns)
- [Google Pub/Sub](https://cloud.google.com/pubsub)

# Enterprise Service Bus (ESB)

Сервисная шина предприятия (ESB) - это архитектурный паттерн, в котором централизованный программный компонент выполняет интеграцию между приложениями. Он выполняет преобразования моделей данных, управляет связью, выполняет маршрутизацию сообщений, преобразует протоколы связи и потенциально управляет композицией нескольких запросов. ESB может сделать эти интеграции и преобразования доступными в виде сервисного интерфейса для повторного использования новыми приложениями.

![enterprise-service-bus](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/enterprise-service-bus/enterprise-service-bus.png)

## Преимущества

Теоретически централизованная ESB позволяет стандартизировать и значительно упростить связь, обмен сообщениями и интеграцию между службами в масштабах предприятия. Вот некоторые преимущества использования ESB:

- **Повышение производительности разработчиков**: Позволяет разработчикам внедрять новые технологии в одну часть приложения, не затрагивая остальные части приложения.
- **Упрощенная и экономически эффективная масштабируемость**: Компоненты можно масштабировать независимо от других.
- **Большая отказоустойчивость**: Отказ одного компонента не влияет на остальные, и каждый микросервис может придерживаться собственных требований к доступности, не рискуя доступностью других компонентов системы.

## Недостатки

Хотя ESB были успешно внедрены во многих организациях, во многих других организациях ESB стали рассматривать как узкое место. Вот некоторые недостатки использования ESB:

- Внесение изменений или усовершенствований в одну интеграцию может дестабилизировать работу других, использующих эту же интеграцию.
- Единая точка отказа может вывести из строя все коммуникации.
- Обновления ESB часто влияют на существующие интеграции, поэтому для выполнения любого обновления требуется значительное тестирование.
- ESB управляется централизованно, что затрудняет взаимодействие между командами.
- Высокая сложность конфигурации и обслуживания.

## Примеры

Ниже приведены некоторые широко используемые технологии Enterprise Service Bus (ESB):

- [Azure Service Bus](https://azure.microsoft.com/en-in/services/service-bus)
- [IBM App Connect](https://www.ibm.com/in-en/cloud/app-connect)
- [Apache Camel](https://camel.apache.org)
- [Fuse ESB](https://www.redhat.com/en/technologies/jboss-middleware/fuse)

# Монолиты и микросервисы

## Монолиты

Монолит - это самодостаточное и независимое приложение. Оно создается как единое целое и отвечает не только за конкретную задачу, но и может выполнять все шаги, необходимые для удовлетворения бизнес-потребностей.

![monolith](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/monolith.png)

### Преимущества

Ниже перечислены некоторые преимущества монолитов:

- Простота разработки и отладки.
- Быстрая и надежная связь.
- Легкий мониторинг и тестирование.
- Поддержка ACID-транзакций.

### Недостатки

К общим недостаткам монолитов относятся:

- Сложность сопровождения по мере роста кодовой базы.
- Жестко связанное приложение, трудно расширяемое.
- Требуется приверженность определенному технологическому стеку.
- При каждом обновлении все приложение развертывается заново.
- Снижение надежности, поскольку одна ошибка может вывести из строя всю систему.
- Сложно масштабировать или внедрять новые технологии.

## Модульные монолиты

Модульный монолит - это подход, при котором мы создаем и развертываем одно приложение (это часть _монолита_), но строим его таким образом, что разбиваем код на независимые модули для каждой из функций, необходимых в нашем приложении.

Такой подход уменьшает зависимости модуля таким образом, что мы можем улучшать или изменять модуль, не затрагивая другие модули. При правильном подходе это может быть очень полезно в долгосрочной перспективе, так как снижает сложность, возникающую при поддержке монолита по мере роста системы.

## Микросервисы

Архитектура микросервисов состоит из набора небольших автономных сервисов, каждый из которых является самодостаточным и должен реализовывать одну бизнес-возможность в ограниченном контексте. Ограниченный контекст - это естественное разделение бизнес-логики, которое обеспечивает явную границу, в пределах которой существует модель домена.

![Микросервисы](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/microservices.png)

Каждый сервис имеет отдельную кодовую базу, которая может управляться небольшой командой разработчиков. Сервисы могут быть развернуты независимо друг от друга, и команда может обновлять существующий сервис без перестройки и развертывания всего приложения.

Сервисы отвечают за сохранение своих собственных данных или внешнего состояния (база данных для каждого сервиса). Это отличается от традиционной модели, в которой за сохранение данных отвечает отдельный слой данных.

### Характеристики

Стиль архитектуры микросервисов имеет следующие характеристики:

- **Свободно соединенные**: Сервисы должны быть слабо связаны друг с другом, чтобы их можно было независимо развертывать и масштабировать. Это приведет к децентрализации команд разработчиков и, таким образом, позволит им быстрее разрабатывать и внедрять сервисы с минимальными ограничениями и операционными зависимостями.
- **Мало, но целенаправленно**: Речь идет о масштабе и ответственности, а не о размере. Сервис должен быть ориентирован на решение конкретной проблемы. По сути, _"он делает одно дело и делает его хорошо"_. В идеале они могут быть независимы от базовой архитектуры.
- **Созданы для бизнеса**: Архитектура микросервисов обычно строится вокруг возможностей и приоритетов бизнеса.
- **Устойчивость и отказоустойчивость**: Сервисы должны быть спроектированы таким образом, чтобы они продолжали функционировать в случае сбоев или ошибок. В средах с независимо развертываемыми сервисами отказоустойчивость имеет первостепенное значение.
- **Высокая ремонтопригодность**: Сервисы должны быть просты в обслуживании и тестировании, поскольку сервисы, которые невозможно обслуживать, будут переписаны.

### Преимущества

Вот некоторые преимущества архитектуры микросервисов:

- Свободно связанные сервисы.
- Сервисы могут быть развернуты независимо друг от друга.
- Высокая гибкость для нескольких команд разработчиков.
- Повышение отказоустойчивости и изоляции данных.
- Лучшая масштабируемость, поскольку каждый сервис может быть масштабирован независимо.
- Исключается долгосрочная привязка к определенному технологическому стеку.

### Недостатки

Архитектура микросервисов имеет свой собственный набор проблем:

- Сложность распределенной системы.
- Тестирование сложнее.
- Дорогое обслуживание (отдельные серверы, базы данных и т. д.).
- Межсервисное взаимодействие имеет свои сложности.
- Целостность и непротиворечивость данных.
- Перегруженность сети и задержки.

### Лучшие практики

Давайте обсудим некоторые лучшие практики работы с микросервисами:

- Моделируйте сервисы вокруг бизнес-области.
- Сервисы должны иметь свободное соединение и высокую функциональную связность.
- Изолируйте сбои и используйте стратегии отказоустойчивости, чтобы предотвратить каскадное распространение сбоев внутри сервиса.
- Сервисы должны взаимодействовать только через хорошо спроектированные API. Избегайте утечки деталей реализации.
- Хранение данных должно быть приватным для сервиса, которому они принадлежат.
- Избегайте сцепления между сервисами. Причинами сцепления являются общие схемы баз данных и жесткие протоколы взаимодействия.
- Децентрализуйте все. За проектирование и создание сервисов отвечают отдельные команды. Избегайте совместного использования кода или схем данных.
- Отказывайте быстро, используя [автоматический выключатель](https://karanpratapsingh.com/courses/system-design/circuit-breaker) для достижения отказоустойчивости.
- Обеспечьте обратную совместимость изменений API.

### Подводные камни

Ниже перечислены некоторые распространенные подводные камни архитектуры микросервисов:

- Границы сервисов не основаны на бизнес-сфере.
- Недооценка того, насколько сложно построить распределенную систему.
- Общая база данных или общие зависимости между сервисами.
- Отсутствие согласованности с бизнесом.
- Отсутствие четкого владения.
- Отсутствие идемпотентности.
- Попытка сделать все [ACID вместо BASE](https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models).
- Отсутствие проектирования для обеспечения отказоустойчивости может привести к каскадным отказам.

## Остерегайтесь распределенного монолита

Распределенный монолит - это система, напоминающая архитектуру микросервисов, но тесно связанная внутри себя, как монолитное приложение. Принятие архитектуры микросервисов имеет массу преимуществ. Но при создании такой архитектуры велика вероятность того, что в итоге мы получим распределенный монолит.

Наши микросервисы - это просто распределенный монолит, если к ним применимо хотя бы одно из этих условий:

- Требуются коммуникации с низкой задержкой.
- Сервисы нелегко масштабируются.
- Зависимость между сервисами.
- Совместное использование одних и тех же ресурсов, например баз данных.
- Жестко связанные системы.

Одна из основных причин создания приложения с использованием архитектуры микросервисов - это масштабируемость. Поэтому микросервисы должны иметь слабосвязанные сервисы, которые позволяют каждому сервису быть независимым. Распределенная монолитная архитектура лишает нас этой возможности и заставляет большинство компонентов зависеть друг от друга, увеличивая сложность проектирования.

## Микросервисы против сервис-ориентированной архитектуры (SOA)

Вы могли видеть, как _сервис-ориентированная архитектура (SOA)_ упоминается в интернете, иногда даже взаимозаменяемо с микросервисами, но они отличаются друг от друга, и главное различие между этими двумя подходами сводится к _скопу_.

Сервисно-ориентированная архитектура (SOA) определяет способ сделать программные компоненты многократно используемыми с помощью сервисных интерфейсов. Эти интерфейсы используют общие стандарты взаимодействия и нацелены на максимальное повторное использование сервисов приложения, в то время как микросервисы строятся как набор различных мелких независимых сервисных единиц, ориентированных на автономность и разделение команд.

## Почему вам не нужны микросервисы

![architecture-range](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/architecture-range.png)

Итак, вы, возможно, задаетесь вопросом: монолиты кажутся плохой идеей с самого начала, почему кто-то должен их использовать?

Ну, это зависит от ситуации. Хотя у каждого подхода есть свои преимущества и недостатки, при построении новой системы рекомендуется начинать с монолита. Важно понимать, что микросервисы - это не серебряная пуля, вместо этого они решают организационную проблему. Архитектура микросервисов зависит от приоритетов вашей организации и команды в той же степени, что и технология.

Прежде чем принять решение о переходе на архитектуру микросервисов, необходимо задать себе такие вопросы, как:

- "Не слишком ли велика команда для эффективной работы над общей кодовой базой?
- Не блокируются ли команды другими командами?
- "Обеспечивают ли микросервисы явную ценность для бизнеса?"
- Достаточно ли развит мой бизнес для использования микросервисов?
- Не ограничивает ли нас текущая архитектура накладными расходами на коммуникации?

Если ваше приложение не требует разбиения на микросервисы, вам это не нужно. Не существует абсолютной необходимости в том, чтобы все приложения разбивались на микросервисы.

Мы часто черпаем вдохновение в таких компаниях, как Netflix, и их использовании микросервисов, но упускаем из виду, что мы - не Netflix. Они прошли через множество итераций и моделей, прежде чем у них появилось готовое решение для рынка, и эта архитектура стала для них приемлемой, когда они определили и решили проблему, которую пытались решить.

Вот почему важно глубоко понять, действительно ли вашему бизнесу нужны микросервисы. Я пытаюсь сказать, что микросервисы - это решения сложных проблем, и если у вашего бизнеса нет сложных проблем, то они вам не нужны.

# Event-Driven Architecture (EDA)

Архитектура, управляемая событиями (Event-Driven Architecture, EDA), - это использование событий в качестве способа взаимодействия внутри системы. Как правило, используется брокер сообщений для асинхронной публикации и потребления событий. Издатель не знает, кто потребляет событие, а потребители не знают друг о друге. Архитектура, управляемая событиями, - это просто способ достижения свободной связи между сервисами в системе.

## Что такое событие?

Событие - это точка данных, которая представляет собой изменение состояния системы. Оно не определяет, что должно произойти и как это изменение должно изменить систему, оно лишь уведомляет систему о конкретном изменении состояния. Когда пользователь совершает действие, он запускает событие.

## Компоненты

Архитектуры, управляемые событиями, состоят из трех ключевых компонентов:

- **Производители событий**: Публикуют событие в маршрутизатор.
- **Маршрутизаторы событий**: Фильтруют и передают события потребителям.
- **Потребители событий**: Используют события для отражения изменений в системе.

![event-driven-architecture](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-driven-architecture/event-driven-architecture.png)

Примечание: Точки на диаграмме обозначают различные события в системе.

## Паттерны

Существует несколько способов реализации событийно-управляемой архитектуры, и то, какой метод мы используем, зависит от конкретного случая, но вот несколько общих примеров:

- [Sagas](https://karanpratapsingh.com/courses/system-design/distributed-transactions#sagas)
- [Publish-Subscribe](https://karanpratapsingh.com/courses/system-design/publish-subscribe)
- [Event Sourcing](https://karanpratapsingh.com/courses/system-design/event-sourcing)
- [Command and Query Responsibility Segregation (CQRS)](https://karanpratapsingh.com/courses/system-design/command-and-query-responsibility-segregation)

Примечание: каждый из этих методов рассматривается отдельно.

## Преимущества

Давайте обсудим некоторые преимущества:

- Разделенные производители и потребители.
- Высокая масштабируемость и распределенность.
- Легко добавлять новых потребителей.
- Повышает гибкость.

## Проблемы

Вот некоторые проблемы архитектуры event-drive:

- Гарантированная доставка.
- Сложность обработки ошибок.
- Системы, управляемые событиями, в целом сложны.
- Обработка событий в порядке очереди.

## Примеры использования

Ниже приведены некоторые распространенные случаи использования, когда архитектуры, управляемые событиями, оказываются полезными:

- Метаданные и метрики.
- Журналы серверов и систем безопасности.
- Интеграция разнородных систем.
- Веерная и параллельная обработка.

## Примеры

Вот несколько широко используемых технологий для реализации событийно-управляемых архитектур:

- [NATS](https://nats.io)
- [Apache Kafka](https://kafka.apache.org)
- [Amazon EventBridge](https://aws.amazon.com/eventbridge)
- [Amazon SNS](https://aws.amazon.com/sns)
- [Google PubSub](https://cloud.google.com/pubsub)

# Event Sourcing

Вместо того чтобы хранить только текущее состояние данных в домене, используйте хранилище, работающее только с приложениями, для записи всей серии действий, выполняемых над этими данными. Хранилище действует как система записей и может быть использовано для материализации объектов домена.

![event-sourcing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-sourcing/event-sourcing.png)

Это может упростить задачи в сложных доменах, избавив от необходимости синхронизировать модель данных и бизнес-домен, а также повысить производительность, масштабируемость и скорость реагирования. Кроме того, это может обеспечить согласованность транзакционных данных, а также поддерживать полные журналы аудита и историю, что может позволить принять компенсирующие меры.

## Event sourcing vs Event-Driven Architecture (EDA)

Кажется, что ивент-сорсинг постоянно путают с [Event-driven Architecture (EDA)](https://karanpratapsingh.com/courses/system-design/event-driven-architecture). Событийно-управляемая архитектура - это использование событий для связи между границами сервисов. Как правило, используется брокер сообщений для асинхронной публикации и потребления событий в пределах других границ.

В то время как событийная архитектура предполагает использование событий в качестве состояния, что представляет собой другой подход к хранению данных. Вместо того чтобы хранить текущее состояние, мы будем хранить события. Кроме того, сорсинг событий - это один из нескольких паттернов для реализации событийно-ориентированной архитектуры.

## Преимущества

Давайте обсудим некоторые преимущества использования событийного сорсинга:

- Отлично подходит для создания отчетов в реальном времени.
- Отлично подходит для обеспечения отказоустойчивости, данные могут быть восстановлены из хранилища событий.
- Чрезвычайная гибкость, можно хранить сообщения любого типа.
- Предпочтительный способ обеспечения функциональности журналов аудита для систем с высоким уровнем соответствия.

## Недостатки

Ниже перечислены недостатки событийного сорсинга:

- Требуется чрезвычайно эффективная сетевая инфраструктура.
- Требуется надежный способ контроля форматов сообщений, например реестр схем.
- Различные события будут содержать различную полезную нагрузку.

# Command and Query Responsibility Segregation (CQRS)

Разделение ответственности команд и запросов (Command Query Responsibility Segregation, CQRS) - это архитектурный паттерн, который разделяет действия системы на команды и запросы. Впервые он был описан [Greg Young](https://twitter.com/gregyoung).

В CQRS _команда_ - это инструкция, директива для выполнения определенной задачи. Она представляет собой намерение изменить что-то и не возвращает значения, а лишь указывает на успех или неудачу. А _запрос_ - это запрос информации, который не изменяет состояние системы и не вызывает никаких побочных эффектов.

![command-and-query-responsibility-segregation](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/command-and-query-responsibility-segregation/command-and-query-responsibility-segregation.png)

Основной принцип CQRS - разделение команд и запросов. Они выполняют принципиально разные роли в системе, и их разделение означает, что каждая из них может быть оптимизирована по мере необходимости, что очень полезно для распределенных систем.

## CQRS с Event Sourcing

Паттерн CQRS часто используется вместе с паттерном Event Sourcing. Системы на основе CQRS используют отдельные модели данных для чтения и записи, каждая из которых предназначена для выполнения соответствующих задач и часто располагается в физически отдельных хранилищах.

При использовании паттерна Event Sourcing хранилище событий представляет собой модель записи и является официальным источником информации. Модель чтения в системе на основе CQRS обеспечивает материализованные представления данных, обычно в виде сильно денормализованных представлений.

## Преимущества

Давайте обсудим некоторые преимущества CQRS:

- Позволяет независимо масштабировать рабочие нагрузки чтения и записи.
- Более легкое масштабирование, оптимизация и изменение архитектуры.
- Близость к бизнес-логике благодаря свободному соединению.
- Приложение может избежать сложных соединений при запросах.
- Четкие границы между поведением системы.

## Недостатки

Ниже перечислены некоторые недостатки CQRS:

- Более сложный дизайн приложения.
- Возможны сбои в передаче сообщений или дублирование сообщений.
- Решение проблемы конечной согласованности является сложной задачей.
- Увеличение объема работ по обслуживанию системы.

## Сценарии использования

Вот несколько сценариев, в которых CQRS будет полезен:

- Производительность чтения данных должна настраиваться отдельно от производительности записи данных.
- Предполагается, что система будет развиваться с течением времени и может содержать несколько версий модели, или в ней регулярно меняются бизнес-правила.
- Интеграция с другими системами, особенно в сочетании с событийными источниками, когда временный отказ одной подсистемы не должен влиять на доступность других.
- Повышение безопасности, чтобы гарантировать, что только правильные доменные сущности выполняют запись в данные.

# API Gateway

Шлюз API - это инструмент управления API, который находится между клиентом и набором внутренних сервисов. Это единая точка входа в систему, которая инкапсулирует внутреннюю архитектуру системы и предоставляет API, адаптированный для каждого клиента. На него также возлагаются другие обязанности, такие как аутентификация, мониторинг, балансировка нагрузки, кэширование, дросселирование, ведение логов и т. д.

![api-gateway](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/api-gateway.png)

## Зачем нам нужен API-шлюз?

Гранулярность API, предоставляемых микросервисами, часто отличается от того, что нужно клиенту. Микросервисы обычно предоставляют мелкозернистые API, что означает, что клиентам необходимо взаимодействовать с несколькими сервисами. Поэтому API-шлюз может обеспечить единую точку входа для всех клиентов с некоторыми дополнительными возможностями и лучшим управлением.

## Особенности

Ниже перечислены некоторые необходимые функции API-шлюза:

- Аутентификация и авторизация
- [Обнаружение услуг](https://karanpratapsingh.com/courses/system-design/service-discovery)
- [Обратный прокси](https://karanpratapsingh.com/courses/system-design/proxy#reverse-proxy)
- [Кэширование](https://karanpratapsingh.com/courses/system-design/caching)
- Безопасность
- Повторные попытки и [Разрыв цепи](https://karanpratapsingh.com/courses/system-design/circuit-breaker)
- [Балансировка нагрузки](https://karanpratapsingh.com/courses/system-design/load-balancing)
- Протоколирование, трассировка
- Состав API
- [Ограничение скорости](https://karanpratapsingh.com/courses/system-design/rate-limiting) и дросселирование
- Версионирование
- Маршрутизация
- Белые или черные списки IP-адресов

## Преимущества

Давайте рассмотрим некоторые преимущества использования API-шлюза:

- Инкапсулирует внутреннюю структуру API.
- Обеспечивает централизованное представление API.
- Упрощает клиентский код.
- Мониторинг, аналитика, трассировка и другие подобные функции.

## Недостатки

Вот некоторые возможные недостатки API-шлюза:

- Возможность возникновения единой точки отказа.
- Может повлиять на производительность.
- Может стать узким местом при неправильном масштабировании.
- Конфигурация может быть сложной.

## Паттерн Backend For Frontend (BFF)

В паттерне Backend For Frontend (BFF) мы создаем отдельные сервисы бэкенда, которые будут потребляться определенными приложениями или интерфейсами фронтенда. Этот паттерн полезен, когда мы хотим избежать настройки одного бэкенда для нескольких интерфейсов. Впервые этот паттерн был описан [Sam Newman](https://samnewman.io).

Кроме того, иногда данные, возвращаемые микросервисами на фронтенд, не имеют того формата или не фильтруются так, как нужно фронтенду. Чтобы решить эту проблему, фронтенд должен иметь некоторую логику для переформатирования данных, и поэтому мы можем использовать BFF для переноса части этой логики на промежуточный слой.

![backend-for-frontend](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/backend-for-frontend.png)

Основная функция бэкенда для шаблона фронтенда - получить необходимые данные из соответствующего сервиса, отформатировать их и отправить на фронтенд.

В качестве бэкенда для фронтенда (BFF) очень хорошо работает _[GraphQL](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#graphql).

### Когда использовать этот паттерн?

Мы должны рассмотреть возможность использования паттерна Backend For Frontend (BFF), когда:

- Необходимо поддерживать общий или универсальный бэкенд-службу со значительными накладными расходами на разработку.
- Мы хотим оптимизировать бэкенд под требования конкретного клиента.
- В бэкенд общего назначения вносятся изменения, чтобы обеспечить работу с несколькими интерфейсами.

## Примеры

Ниже приведены некоторые широко используемые технологии шлюзов:

- [Amazon API Gateway](https://aws.amazon.com/api-gateway)
- [Apigee API Gateway](https://cloud.google.com/apigee)
- [Azure API Gateway](https://azure.microsoft.com/en-in/services/api-management)
- [Kong API Gateway](https://konghq.com/kong)

# REST, GraphQL, gRPC

Хороший дизайн API всегда является важной частью любой системы. Но также важно выбрать правильную технологию API. Поэтому в этом руководстве мы кратко рассмотрим различные технологии API, такие как REST, GraphQL и gRPC.

## Что такое API?

Прежде чем перейти к технологиям API, давайте сначала разберемся, что такое API.

API расшифровывается как интерфейс прикладного программирования. Это набор определений и протоколов для создания и интеграции прикладного программного обеспечения. Иногда его называют контрактом между поставщиком и пользователем информации, в котором указывается содержание, требуемое производителем, и содержание, требуемое потребителем.

Другими словами, если вы хотите взаимодействовать с компьютером или системой для получения информации или выполнения какой-либо функции, API поможет вам передать системе то, что вы хотите, чтобы она могла понять и выполнить запрос.

## REST

API [REST](https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm) (также известный как RESTful API) - это интерфейс прикладного программирования, который соответствует ограничениям архитектурного стиля REST и позволяет взаимодействовать с RESTful веб-сервисами. REST расшифровывается как Representational State Transfer и впервые был представлен [Roy Fielding](https://roy.gbiv.com) в 2000 году.

_В REST API основной единицей является ресурс._

### Концепции

Давайте обсудим некоторые концепции RESTful API.

**Ограничения**.

Для того чтобы API считался _RESTful_, он должен соответствовать следующим архитектурным ограничениям:

- **Единый интерфейс**: Должен существовать единый способ взаимодействия с определенным сервером.
- **Клиент-сервер**: Клиент-серверная архитектура, управляемая через HTTP.
- **Stateless**: Контекст клиента не должен храниться на сервере между запросами.
- **Cacheable**: Каждый ответ должен содержать информацию о том, является ли ответ кэшируемым или нет, и в течение какого времени ответы могут быть кэшированы на стороне клиента.
- **Слоистая система**: Архитектура приложения должна состоять из нескольких уровней.
- **Код по требованию**: Возвращение исполняемого кода для поддержки части вашего приложения. (необязательно)_

**Глаголы HTTP**.

HTTP определяет набор методов запроса для указания желаемого действия, которое должно быть выполнено для данного ресурса. Хотя они могут быть и существительными, эти методы запроса иногда называют _HTTP-главами_. Каждый из них реализует свою семантику, но некоторые общие черты разделяет группа этих методов.

Ниже приведены некоторые часто используемые глаголы HTTP:

- **GET**: Запрос представления указанного ресурса.
- **HEAD**: Ответ идентичен запросу `GET`, но без тела ответа.
- **POST**: Отправляет сущность на указанный ресурс, часто вызывая изменение состояния или побочные эффекты на сервере.
- **PUT**: Заменяет все текущие представления целевого ресурса на полезную нагрузку запроса.
- **DELETE**: Удаляет указанный ресурс.
- **PATCH**: Применяет частичные модификации к ресурсу.

**Коды ответов HTTP**

[Коды статуса ответа HTTP] (https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) указывают, был ли успешно выполнен определенный HTTP-запрос.

В стандарте определено пять классов:

- 1xx - информационные ответы.
- 2xx - успешные ответы.
- 3xx - ответы о перенаправлении.
- 4xx - ответы об ошибках клиента.
- 5xx - ответы об ошибках сервера.

Например, HTTP 200 означает, что запрос был выполнен успешно.

### Преимущества

Давайте обсудим некоторые преимущества REST API:

- Простой и понятный.
- Гибкость и портативность.
- Хорошая поддержка кэширования.
- Клиент и сервер разделены.

### Недостатки

Давайте обсудим некоторые недостатки REST API:

- Избыточная выборка данных.
- Иногда требуется несколько обращений к серверу.

### Примеры использования

REST API используются практически повсеместно и являются стандартом по умолчанию для разработки API. В целом REST API довольно гибкие и подходят практически для всех сценариев.

### Пример

Вот пример использования REST API, который работает с ресурсом **users**.

| URI | HTTP-глагол | Описание |
| ------------- | --------- | ------------------- |
| /users | GET | Получить всех пользователей |
| /users/\{id\} | GET | Получить пользователя по id |
| /users | POST | Добавить нового пользователя |
| /users/\{id\} | PATCH | Обновить пользователя по id |
| /users/\{id\} | DELETE | Удалить пользователя по id |

Я настоятельно рекомендую изучить [Hypermedia as the Engine of Application State (HATEOAS)](https://en.wikipedia.org/wiki/HATEOAS)._Так много еще предстоит узнать, когда речь идет о REST API.

## GraphQL

[GraphQL](https://graphql.org) - это язык запросов и серверная среда выполнения для API, приоритетом которой является предоставление клиентам именно тех данных, которые они запрашивают, и не более. Он был разработан [Facebook](https://engineering.fb.com) и позже, в 2015 году, стал открытым.

GraphQL призван сделать API быстрыми, гибкими и удобными для разработчиков. Кроме того, GraphQL дает разработчикам API возможность добавлять или упразднять поля, не влияя на существующие запросы. Разработчики могут создавать API с любыми методами, которые они предпочитают, а спецификация GraphQL обеспечит их предсказуемое функционирование для клиентов.

_В GraphQL основной единицей является запрос._

### Концепции

Давайте кратко обсудим некоторые ключевые понятия в GraphQL:

**Схема**.

Схема GraphQL описывает функциональность, которую клиенты могут использовать после подключения к серверу GraphQL.

**Запросы**.

Запрос - это запрос, сделанный клиентом. Он может состоять из полей и аргументов для запроса. Тип операции запроса также может быть [мутацией](https://graphql.org/learn/queries/#mutations), которая предоставляет возможность модифицировать данные на стороне сервера.

**Резольверы**.

Резольвер - это набор функций, которые генерируют ответы на GraphQL-запрос. Проще говоря, резолвер выступает в роли обработчика запросов GraphQL.

### Преимущества

Давайте обсудим некоторые преимущества GraphQL:

- Устранение избыточной выборки данных.
- Сильно определенная схема.
- Поддержка генерации кода.
- Оптимизация полезной нагрузки.

### Недостатки

Давайте обсудим некоторые недостатки GraphQL:

- Перенос сложности на сторону сервера.
- Кэширование становится затруднительным.
- Версионность неоднозначна.
- Проблема N+1.

### Примеры использования

GraphQL оказывается незаменимым в следующих сценариях:

- Сокращение пропускной способности приложения, так как мы можем запрашивать несколько ресурсов одним запросом.
- Быстрое создание прототипов для сложных систем.
- Когда мы работаем с графоподобной моделью данных.

### Пример

Вот схема GraphQL, определяющая тип `User` и тип `Query`.

```graphql
type Query {
  getUser: User
}

type User {
  id: ID
  name: String
  city: String
  state: String
}
```

Используя приведенную выше схему, клиент может легко запросить необходимые поля без необходимости получать весь ресурс или гадать, что может вернуть API.

```graphql
{
  getUser {
    id
    name
    city
  }
}
```

В результате клиент получит следующий ответ:

```json
{
  "getUser": {
    "id": 123,
    "name": "Karan",
    "city": "San Francisco"
  }
}
```

_Узнайте больше о GraphQL на [graphql.org](https://graphql.org)._

## gRPC

[gRPC](https://grpc.io) - это современный высокопроизводительный фреймворк с открытым исходным кодом [Remote Procedure Call (RPC)](https://en.wikipedia.org/wiki/Remote_procedure_call), который может работать в любой среде. Он может эффективно соединять сервисы в центрах обработки данных и между ними благодаря подключаемой поддержке балансировки нагрузки, трассировки, проверки работоспособности, аутентификации и многого другого.

### Концепции

Давайте обсудим некоторые ключевые понятия gRPC.

**Буферы протоколов**.

Буферы протоколов представляют собой нейтральный для языка и платформы расширяемый механизм для сериализации структурированных данных, совместимый как с прямыми, так и с обратными данными. Это похоже на JSON, только меньше и быстрее, и генерирует привязки к родным языкам.

**Определение сервиса**.

Как и многие другие системы RPC, gRPC основан на идее определения сервиса и указания методов, которые могут быть вызваны удаленно, с их параметрами и возвращаемыми типами. gRPC использует буферы протоколов в качестве [Interface Definition Language (IDL)](https://en.wikipedia.org/wiki/Interface_description_language) для описания как интерфейса сервиса, так и структуры сообщений полезной нагрузки.

### Преимущества

Давайте обсудим некоторые преимущества gRPC:

- Легкость и эффективность.
- Высокая производительность.
- Встроенная поддержка генерации кода.
- Двунаправленная потоковая передача.

### Недостатки

Давайте обсудим некоторые недостатки gRPC:

- Относительно новый по сравнению с REST и GraphQL.
- Ограниченная поддержка браузеров.
- Более сложная кривая обучения.
- Не читается человеком.

### Примеры использования

Ниже перечислены примеры использования gRPC:

- Общение в реальном времени с помощью двунаправленной потоковой передачи.
- Эффективное межсервисное взаимодействие в микросервисах.
- Коммуникация с низкой задержкой и высокой пропускной способностью.
- Полиглотские среды.

### Пример

Вот базовый пример сервиса gRPC, определенного в файле `*.proto`. Используя это определение, мы можем легко сгенерировать код сервиса `HelloService` на выбранном нами языке программирования.

```protobuf
service HelloService {
  rpc SayHello (HelloRequest) returns (HelloResponse);
}

message HelloRequest {
  string greeting = 1;
}

message HelloResponse {
  string reply = 1;
}
```

## REST vs GraphQL vs gRPC

Теперь, когда мы знаем, как работают эти техники проектирования API, давайте сравним их по следующим параметрам:

- Приведет ли это к тесному взаимодействию?
- Насколько _разговорчивы_ (отдельные вызовы API для получения необходимой информации) API?
- Какова производительность?
- Насколько сложна интеграция?
- Насколько хорошо работает кэширование?
- Встроенный инструментарий и генерация кода?
- Какова открываемость API?
- Насколько легко версифицировать API?

| Type | Coupling | Chattiness | Performance | Complexity | Caching | Codegen | Discoverability | Versioning |
| ------- | -------- | ---------- | ----------- | ---------- | ------- | ------- | --------------- | ---------- |
| REST | Низкий | Высокий | Хороший | Средний | Отличный | Плохой | Хороший | Легкий |
| GraphQL | Средний | Низкий | Хороший | Высокий | Пользовательский | Хороший | Хороший | Пользовательский |
| gRPC | Высокий | Средний | Большой | Низкий | Пользовательский | Большой | Плохой | Тяжелый |

### Какая технология API лучше?

Ответ - ни одна из них. Серебряной пули не существует, поскольку у каждой из этих технологий есть свои преимущества и недостатки. Пользователей волнует только последовательное использование наших API, поэтому при разработке API ориентируйтесь на свой домен и требования.

# Длинные опросы, WebSockets, события, отправляемые сервером (SSE)

Изначально веб-приложения разрабатывались по модели клиент-сервер, где веб-клиент всегда является инициатором транзакций, таких как запрос данных с сервера. Таким образом, не существовало механизма, позволяющего серверу самостоятельно отправлять данные клиенту без предварительного запроса со стороны клиента. Давайте обсудим некоторые подходы к решению этой проблемы.

## Длинный опрос

Длинный опрос HTTP - это техника, используемая для передачи клиенту информации с сервера как можно быстрее. В результате серверу не нужно ждать, пока клиент отправит запрос.

При длинном опросе сервер не закрывает соединение после получения запроса от клиента. Вместо этого сервер отвечает только в том случае, если доступно новое сообщение или достигнут порог таймаута.

![long-polling](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/long-polling.png)

Как только клиент получает ответ, он тут же отправляет новый запрос на сервер, чтобы получить новое ожидающее соединение для отправки данных клиенту, и операция повторяется. При таком подходе сервер эмулирует функцию push в реальном времени.

### Устройство

Давайте разберемся, как работает длинный опрос:

1. Клиент делает первоначальный запрос и ждет ответа.
2. Сервер получает запрос и откладывает отправку до тех пор, пока не появится обновление.
3. Как только обновление доступно, ответ отправляется клиенту.
4. Клиент получает ответ и сразу же или через определенный промежуток времени делает новый запрос, чтобы снова установить соединение.

### Преимущества

Вот некоторые преимущества длинного опроса:

- Простота реализации, подходит для небольших проектов.
- Почти повсеместная поддержка.

### Недостатки

Основной недостаток длинного опроса в том, что он обычно не масштабируется. Ниже перечислены некоторые другие причины:

- Каждый раз создается новое соединение, что может быть интенсивным для сервера.
- Надежность упорядочивания сообщений может стать проблемой при многократных запросах.
- Увеличение задержки, поскольку серверу приходится ждать нового запроса.

## WebSockets

WebSocket обеспечивает полнодуплексные каналы связи через одно TCP-соединение. Это постоянное соединение между клиентом и сервером, которое обе стороны могут использовать для отправки данных в любое время.

Клиент устанавливает соединение WebSocket с помощью процесса, известного как WebSocket handshake. Если процесс проходит успешно, то сервер и клиент могут обмениваться данными в обоих направлениях в любое время. Протокол WebSocket обеспечивает связь между клиентом и сервером с меньшими накладными расходами, облегчая передачу данных с сервера и на сервер в режиме реального времени.

![websockets](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/websockets.png)

Это стало возможным благодаря стандартизированному способу отправки сервером содержимого клиенту без запроса и возможности передачи сообщений туда и обратно при сохранении соединения открытым.

### Устройство

Давайте разберемся, как работают WebSockets:

1. Клиент инициирует процесс рукопожатия WebSocket, отправляя запрос.
2. Запрос также содержит заголовок [HTTP Upgrade](https://en.wikipedia.org/wiki/HTTP/1.1_Upgrade_header), который позволяет переключиться на протокол WebSocket (`ws://`).
3. Сервер отправляет ответ клиенту, подтверждая запрос WebSocket handshake.
4. Соединение WebSocket будет открыто, как только клиент получит успешный ответ на рукопожатие.
5. Теперь клиент и сервер могут начать отправлять данные в обоих направлениях, обеспечивая связь в реальном времени.
6. Соединение будет закрыто, как только сервер или клиент решит закрыть соединение.

### Преимущества

Ниже перечислены некоторые преимущества WebSockets:

- Полнодуплексный асинхронный обмен сообщениями.
- Лучшая модель безопасности на основе происхождения.
- Легкий вес как для клиента, так и для сервера.

### Недостатки

Давайте обсудим некоторые недостатки WebSockets:

- Прерванные соединения не восстанавливаются автоматически.
- Старые браузеры не поддерживают WebSockets (становится менее актуальным).

## События, отправляемые сервером (SSE)

Server-Sent Events (SSE) - это способ установления долгосрочной связи между клиентом и сервером, который позволяет серверу проактивно передавать данные клиенту.

![server-sent-events](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/server-sent-events.png)

Он является однонаправленным, то есть после отправки запроса клиент может только получать ответы, не имея возможности отправлять новые запросы по тому же соединению.

### Устройство

Давайте разберемся, как работают события, отправляемые сервером:

1. Клиент делает запрос к серверу.
2. Устанавливается соединение между клиентом и сервером, которое остается открытым.
3. Сервер отправляет ответы или события клиенту, когда появляются новые данные.

### Преимущества

- Простота реализации и использования как для клиента, так и для сервера.
- Поддерживается большинством браузеров.
- Нет проблем с брандмауэрами.

### Недостатки

- Однонаправленная природа может быть ограничивающей.
- Ограничение на максимальное количество открытых соединений.
- Не поддерживает двоичные данные.

# Geohashing and Quadtrees

# # Geohashing

Geohashing - это метод [геокодирования](https://en.wikipedia.org/wiki/Address_geocoding), используемый для кодирования географических координат, таких как широта и долгота, в короткие буквенно-цифровые строки. Он был создан [Gustavo Niemeyer](https://twitter.com/gniemeyer) в 2008 году.

Например, Сан-Франциско с координатами `37.7564, -122.4016` может быть представлен в геохеше как `9q8yy9mf`.

### Как работает геохеширование?

Geohash - это иерархический пространственный индекс, использующий кодировку алфавита Base-32. Первый символ в geohash идентифицирует начальное местоположение как одну из 32 ячеек. Эта ячейка также будет содержать 32 ячейки. Это означает, что для представления точки мир рекурсивно делится на все меньшие и меньшие ячейки с каждым дополнительным битом, пока не будет достигнута требуемая точность. Коэффициент точности также определяет размер ячейки.

![geohashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png)

Геохэширование гарантирует, что точки будут пространственно ближе, если их геохэши имеют более длинный префикс, то есть чем больше символов в строке, тем точнее местоположение. Например, геохэши `9q8yy9mf` и `9q8yy9vx` пространственно ближе, так как имеют общий префикс `9q8yy9`.

Геохеширование также может использоваться для обеспечения некоторой степени анонимности, поскольку нам не нужно раскрывать точное местоположение пользователя, так как в зависимости от длины геохеша мы просто знаем, что он находится в определенном районе.

Размеры ячеек геохэшей разной длины следующие:

| Длина Geohash | Ширина ячейки | Высота ячейки |
| -------------- | ---------- | ----------- |
| 1 | 5000 км | 5000 км |
| 2 | 1250 км | 1250 км |
| 3 | 156 км | 156 км |
| 4 | 39,1 км | 19,5 км |
| 5 | 4,89 км | 4,89 км |
6 | | 1,22 км | 0,61 км |
| 7 | 153 м | 153 м |
| 8 | 38,2 м | 19,1 м |
| 9 | 4,77 м | 4,77 м |
| 10 | 1,19 м | 0,596 м |
| 11 | 149 мм | 149 мм |
| 12 | 37,2 мм | 18,6 мм |

### Примеры использования

Вот несколько распространенных вариантов использования Geohashing:

- Это простой способ представления и хранения местоположения в базе данных.
- Им также можно делиться в социальных сетях в виде URL, поскольку им легче поделиться и запомнить, чем широту и долготу.
- Мы можем эффективно находить ближайших соседей точки с помощью очень простых сравнений строк и эффективного поиска по индексам.

### Примеры

Геохашинг широко используется и поддерживается популярными базами данных.

- [MySQL](https://www.mysql.com)
- [Redis](http://redis.io)
- [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
- [Google Cloud Firestore](https://cloud.google.com/firestore)

## Quadtrees.

Квадтри - это древовидная структура данных, в которой каждый внутренний узел имеет ровно четыре дочерних. Они часто используются для разбиения двумерного пространства путем рекурсивного деления его на четыре квадранта или области. Каждый дочерний или листовой узел хранит пространственную информацию. Квадтри - это двумерный аналог [Octrees](https://en.wikipedia.org/wiki/Octree), который используется для разбиения трехмерного пространства.

![quadtree](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png)

### Типы Quadtrees.

Квадродеревья можно классифицировать по типу данных, которые они представляют, включая области, точки, линии и кривые. Ниже перечислены распространенные типы квадтреков:

- Точечные квадтрики
- Квадтрики "точка-область" (PR)
- Квадтрики полигональной карты (PM)
- Сжатые квадтрики
- Краевые квадтрики

### Зачем нам нужны квадтрики?

Разве широты и долготы не достаточно? Зачем нам нужны квадтрики? Хотя теоретически, используя широту и долготу, мы можем определить, насколько близки точки друг к другу, используя [евклидово расстояние](https://en.wikipedia.org/wiki/Euclidean_distance), для практического использования этот метод просто не подходит, поскольку он требует больших затрат процессора при работе с большими наборами данных.

![quadtree-subdivision](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png)

Квадродеревья позволяют эффективно искать точки в двумерном диапазоне, где эти точки определены как координаты широты/долготы или как декартовы координаты (x, y). Кроме того, мы можем сэкономить на вычислениях, разбивая узел только после определенного порога. А применение алгоритмов отображения, таких как [кривая Гильберта] (https://en.wikipedia.org/wiki/Hilbert_curve), позволяет легко повысить производительность запросов к диапазонам.

### Примеры использования

Ниже перечислены некоторые распространенные случаи использования квадтри:

- Представление, обработка и сжатие изображений.
- Пространственное индексирование и запросы к диапазонам.
- Сервисы, основанные на местоположении, такие как Google Maps, Uber и т. д.
- Генерация сетки и компьютерная графика.
- Хранение разреженных данных.

# Автоматический выключатель (Circuit breaker)

Автоматический выключатель - это шаблон проектирования, используемый для обнаружения сбоев и заключающий в себе логику предотвращения постоянного повторения сбоя во время технического обслуживания, временного внешнего сбоя системы или неожиданных трудностей в работе системы.

![circuit-breaker](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/circuit-breaker/circuit-breaker.png)

Основная идея, лежащая в основе автоматического выключателя, очень проста. Мы оборачиваем вызов защищенной функции в объект автоматического выключателя, который отслеживает сбои. Как только количество отказов достигает определенного порога, выключатель срабатывает, и все дальнейшие обращения к нему возвращаются с ошибкой, при этом защищенный вызов вообще не выполняется. Как правило, при срабатывании автоматического выключателя нам также требуется какое-то оповещение монитора.

## Зачем нам нужен разрыв цепи?

Обычно программные системы выполняют удаленные вызовы программ, запущенных в разных процессах, возможно, на разных машинах в сети. Одно из главных различий между вызовами в памяти и удаленными вызовами заключается в том, что удаленные вызовы могут не работать или висеть без ответа до тех пор, пока не будет достигнут некоторый предел таймаута. Что еще хуже, так это то, что если у нас много абонентов на не отвечающем поставщике, то мы можем исчерпать критические ресурсы, что приведет к каскадным сбоям в нескольких системах.

## Состояния

Давайте обсудим состояния автоматического выключателя:

### Замкнуто

Когда все нормально, автоматические выключатели остаются закрытыми, и все запросы проходят через службы в обычном режиме. Если количество отказов превышает пороговое значение, автоматический выключатель срабатывает и переходит в открытое состояние.

### Open

В этом состоянии автоматический выключатель сразу же возвращает ошибку, даже не обращаясь к службам. Автоматические выключатели переходят в полуоткрытое состояние по истечении определенного времени ожидания. Как правило, в системе мониторинга указывается время ожидания.

### Полуоткрытое состояние

В этом состоянии автоматический выключатель пропускает через себя ограниченное количество запросов от службы и вызывает операцию. Если запросы будут успешными, то выключатель перейдет в закрытое состояние. Однако если запросы продолжают терпеть неудачу, то он возвращается в открытое состояние.

# Ограничение скорости

Ограничение скорости - это предотвращение превышения частоты операций над заданным пределом. В крупномасштабных системах ограничение скорости обычно используется для защиты базовых служб и ресурсов. Ограничение скорости обычно используется в качестве защитного механизма в распределенных системах, чтобы общие ресурсы могли поддерживать доступность. Оно также защищает наши API от непреднамеренного или злонамеренного чрезмерного использования, ограничивая количество запросов, которые могут поступить к нашему API за определенный период времени.

![rate-limiting](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/rate-limiting/rate-limiting.png)

## Зачем нам нужно ограничение скорости?

Ограничение скорости - очень важная часть любой крупномасштабной системы, и оно может быть использовано для достижения следующих целей:

- Избежать голодания ресурсов в результате атак типа "отказ в обслуживании" (DoS).
- Ограничение скорости помогает контролировать эксплуатационные расходы, устанавливая виртуальный лимит на автоматическое масштабирование ресурсов, которое, если за ним не следить, может привести к экспоненциальным счетам.
- Ограничение скорости может использоваться в качестве защиты или смягчения последствий некоторых распространенных атак.
- Для API, обрабатывающих огромные объемы данных, ограничение скорости может быть использовано для контроля потока этих данных.

## Алгоритмы

Существуют различные алгоритмы ограничения скорости API, каждый из которых имеет свои преимущества и недостатки. Давайте вкратце обсудим некоторые из этих алгоритмов:

### Leaky Bucket

Leaky Bucket - это алгоритм, который обеспечивает простой и интуитивно понятный подход к ограничению скорости с помощью очереди. При регистрации запроса система добавляет его в конец очереди. Обработка первого элемента в очереди происходит с регулярным интервалом или по принципу "первый пришел - первый ушел" (FIFO). Если очередь переполнена, то дополнительные запросы отбрасываются (или просачиваются).

### Token Bucket

Здесь мы используем концепцию _ведра_. Когда поступает запрос, токен из ведра должен быть взят и обработан. Если в ведре нет токена, запрос будет отклонен, и запросчику придется повторить попытку позже. В результате ведро токенов обновляется через определенный промежуток времени.

### Фиксированное окно

Система использует окно размером в `n` секунд для отслеживания скорости работы алгоритма с фиксированным окном. Каждый входящий запрос увеличивает счетчик для этого окна. Система отбрасывает запрос, если счетчик превышает пороговое значение.

### Скользящий журнал

Ограничение скорости по скользящему журналу включает в себя отслеживание журнала с временной меткой для каждого запроса. Система хранит эти журналы в хэш-наборе или таблице с временной сортировкой. Она также отбрасывает журналы с временными метками, превышающими пороговое значение. Когда поступает новый запрос, мы подсчитываем сумму журналов, чтобы определить частоту запросов. Если запрос превышает пороговое значение, то он задерживается.

### Скользящее окно

Sliding Window - это гибридный подход, который сочетает в себе низкую стоимость обработки алгоритма фиксированного окна и улучшенные граничные условия скользящего журнала. Как и в алгоритме фиксированного окна, мы отслеживаем счетчик для каждого фиксированного окна. Затем мы учитываем взвешенное значение частоты запросов предыдущего окна, основанное на текущей временной метке, чтобы сгладить всплески трафика.

## Ограничение скорости в распределенных системах

Ограничение скорости усложняется, когда речь идет о распределенных системах. Две основные проблемы, возникающие при ограничении скорости в распределенных системах, таковы:

### Несоответствия

При использовании кластера из нескольких узлов нам может потребоваться глобальная политика ограничения скорости. Поскольку если каждый узел будет отслеживать свой лимит скорости, потребитель может превысить глобальный лимит скорости при отправке запросов на разные узлы. Чем больше узлов, тем больше вероятность того, что пользователь превысит глобальный лимит.

Самый простой способ решить эту проблему - использовать липкие сессии в наших балансировщиках нагрузки, чтобы каждый потребитель отправлялся ровно на один узел, но это приводит к недостаточной отказоустойчивости и проблемам масштабирования. Другим подходом может быть использование централизованного хранилища данных, например [Redis](https://redis.io), но это приведет к увеличению задержек и возникновению условий гонки.

### Условия гонки

Эта проблема возникает, когда мы используем наивный подход _"get-then-set"_, при котором мы получаем текущий счетчик ограничения скорости, инкрементируем его, а затем отправляем обратно в хранилище данных. Проблема этой модели заключается в том, что за время, необходимое для выполнения полного цикла чтения-инкремента-магазина, могут прийти дополнительные запросы, каждый из которых попытается сохранить счетчик инкремента с недопустимым (меньшим) значением счетчика. Это позволяет потребителю отправить очень большое количество запросов, чтобы обойти контроль ограничения скорости.

Один из способов избежать этой проблемы - использовать некий механизм распределенной блокировки вокруг ключа, не позволяющий другим процессам обращаться к счетчику или записывать в него данные. Однако блокировка станет значительным узким местом и будет плохо масштабироваться. Лучшим подходом может быть использование подхода _"set-then-get"_, позволяющего нам быстро увеличивать и проверять значения счетчиков, не позволяя атомарным операциям мешать.

# Обнаружение сервисов

Обнаружение сервисов - это обнаружение сервисов в компьютерной сети. Service Discovery Protocol (SDP) - это сетевой стандарт, который обеспечивает обнаружение сетей путем идентификации ресурсов.


## Зачем нам нужно обнаружение сервисов?

В монолитном приложении сервисы вызывают друг друга с помощью методов на уровне языка или вызовов процедур. Однако современные приложения, основанные на микросервисах, обычно работают в виртуализированных или контейнерных средах, где количество экземпляров сервисов и их местоположение динамически меняются. Следовательно, нам нужен механизм, позволяющий клиентам сервиса делать запросы к динамически меняющемуся набору эфемерных экземпляров сервиса.

## Реализации

Существует два основных шаблона обнаружения сервисов:

### Обнаружение на стороне клиента

![client-side-service-discovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/client-side-service-discovery.png)

При таком подходе клиент получает местоположение другой службы, обращаясь к реестру служб, который отвечает за управление и хранение сетевых местоположений всех служб.

### Обнаружение на стороне сервера

![server-side-service-discovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/server-side-service-discovery.png)

В этом подходе мы используем промежуточный компонент, такой как балансировщик нагрузки. Клиент делает запрос к сервису через балансировщик нагрузки, который затем направляет запрос к доступному экземпляру сервиса.

## Реестр сервисов

Реестр сервисов - это, по сути, база данных, содержащая сетевые расположения экземпляров сервисов, к которым могут обращаться клиенты. Реестр сервисов должен быть высокодоступным и актуальным.

## Регистрация сервисов

Нам также нужен способ получения информации о сервисе, часто называемый регистрацией сервиса. Давайте рассмотрим два возможных подхода к регистрации сервисов:

### Саморегистрация (Self-Registration)

При использовании модели саморегистрации экземпляр службы отвечает за регистрацию и снятие с регистрации в реестре служб. Кроме того, если необходимо, экземпляр сервиса отправляет запросы heartbeat, чтобы поддерживать свою регистрацию в актуальном состоянии.

### Регистрация третьих лиц (Third-party Registration)

Реестр отслеживает изменения в запущенных экземплярах, опрашивая среду развертывания или подписываясь на события. Когда он обнаруживает новый доступный экземпляр службы, он записывает его в свою базу данных. Реестр служб также снимает с регистрации завершенные экземпляры служб.

## Сервисная сетка (Service mesh)

Связь между сервисами необходима в распределенных приложениях, но маршрутизация этой связи как внутри, так и между кластерами приложений становится все более сложной по мере роста числа сервисов. Service mesh обеспечивает управляемую, наблюдаемую и безопасную связь между отдельными сервисами. Для обнаружения сервисов она работает с протоколом обнаружения сервисов. [Istio](https://istio.io/latest/about/service-mesh) и [envoy](https://www.envoyproxy.io) - одни из наиболее часто используемых технологий сервисной сетки.

## Примеры

Вот некоторые часто используемые инструменты инфраструктуры обнаружения сервисов:

- [etcd](https://etcd.io)
- [Consul](https://www.consul.io)
- [Apache Thrift](https://thrift.apache.org)
- [Apache Zookeeper](https://zookeeper.apache.org)

# SLA, SLO, SLI

Давайте вкратце обсудим SLA, SLO и SLI. Они в основном относятся к бизнесу и надежности сайта, но, тем не менее, их полезно знать.

## Почему они важны?

SLA, SLO и SLI позволяют компаниям определять, отслеживать и контролировать обещания, данные пользователям в отношении услуг. В совокупности SLA, SLO и SLI должны помочь командам повысить доверие пользователей к своим услугам, а также сделать акцент на постоянном совершенствовании процессов управления и реагирования на инциденты.

## SLA

SLA, или соглашение об уровне обслуживания, - это соглашение, заключенное между компанией и пользователями определенного сервиса. SLA определяет различные обещания, которые компания дает пользователям в отношении конкретных показателей, таких как доступность сервиса.

_SLA часто пишут бизнесмены или юристы компании._

## SLO

SLO (Service Level Objective) - это обещание, которое компания дает пользователям в отношении конкретного показателя, такого как реакция на инцидент или время безотказной работы. SLO существуют в SLA как отдельные обещания, содержащиеся в полном пользовательском соглашении. SLO - это конкретная цель, которую должна достичь служба, чтобы соответствовать SLA. SLO всегда должны быть простыми, четко определенными и легко измеряемыми, чтобы определить, выполняется ли цель.

## SLI

SLI, или индикатор уровня сервиса, - это ключевая метрика, используемая для определения того, выполняется ли SLO. Это измеренное значение метрики, описанной в SLO. Для того чтобы оставаться в соответствии с SLA, значение SLI должно всегда соответствовать или превышать значение, определенное SLO.

# Восстановление после катастроф

Аварийное восстановление (DR) - это процесс восстановления доступа и функциональности инфраструктуры после таких событий, как стихийные бедствия, кибератаки или даже сбои в работе.

Аварийное восстановление основано на репликации данных и компьютерной обработки в удаленном месте, не затронутом катастрофой. Когда серверы выходят из строя из-за стихийного бедствия, предприятию необходимо восстановить потерянные данные из второго места, где хранятся резервные копии данных. В идеале организация может перенести свою компьютерную обработку и в это удаленное место, чтобы продолжить работу.

Восстановление после катастроф часто не обсуждается на собеседованиях при проектировании системы, но важно иметь базовое представление об этой теме. Подробнее о восстановлении после катастроф вы можете узнать из [AWS Well-Architected Framework](https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html)._

## Почему аварийное восстановление важно?

Аварийное восстановление может иметь следующие преимущества:

- Минимизация перерывов и простоев
- Ограничение ущерба
- Быстрое восстановление
- Лучшее удержание клиентов

## Термины

Давайте обсудим некоторые важные термины, имеющие отношение к аварийному восстановлению:

![disaster-recovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/disaster-recovery/disaster-recovery.png)

### RTO

Время восстановления (Recovery Time Objective, RTO) - это максимально допустимая задержка между прерыванием обслуживания и его восстановлением. Это определяет, что считается приемлемым промежутком времени, когда сервис недоступен.

### RPO

Цель точки восстановления (RPO) - это максимально допустимый промежуток времени с момента последней точки восстановления данных. Это определяет, что считается приемлемой потерей данных между последней точкой восстановления и прерыванием обслуживания.

## Стратегии

В план аварийного восстановления (DR) могут входить различные стратегии.

### Резервное копирование

Это самый простой тип аварийного восстановления, предполагающий хранение данных за пределами предприятия или на съемном диске.

### Холодный сайт

При этом типе аварийного восстановления организация создает базовую инфраструктуру на второй площадке.

### Горячий сайт

На "горячем" сайте постоянно поддерживаются актуальные копии данных. Создание "горячих" сайтов занимает много времени и обходится дороже, чем "холодных", но они значительно сокращают время простоя.

# Виртуальные машины (ВМ) и контейнеры

Прежде чем обсуждать виртуализацию и контейнеризацию, давайте узнаем, что такое виртуальные машины (ВМ) и контейнеры.

## Виртуальные машины (ВМ)

Виртуальная машина (ВМ) - это виртуальная среда, которая функционирует как виртуальная компьютерная система с собственным процессором, памятью, сетевым интерфейсом и хранилищем, созданная на физической аппаратной системе. Программное обеспечение, называемое гипервизором, отделяет ресурсы машины от аппаратного обеспечения и соответствующим образом распределяет их, чтобы они могли использоваться ВМ.

ВМ изолированы от остальной системы, и несколько ВМ могут существовать на одном аппаратном обеспечении, например на сервере. Их можно перемещать между хост-серверами в зависимости от потребностей или для более эффективного использования ресурсов.

### Что такое гипервизор?

Гипервизор, иногда называемый монитором виртуальных машин (VMM), изолирует операционную систему и ресурсы от виртуальных машин и позволяет создавать и управлять этими виртуальными машинами. Гипервизор рассматривает такие ресурсы, как процессор, память и хранилище, как пул ресурсов, которые можно легко перераспределять между существующими гостями или новыми виртуальными машинами.

### Зачем использовать виртуальную машину?

Консолидация серверов - главная причина использования виртуальных машин. Большинство операционных систем и приложений используют лишь небольшое количество доступных физических ресурсов. Благодаря виртуализации серверов мы можем разместить множество виртуальных серверов на каждом физическом сервере, чтобы повысить эффективность использования оборудования. Это избавляет нас от необходимости приобретать дополнительные физические ресурсы.

В виртуальной машине создается среда, изолированная от остальной системы, поэтому все, что выполняется внутри виртуальной машины, не будет мешать работе всего остального оборудования хоста. Поскольку ВМ изолированы, они являются хорошим вариантом для тестирования новых приложений или настройки производственной среды. Мы также можем запустить одноцелевую ВМ для поддержки конкретного случая использования.

## Контейнеры

Контейнер - это стандартная единица программного обеспечения, которая упаковывает код и все его зависимости, такие как конкретные версии времени выполнения и библиотек, чтобы приложение быстро и надежно запускалось из одной вычислительной среды в другую. Контейнеры представляют собой логический механизм упаковки, в котором приложения могут быть абстрагированы от среды, в которой они фактически выполняются. Такое разделение позволяет легко и последовательно развертывать приложения на основе контейнеров, независимо от целевой среды.

### Зачем нам нужны контейнеры?

Давайте обсудим некоторые преимущества использования контейнеров:

**Разделение ответственности**.

Контейнеризация обеспечивает четкое разделение ответственности, поскольку разработчики сосредоточены на логике приложения и зависимостях, а операционные команды могут сосредоточиться на развертывании и управлении.

**Переносимость рабочей нагрузки**.

Контейнеры могут работать практически в любом месте, что значительно облегчает разработку и развертывание.

**Изоляция приложений**.

Контейнеры виртуализируют ресурсы процессора, памяти, хранилища и сети на уровне операционной системы, предоставляя разработчикам представление об ОС, логически изолированное от других приложений.

**Агильная разработка**

Контейнеры позволяют разработчикам двигаться гораздо быстрее, избавляя их от забот о зависимостях и окружении.

**Эффективные операции**.

Контейнеры легковесны и позволяют использовать только те вычислительные ресурсы, которые нам нужны.

## Виртуализация против контейнеризации

![virtualization-vs-containerization](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/virtual-machines-and-containers/virtualization-vs-containerization.png)

При традиционной виртуализации гипервизор виртуализирует физическое оборудование. В результате каждая виртуальная машина содержит гостевую ОС, виртуальную копию аппаратного обеспечения, которое требуется ОС для работы, а также приложение и связанные с ним библиотеки и зависимости.

Вместо виртуализации базового оборудования контейнеры виртуализируют операционную систему, поэтому каждый контейнер содержит только приложение и его зависимости, что делает их гораздо более легковесными, чем виртуальные машины. Контейнеры также разделяют ядро ОС и используют лишь часть памяти, которая требуется виртуальным машинам.

# OAuth 2.0 и OpenID Connect (OIDC)

## OAuth 2.0

OAuth 2.0, что расшифровывается как Open Authorization, - это стандарт, разработанный для предоставления согласованного доступа к ресурсам от имени пользователя, без передачи его учетных данных. OAuth 2.0 - это протокол авторизации, а не аутентификации, он разработан в первую очередь как средство предоставления доступа к набору ресурсов, например, удаленным API или данным пользователя.

### Концепции

Протокол OAuth 2.0 определяет следующие сущности:

- **Владелец ресурса**: Пользователь или система, которая владеет защищенными ресурсами и может предоставлять к ним доступ.
- **Клиент**: Клиент - это система, которой требуется доступ к защищенным ресурсам.
- **Сервер авторизации**: Этот сервер получает от клиента запросы на токены доступа и выдает их после успешной аутентификации и согласия владельца ресурса.
- **Сервер ресурсов**: Сервер, который защищает ресурсы пользователя и получает запросы на доступ от клиента. Он принимает и проверяет токен доступа от клиента и возвращает соответствующие ресурсы.
- **Сферы**: Используются для указания причины, по которой может быть предоставлен доступ к ресурсам. Приемлемые значения диапазонов и то, к каким ресурсам они относятся, зависят от сервера ресурсов.
- **Токен доступа**: Часть данных, которая представляет собой разрешение на доступ к ресурсам от имени конечного пользователя.

### Как работает OAuth 2.0?

Давайте узнаем, как работает OAuth 2.0:

![oauth2](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/oauth2-and-openid-connect/oauth2.png)

1. Клиент запрашивает авторизацию у сервера авторизации, предоставляя идентификатор и секрет клиента в качестве идентификатора. Он также указывает область действия и URI конечной точки для отправки токена доступа или кода авторизации.
2. Сервер авторизации проверяет подлинность клиента и убеждается, что запрошенные области разрешены.
3. Владелец ресурса взаимодействует с сервером авторизации для предоставления доступа.
4. Сервер авторизации перенаправляет клиенту код авторизации или токен доступа, в зависимости от типа разрешения. Также может быть возвращен токен обновления.
5. Получив токен доступа, клиент может запросить доступ к ресурсу у сервера ресурсов.

### Недостатки

Вот наиболее распространенные недостатки OAuth 2.0:

- Отсутствие встроенных средств безопасности.
- Нет стандартной реализации.
- Нет общего набора диапазонов.

## OpenID Connect

OAuth 2.0 предназначен только для _авторизации_, для предоставления доступа к данным и функциям от одного приложения к другому. OpenID Connect (OIDC) - это тонкий слой, который располагается поверх OAuth 2.0 и добавляет информацию о логине и профиле человека, который вошел в систему.

Когда сервер авторизации поддерживает OIDC, его иногда называют провайдером идентификации (IdP), поскольку он предоставляет информацию о владельце ресурса обратно клиенту. OpenID Connect появился относительно недавно, что привело к меньшему распространению и внедрению лучших практик по сравнению с OAuth.

### Концепции

Протокол OpenID Connect (OIDC) определяет следующие сущности:

- **Relying Party**: Текущее приложение.
- **OpenID Provider**: По сути, это промежуточная служба, которая предоставляет одноразовый код доверяющей стороне.
- **Token Endpoint**: Веб-сервер, принимающий одноразовый код (OTC) и предоставляющий код доступа, действительный в течение часа. Основное различие между OIDC и OAuth 2.0 заключается в том, что токен предоставляется с помощью JSON Web Token (JWT).
- **UserInfo Endpoint**: Реализующая сторона взаимодействует с этой конечной точкой, предоставляя защищенный токен и получая информацию о конечном пользователе.

Оба протокола - OAuth 2.0 и OIDC - просты в реализации и основаны на JSON, что поддерживается большинством веб- и мобильных приложений. Однако спецификация OpenID Connect (OIDC) более строгая, чем спецификация базового OAuth.

# Single Sign-On (SSO)

Single Sign-On (SSO) - это процесс аутентификации, при котором пользователю предоставляется доступ к нескольким приложениям или веб-сайтам с использованием только одного набора учетных данных. Это избавляет пользователя от необходимости отдельно входить в различные приложения.

Учетные данные пользователя и другая идентифицирующая информация хранятся и управляются централизованной системой, называемой Identity Provider (IdP). Провайдер идентификации - это доверенная система, которая обеспечивает доступ к другим веб-сайтам и приложениям.

Системы аутентификации на основе единого входа (SSO) обычно используются в корпоративных средах, где сотрудникам требуется доступ к нескольким приложениям своей организации.

## Компоненты

Давайте обсудим некоторые ключевые компоненты системы единого входа (SSO).

### Провайдер идентификации (IdP)

Информация о личности пользователя хранится и управляется централизованной системой, называемой Identity Provider (IdP). Провайдер идентификации аутентифицирует пользователя и предоставляет доступ к поставщику услуг.

Провайдер идентификации может непосредственно аутентифицировать пользователя, проверяя имя пользователя и пароль, или подтверждать утверждение об идентичности пользователя, представленное отдельным провайдером идентификации. Поставщик идентификации занимается управлением идентификационными данными пользователей, чтобы освободить поставщика услуг от этой обязанности.

### Поставщик услуг

Поставщик услуг предоставляет услуги конечному пользователю. Они полагаются на поставщиков идентификации для подтверждения личности пользователя, и обычно определенные атрибуты пользователя управляются поставщиком идентификации. Поставщики услуг могут также поддерживать локальную учетную запись пользователя вместе с атрибутами, уникальными для их услуг.

### Брокер идентификации

Брокер идентификации выступает в качестве посредника, который соединяет несколько поставщиков услуг с различными поставщиками идентификационных данных. Используя Identity Broker, мы можем выполнять единую регистрацию в любом приложении, не задумываясь о том, по какому протоколу оно работает.

## SAML

Security Assertion Markup Language - это открытый стандарт, позволяющий клиентам обмениваться информацией об идентификации, аутентификации и разрешениях в различных системах. SAML реализован с помощью стандарта Extensible Markup Language (XML) для обмена данными.

SAML обеспечивает федерацию идентификационных данных, позволяя поставщикам идентификационных данных (IdP) беспрепятственно и безопасно передавать аутентифицированные идентификационные данные и их атрибуты поставщикам услуг.

## Как работает SSO?

Теперь давайте обсудим, как работает Single Sign-On:

![sso](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/single-sign-on/sso.png)

1. Пользователь запрашивает ресурс у нужного ему приложения.
2. Приложение перенаправляет пользователя к провайдеру идентификации (IdP) для аутентификации.
3. Пользователь входит в систему, используя свои учетные данные (обычно имя пользователя и пароль).
4. Провайдер идентификации (IdP) отправляет ответ Single Sign-On обратно клиентскому приложению.
5. Приложение предоставляет пользователю доступ.

## SAML против OAuth 2.0 и OpenID Connect (OIDC)

Между SAML, OAuth и OIDC существует множество различий. SAML использует XML для передачи сообщений, в то время как OAuth и OIDC используют JSON. OAuth обеспечивает более простой опыт, в то время как SAML ориентирован на корпоративную безопасность.

OAuth и OIDC широко используют RESTful-коммуникации, поэтому мобильные и современные веб-приложения считают OAuth и OIDC более удобными для пользователей. SAML, с другой стороны, оставляет в браузере сессионный cookie, который позволяет пользователю получить доступ к определенным веб-страницам. Это отлично подходит для кратковременных рабочих нагрузок.

OIDC удобен для разработчиков и более прост в реализации, что расширяет возможности его применения. Его можно довольно быстро реализовать с нуля с помощью свободно распространяемых библиотек на всех распространенных языках программирования. SAML может быть сложным в установке и обслуживании, с чем хорошо справляются только компании корпоративного уровня.

OpenID Connect - это, по сути, слой поверх фреймворка OAuth. Поэтому он может предложить встроенный уровень разрешения, который просит пользователя согласиться с тем, что поставщик услуг может получить доступ. Хотя SAML также способен обеспечить поток разрешений, он достигает этого путем жесткого кодирования, выполняемого разработчиком, а не как часть своего протокола.

_Оба этих протокола аутентификации хороши в том, что они делают. Как всегда, многое зависит от конкретного случая использования и целевой аудитории._

## Преимущества

Ниже перечислены преимущества использования единого входа:

- Простота использования, поскольку пользователям нужно помнить только один набор учетных данных.
- Простота доступа без необходимости проходить длительный процесс авторизации.
- Обеспечение безопасности и соответствия нормативным требованиям для защиты конфиденциальных данных.
- Упрощение управления за счет снижения затрат на ИТ-поддержку и времени администраторов.

## Недостатки

Вот некоторые недостатки Single Sign-On:

- Уязвимость единого пароля: если основной пароль SSO будет скомпрометирован, то под угрозой окажутся все поддерживаемые приложения.
- Процесс аутентификации с помощью Single Sign-On медленнее, чем при традиционной аутентификации, поскольку каждое приложение должно запросить у провайдера SSO верификацию.

## Примеры

Вот некоторые часто используемые провайдеры идентификации (IdP):

- [Okta](https://www.okta.com)
- [Google](https://cloud.google.com/architecture/identity/single-sign-on)
- [Auth0](https://auth0.com)
- [OneLogin](https://www.onelogin.com)


# SSL, TLS, mTLS

Давайте вкратце обсудим некоторые важные протоколы безопасности связи, такие как SSL, TLS и mTLS. Я бы сказал, что с точки зрения _"общей картины"_ проектирования системы эта тема не очень важна, но знать о ней все же полезно.

## SSL

SSL расшифровывается как Secure Sockets Layer и представляет собой протокол для шифрования и защиты коммуникаций, которые происходят в Интернете. Впервые он был разработан в 1995 году, но с тех пор был устаревшим в пользу TLS (Transport Layer Security).

### Почему сертификат называется SSL, если он устарел?

Большинство крупных поставщиков сертификатов по-прежнему называют их SSL-сертификатами, поэтому такое название сохраняется.

### Почему SSL так важен?

Первоначально данные в Интернете передавались в виде открытого текста, который мог прочесть любой, кто перехватит сообщение. SSL был создан для решения этой проблемы и защиты конфиденциальности пользователей. Шифруя все данные, которые передаются между пользователем и веб-сервером, SSL также предотвращает некоторые виды кибератак, не позволяя злоумышленникам подделывать данные во время их передачи.

## TLS

Transport Layer Security, или TLS, - это широко распространенный протокол безопасности, предназначенный для обеспечения конфиденциальности и защиты данных при обмене через Интернет. TLS развился из предыдущего протокола шифрования под названием Secure Sockets Layer (SSL). Основное применение TLS - шифрование связи между веб-приложениями и серверами.

Протокол TLS состоит из трех основных компонентов:

- **Шифрование**: скрывает передаваемые данные от третьих лиц.
- **Аутентификация**: гарантирует, что стороны, обменивающиеся информацией, являются теми, за кого себя выдают.
- **Целостность**: проверка того, что данные не были подделаны или фальсифицированы.

## mTLS

Взаимный TLS, или mTLS, - это метод взаимной аутентификации. mTLS гарантирует, что стороны на каждом конце сетевого соединения являются теми, за кого себя выдают, проверяя, что у них обоих есть правильный закрытый ключ. Дополнительную проверку обеспечивает информация, содержащаяся в соответствующих сертификатах TLS.

### Зачем использовать mTLS?

mTLS помогает обеспечить безопасность и доверие к трафику в обоих направлениях между клиентом и сервером. Это обеспечивает дополнительный уровень безопасности для пользователей, которые входят в сеть или приложения организации. Он также проверяет соединения с клиентскими устройствами, которые не проходят процедуру входа в систему, например устройствами Интернета вещей (IoT).

В настоящее время mTLS обычно используется микросервисами или распределенными системами в [zero trust security model](https://en.wikipedia.org/wiki/Zero_trust_security_model) для проверки друг друга.

# Собеседования по системному дизайну

Проектирование систем - это очень обширная тема, и собеседования по проектированию систем предназначены для оценки вашей способности создавать технические решения абстрактных проблем, поэтому они не рассчитаны на конкретный ответ. Уникальным аспектом собеседований по проектированию систем является двусторонняя связь между кандидатом и интервьюером.

Ожидания на разных инженерных уровнях также сильно отличаются. Это связано с тем, что человек с большим практическим опытом будет подходить к собеседованию совсем иначе, чем новичок в этой отрасли. В результате трудно выработать единую стратегию, которая помогла бы нам оставаться организованными во время собеседования.

Давайте рассмотрим некоторые общие стратегии для собеседований по разработке систем:

## Уточнение требований

Вопросы на собеседовании по разработке системы по своей природе являются расплывчатыми или абстрактными. Задавать вопросы о точном масштабе проблемы и уточнять функциональные требования на ранних этапах собеседования очень важно. Обычно требования делятся на три части:

### Функциональные требования

Это требования, которые конечный пользователь выдвигает в качестве основных функциональных возможностей, которые должна предоставлять система. Все эти функциональные возможности должны быть обязательно включены в систему в рамках контракта.

Например:

- "Какие функции нам нужно разработать для этой системы?".
- "Какие крайние случаи мы должны учесть при проектировании, если таковые имеются?"

### Нефункциональные требования

Это ограничения качества, которым должна удовлетворять система в соответствии с проектным контрактом. Приоритет или степень реализации этих факторов варьируется от проекта к проекту. Их также называют не-поведенческими требованиями. Например, переносимость, ремонтопригодность, надежность, масштабируемость, безопасность и т. д.

Например:

- "Каждый запрос должен обрабатываться с минимальной задержкой".
- "Система должна быть высокодоступной".

### Расширенные требования

В основном это "приятные" требования, которые могут выходить за рамки системы.

Например:

- "Наша система должна записывать метрики и аналитику".
- "Мониторинг состояния и производительности сервиса?"

## Оценка и ограничения

Оцените масштаб системы, которую мы собираемся проектировать. Важно задавать такие вопросы, как:

- "Каков желаемый масштаб, с которым должна справляться эта система?"
- "Каково соотношение чтения и записи в нашей системе?"
- "Сколько запросов в секунду?"
- "Какой объем памяти потребуется?"

Эти вопросы помогут нам масштабировать наш дизайн в дальнейшем.

## Разработка модели данных

Получив оценки, мы можем приступить к определению схемы базы данных. Это необходимо сделать на ранних этапах интервью, чтобы понять поток данных, который является основой любой системы. На этом этапе мы определяем все сущности и отношения между ними.

- "Что представляют собой различные сущности в системе?"
- "Какие отношения существуют между этими сущностями?"
- "Сколько таблиц нам нужно?"
- "Является ли NoSQL лучшим выбором в данном случае?"

## Разработка API

Далее мы можем приступить к разработке API для системы. Эти API помогут нам определить ожидания от системы в явном виде. Нам не нужно писать никакого кода, достаточно простого интерфейса, определяющего требования к API, такие как параметры, функции, классы, типы, сущности и т. д.

Например:

```tsx
createUser(name: string, email: string): User
```

Рекомендуется максимально упростить интерфейс и вернуться к нему позже, когда будут рассмотрены расширенные требования.

## Высокоуровневый дизайн компонентов

Теперь, когда мы определились с моделью данных и дизайном API, пришло время определить компоненты системы (такие как балансировщики нагрузки, шлюзы API и т. д.), необходимые для решения нашей задачи, и набросать первый проект нашей системы.

- "Что лучше - монолитная или микросервисная архитектура?"
- "Какой тип базы данных мы должны использовать?"

Когда у нас есть базовая схема, мы можем начать обсуждать с интервьюером, как система будет работать с точки зрения клиента.

## Детальное проектирование

Теперь пришло время подробно рассказать об основных компонентах системы, которую мы спроектировали. Как обычно, обсудите с интервьюером, какие компоненты могут нуждаться в дальнейших улучшениях.

Это хорошая возможность продемонстрировать свой опыт в тех областях, в которых вы разбираетесь. Представьте различные подходы, преимущества и недостатки. Объясните свои проектные решения и подкрепите их примерами. Это также хорошее время для обсуждения дополнительных возможностей, которые может поддерживать система, хотя это необязательно.

- "Как мы должны разделить наши данные?"
- "Как насчет распределения нагрузки?"
- "Нужно ли использовать кэш?"
- "Как мы справимся с внезапным всплеском трафика?"

Также постарайтесь не быть слишком категоричным в отношении определенных технологий, заявления типа "Я считаю, что базы данных NoSQL просто лучше, а базы данных SQL не масштабируемы" отражают плохую репутацию. Как человек, который за годы работы провел множество собеседований, скажу, что нужно быть скромным в том, что вы знаете и чего не знаете. Используйте свои знания и примеры, чтобы пройти эту часть собеседования.

## Выявление и устранение узких мест

Наконец, пришло время обсудить узкие места и подходы к их устранению. Вот несколько важных вопросов, которые следует задать:

- "Достаточно ли у нас реплик базы данных?"
- "Есть ли единая точка отказа?"
- "Требуется ли шардинг базы данных?"
- "Как мы можем сделать нашу систему более надежной?"
- "Как повысить доступность нашего кэша?".

Обязательно читайте инженерный блог компании, в которую вы идете на собеседование. Это поможет вам понять, какой стек технологий они используют и какие проблемы для них важны.

# URL Shortener

Давайте разработаем сокращатель URL-адресов, подобный таким сервисам, как [Bitly](https://bitly.com), [TinyURL](https://tinyurl.com/app).

## Что такое сокращатель URL?

Сервис сокращатель URL создает псевдоним или короткий URL для длинного URL. При переходе по этим коротким ссылкам пользователи перенаправляются на оригинальный URL.

Например, следующий длинный URL-адрес может быть заменен на более короткий.

**Длинный URL**: [https://karanpratapsingh.com/courses/system-design/url-shortener](https://karanpratapsingh.com/courses/system-design/url-shortener)

**Короткий URL**: [https://bit.ly/3I71d3o](https://bit.ly/3I71d3o)

## Зачем нам нужен сокращатель URL?

Сокращатель URL позволяет экономить место при обмене URL-адресами. Пользователи также реже ошибаются при вводе коротких URL. Кроме того, мы можем оптимизировать ссылки на разных устройствах, что позволяет нам отслеживать отдельные ссылки.

## Требования

Наша система сокращения URL должна отвечать следующим требованиям:

### Функциональные требования

- При задании URL-адреса наш сервис должен генерировать для него _короткий и уникальный_ псевдоним.
- При переходе по короткой ссылке пользователи должны перенаправляться на оригинальный URL.
- Срок действия ссылок должен истекать через заданный по умолчанию промежуток времени.

### Нефункциональные требования

- Высокая доступность при минимальных задержках.
- Система должна быть масштабируемой и эффективной.

### Расширенные требования

- Предотвращение злоупотребления услугами.
- Запись аналитики и метрик для перенаправлений.

## Оценка и ограничения

Давайте начнем с оценки и ограничений.

_Примечание: Обязательно уточните у интервьюера любые предположения, связанные с масштабом или трафиком._

### Трафик

Это будет система с большим объемом чтения, поэтому предположим соотношение чтения и записи `100:1` и 100 миллионов генерируемых ссылок в месяц.

**Чтения/Записи в месяц**.

Для чтения в месяц:

$$
100 \times 100 \space million = 10 \space billion/month
$$

Аналогично и с записью:
$$
1 \times 100 \space million = 100 \space million/month
$$

**Какова будет скорость обработки запросов в секунду (RPS) для нашей системы?**

100 миллионов запросов в месяц - это 40 запросов в секунду.

$$
\frac{100 \space million}{(30 \space days \times 24 \space hrs \times 3600 \space seconds)} = \sim 40 \space URLs/second
$$

А при соотношении чтения и записи `100:1` количество перенаправлений будет:

$$
100 \times 40 \space URLs/second = 4000 \space requests/second
$$

### Пропускная способность

Поскольку мы ожидаем около 40 URL каждую секунду, и если мы предположим, что каждый запрос имеет размер 500 байт, то общее количество входящих данных для запросов на запись будет составлять:

$$
40 \times 500 \space bytes = 20 \space KB/second
$$

Аналогично, для запросов на чтение, поскольку мы ожидаем около 4K перенаправлений, общее количество исходящих данных будет составлять:

$$
4000 \space URLs/second \times 500 \space bytes = \sim 2 \space MB/second
$$

### Хранение

Для хранения данных мы предположим, что каждая ссылка или запись будет храниться в нашей базе данных в течение 10 лет. Поскольку мы ожидаем около 100 миллионов новых запросов каждый месяц, общее количество записей, которые нам нужно будет хранить, составит:

$$
100 \space million \times 10\space years \times 12 \space months = 12 \space billion
$$

Как и ранее, если мы предположим, что каждая хранимая запись будет иметь размер около 500 байт. Нам потребуется около 6 ТБ памяти:

$$
12 \space billion \times 500 \space bytes = 6 \space TB
$$

### Кэш

Для кэширования мы будем следовать классическому [принципу Парето](https://en.wikipedia.org/wiki/Pareto_principle), также известному как правило 80/20. Это означает, что 80% запросов приходится на 20% данных, поэтому мы можем кэшировать около 20% запросов.

Поскольку каждую секунду мы получаем около 4K запросов на чтение или переадресацию, это означает 350M запросов в день.

$$
4000 \space URLs/second \times 24 \space hours \times 3600 \space seconds = \sim 350 \space million \space requests/day
$$

Таким образом, нам потребуется около 35 ГБ памяти в день.

$$
20 \space percent \times 350 \space million \times 500 \space bytes = 35 \space GB/day
$$

### Оценка высокого уровня


| Тип | Смета |
| -------------------- | ---------- |
| Запись (новые URL) | 40/с |
| Чтения (перенаправление) | 4K/s |
| Пропускная способность (входящие)| 20 КБ/с |
| Пропускная способность (исходящая) | 2 МБ/с |
| Хранение (10 лет) | 6 ТБ |
| Память (кэширование)| ~35 ГБ/день |

## Проектирование модели данных

Далее мы сосредоточимся на проектировании модели данных. Вот схема нашей базы данных:

![url-shortener-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-datamodel.png)

Изначально мы можем начать с двух таблиц:

**users**

Хранит данные о пользователях, такие как `имя`, `электронная почта`, `созданАт` и т.д.

**urls**

Содержит свойства нового короткого URL, такие как `expiration`, `hash`, `originalURL` и `userID` пользователя, создавшего короткий URL. Мы также можем использовать столбец `hash` в качестве [индекса](https://karanpratapsingh.com/courses/system-design/indexes) для повышения производительности запросов.

### Какую базу данных мы должны использовать?

Поскольку данные не являются реляционными, лучшим выбором здесь будут NoSQL базы данных, такие как [Amazon DynamoDB](https://aws.amazon.com/dynamodb), [Apache Cassandra](https://cassandra.apache.org/_/index.html) или [MongoDB](https://www.mongodb.com), если мы все же решим использовать SQL базу данных, то мы можем использовать что-то вроде [Azure SQL Database](https://azure.microsoft.com/en-in/products/azure-sql/database) или [Amazon RDS](https://aws.amazon.com/rds).

_Более подробную информацию см. в статье [SQL vs NoSQL](https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases)._

## Дизайн API

Давайте сделаем базовый дизайн API для наших сервисов:

### Создать URL

Этот API должен создавать новый короткий URL в нашей системе при наличии исходного URL.

```tsx
createURL(apiKey: string, originalURL: string, expiration?: Date): string
```

**Параметры**

Ключ API (`строка`): Ключ API, предоставленный пользователем.

Оригинальный URL (`string`): Оригинальный URL, который будет сокращен.

Expiration (`Date`): Дата истечения срока действия нового URL _(необязательно)_.

**Возврат**

Короткий URL (`string`): Новый сокращенный URL

### Получить URL

Этот API должен получить оригинальный URL из заданного короткого URL.

```tsx
getURL(apiKey: string, shortURL: string): string
```

**Параметры**

Ключ API (`строка`): Ключ API, предоставленный пользователем.

Короткий URL (`string`): Короткий URL, сопоставленный с исходным URL.

**Возврат**.

Оригинальный URL (`string`): Исходный URL, который будет получен.

### Удалить URL

Этот API должен удалить заданный короткий URL из нашей системы.

```tsx
deleteURL(apiKey: string, shortURL: string): boolean
```

**Параметры**

Ключ API (`строка`): Ключ API, предоставленный пользователем.

Короткий URL (`string`): Короткий URL-адрес, который нужно удалить.

**Возвраты**

Результат (`boolean`): Указывает, была ли операция успешной или нет.

### Зачем нам нужен ключ API?

Как вы, должно быть, заметили, мы используем API-ключ, чтобы предотвратить злоупотребление нашими услугами. Используя этот API-ключ, мы можем ограничить пользователей определенным количеством запросов в секунду или минуту. Это вполне стандартная практика для API разработчиков, и она должна покрыть наши расширенные требования.

## Высокоуровневый дизайн

Теперь давайте сделаем высокоуровневый дизайн нашей системы.

### Кодировка URL

Основная задача нашей системы - сократить заданный URL, давайте рассмотрим различные подходы:

**Подход Base62**.

В этом подходе мы можем закодировать исходный URL с помощью [Base62](https://en.wikipedia.org/wiki/Base62), который состоит из заглавных букв A-Z, строчных букв a-z и цифр 0-9.

$$
Number \space of \space URLs = 62^N
$$

Где,

`N`: Количество символов в генерируемом URL.

Таким образом, если мы хотим сгенерировать URL длиной 7 символов, мы сгенерируем ~3,5 триллиона различных URL.

$$
\begin{gather*}
62^5 = \sim 916 \space million \space URLs \\
62^6 = \sim 56.8 \space billion \space URLs \\
62^7 = \sim 3.5 \space trillion \space URLs
\end{gather*}
$$

Это самое простое решение, но оно не гарантирует отсутствие дублирования или устойчивость ключей к столкновениям.

**Подход MD5**

Алгоритм [MD5 message-digest algorithm](https://en.wikipedia.org/wiki/MD5) - это широко используемая хэш-функция, создающая 128-битное хэш-значение (или 32 шестнадцатеричные цифры). Мы можем использовать эти 32 шестнадцатеричные цифры для генерации URL длиной 7 символов.

$$
MD5(original\_url) \rightarrow base62encode \rightarrow hash
$$

Однако это создает для нас новую проблему - дублирование и коллизии. Мы можем попытаться повторно вычислить хэш, пока не найдем уникальный, но это приведет к увеличению накладных расходов нашей системы. Лучше искать более масштабируемые подходы.

**Подход со счетчиком**.

В этом подходе мы начнем с одного сервера, который будет вести подсчет сгенерированных ключей. Как только наш сервис получает запрос, он может обратиться к счетчику, который возвращает уникальный номер и увеличивает счетчик. Когда приходит следующий запрос, счетчик снова возвращает уникальный номер, и так продолжается.

$$
Counter(0-3.5 \space trillion) \rightarrow base62encode \rightarrow hash
$$

Проблема такого подхода заключается в том, что он может быстро превратиться в единую точку отказа. А если запустить несколько экземпляров счетчика, то могут возникнуть коллизии, так как это по сути распределенная система.

Чтобы решить эту проблему, мы можем использовать менеджер распределенных систем, например [Zookeeper](https://zookeeper.apache.org), который может обеспечить распределенную синхронизацию. Zookeeper может поддерживать несколько диапазонов для наших серверов.

$$
\begin{align*}
& Range \space 1: \space 1 \rightarrow 1,000,000 \\
& Range \space 2: \space 1,000,001 \rightarrow 2,000,000 \\
& Range \space 3: \space 2,000,001 \rightarrow 3,000,000 \\
& ...
\end{align*}
$$

Когда сервер достигнет своего максимального диапазона, Zookeeper назначит неиспользованный диапазон счетчиков новому серверу. Такой подход позволяет гарантировать отсутствие дубликатов и устойчивость URL к коллизиям. Кроме того, мы можем запустить несколько экземпляров Zookeeper, чтобы устранить единую точку отказа.

### Служба генерации ключей (KGS)

Как мы уже говорили, генерирование уникального ключа в масштабе без дублирования и коллизий может оказаться непростой задачей. Чтобы решить эту проблему, мы можем создать отдельную службу генерации ключей (KGS), которая будет генерировать уникальный ключ заранее и хранить его в отдельной базе данных для последующего использования. Такой подход может упростить нам задачу.

**Как обрабатывать одновременный доступ?

После использования ключа мы можем пометить его в базе данных, чтобы исключить повторное использование, однако, если несколько экземпляров сервера читают данные одновременно, два или более сервера могут попытаться использовать один и тот же ключ.

Самый простой способ решить эту проблему - хранить ключи в двух таблицах. Как только ключ используется, мы перемещаем его в отдельную таблицу с соответствующей блокировкой. Кроме того, для улучшения качества чтения мы можем хранить некоторые ключи в памяти.

**Оценки базы данных KGS**.

Согласно нашим расчетам, мы можем сгенерировать до ~56,8 млрд уникальных ключей длиной 6 символов, что приведет к необходимости хранения 300 ГБ ключей.

$$
6 \space characters \times 56.8 \space billion = \sim 390 \space GB
$$

Хотя 390 ГБ кажется многовато для этого простого случая использования, важно помнить, что это на весь срок службы нашего сервиса, и размер базы данных ключей не будет увеличиваться, как наша основная база данных.

### Кэширование

Теперь поговорим о [кэшировании](https://karanpratapsingh.com/courses/system-design/caching). По нашим оценкам, для кэширования 20% входящих запросов к нашим сервисам нам потребуется около ~35 ГБ памяти в день. Для этого случая мы можем использовать серверы [Redis](https://redis.io) или [Memcached](https://memcached.org) вместе с нашим сервером API.

_Более подробную информацию можно найти в [caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Дизайн

Теперь, когда мы определили некоторые основные компоненты, давайте сделаем первый набросок дизайна нашей системы.

![url-shortener-basic-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-basic-design.png)

Вот как это работает:

**Создание нового URL**.

1. Когда пользователь создает новый URL, наш сервер API запрашивает новый уникальный ключ у службы генерации ключей (KGS).
2. Служба генерации ключей предоставляет уникальный ключ серверу API и помечает его как использованный.
3. Сервер API записывает новую запись URL в базу данных и кэш.
4. Наш сервис возвращает пользователю ответ HTTP 201 (Created).

**Получение доступа к URL**

1. Когда клиент переходит на определенный короткий URL, запрос отправляется на серверы API.
2. Сначала запрос попадает в кэш, и если запись в нем не найдена, то она извлекается из базы данных и выдается HTTP 301 (Redirect) на исходный URL.
3. Если ключ по-прежнему не найден в базе данных, пользователю отправляется ошибка HTTP 404 (Not found).

## Детальный дизайн

Пришло время обсудить более тонкие детали нашего дизайна.

### Разбиение данных

Чтобы масштабировать наши базы данных, нам нужно разделить данные. Горизонтальное разделение (оно же [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) может стать хорошим первым шагом. Мы можем использовать такие схемы разбиения, как:

- Hash-Based Partitioning
- Разбиение на основе списков
- Разбиение на основе диапазонов
- составные разделы

Вышеперечисленные подходы могут привести к неравномерному распределению данных и нагрузки, но мы можем решить эту проблему с помощью [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_Более подробную информацию вы найдете в разделах [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) и [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Очистка базы данных

Это скорее шаг по обслуживанию наших сервисов, который зависит от того, оставим ли мы записи с истекшим сроком действия или удалим их. Если мы решим удалить истекшие записи, мы можем подойти к этому двумя разными способами:

**Активная очистка**.

При активной очистке мы запустим отдельную службу очистки, которая будет периодически удалять просроченные ссылки из нашего хранилища и кэша. Это будет очень легкая служба, похожая на [cron job](https://en.wikipedia.org/wiki/Cron).

**Пассивная очистка**.

При пассивной очистке мы можем удалять запись, когда пользователь пытается получить доступ к просроченной ссылке. Это обеспечит "ленивую" очистку нашей базы данных и кэша.

### Кэш

Теперь давайте поговорим о [кэшировании](https://karanpratapsingh.com/courses/system-design/caching).

**Какую политику вытеснения кэша использовать?**

Как мы уже говорили, мы можем использовать такие решения, как [Redis](https://redis.io) или [Memcached](https://memcached.org), и кэшировать 20 % ежедневного трафика, но какая политика вытеснения кэша лучше всего подойдет для наших нужд?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) может быть хорошей политикой для нашей системы. В этой политике мы отбрасываем в первую очередь наименее недавно использованный ключ.

**Как обрабатывать пропуски кэша?**

Когда происходит пропуск кэша, наши серверы могут напрямую обращаться к базе данных и обновлять кэш новыми записями.

### Метрики и аналитика

Запись аналитики и метрик - одно из наших расширенных требований. Мы можем хранить и обновлять метаданные, такие как страна посетителя, платформа, количество просмотров и т. д., вместе с записью URL в нашей базе данных.

### Безопасность

Для обеспечения безопасности мы можем ввести приватные URL и авторизацию. Отдельная таблица может быть использована для хранения идентификаторов пользователей, имеющих право доступа к определенному URL. Если у пользователя нет соответствующих прав, мы можем вернуть ошибку HTTP 401 (Unauthorized).

Мы также можем использовать [API Gateway](https://karanpratapsingh.com/courses/system-design/api-gateway), поскольку они поддерживают такие возможности, как авторизация, ограничение скорости и балансировка нагрузки.

## Выявление и устранение узких мест

![url-shortener-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-advanced-design.png)

Давайте определим и устраним узкие места, такие как единые точки отказа в нашем проекте:

- "Что, если служба API или служба генерации ключей сломается?"
- "Как мы будем распределять трафик между компонентами?"
- "Как мы можем снизить нагрузку на нашу базу данных?"
- "Что, если база данных ключей, используемая KGS, выйдет из строя?"
- "Как повысить доступность нашего кэша?"

Чтобы сделать нашу систему более устойчивой, мы можем сделать следующее:

- Запустить несколько экземпляров наших серверов и службы генерации ключей.
- Внедрение [балансировщиков нагрузки](https://karanpratapsingh.com/courses/system-design/load-balancing) между клиентами, серверами, базами данных и серверами кэша.
- Использование нескольких реплик на чтение для нашей базы данных, поскольку это система с высокой интенсивностью чтения.
- Резервная реплика для нашей ключевой базы данных на случай ее сбоя.
- Несколько экземпляров и реплик для нашего распределенного кэша.

# WhatsApp

Давайте разработаем сервис обмена мгновенными сообщениями [WhatsApp](https://whatsapp.com), похожий на такие сервисы, как [Facebook Messenger](https://www.messenger.com) и [WeChat](https://www.wechat.com).

## Что такое WhatsApp?

WhatsApp - это чат-приложение, предоставляющее своим пользователям услуги обмена мгновенными сообщениями. Это одно из самых используемых мобильных приложений на планете, объединяющее более 2 миллиардов пользователей в 180 с лишним странах. WhatsApp также доступен в Интернете.

## Требования

Наша система должна отвечать следующим требованиям:

### Функциональные требования

- Должна поддерживать чат один на один.
- Групповые чаты (не более 100 человек).
- Должна поддерживать обмен файлами (изображениями, видео и т. д.).

### Нефункциональные требования

- Высокая доступность при минимальных задержках.
- Система должна быть масштабируемой и эффективной.

### Расширенные требования

- Квитанции об отправке, доставке и прочтении сообщений.
- Отображение времени последнего посещения пользователей.
- Push-уведомления.

## Оценка и ограничения

Давайте начнем с оценки и ограничений.

_Примечание: Обязательно уточните у интервьюера все допущения, связанные с масштабом или трафиком._

### Трафик

Предположим, что у нас 50 миллионов ежедневных активных пользователей (DAU), и в среднем каждый пользователь отправляет не менее 10 сообщений 4 разным людям в день. Это дает нам 2 миллиарда сообщений в день.

$$
50 \пространственных миллионов \times 40 \пространственных сообщений = 2 \пространственных миллиарда в день
$$

Сообщения также могут содержать медиафайлы, такие как изображения, видео или другие файлы. Мы можем предположить, что 5 процентов сообщений - это медиафайлы, которыми делятся пользователи, что дает нам дополнительные 100 миллионов файлов, которые необходимо хранить.

**Что такое количество запросов в секунду (RPS) для нашей системы?

2 миллиарда запросов в день - это 24K запросов в секунду.

$$
\frac{2 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 24K \space requests/second
$$

### Хранилище

Если предположить, что каждое сообщение в среднем составляет 100 байт, то нам потребуется около 200 ГБ хранилища базы данных в день.

$$
2 \space billion \times 100 \space bytes = \sim 200 \space GB/day
$$

Согласно нашим требованиям, мы также знаем, что около 5 % наших ежедневных сообщений (100 миллионов) - это медиафайлы. Если предположить, что каждый файл в среднем занимает 100 КБ, то нам потребуется 10 ТБ хранилища каждый день.

$$
100 \space million \times 100 \space KB = 10 \space TB/day
$$

А за 10 лет нам потребуется около 38 ПБ хранилища.

$$
(10 \space TB + 0.2 \space TB) \times 10 \space years \times 365 \space days = \sim 38 \space PB
$$

### Пропускная способность

Поскольку наша система ежедневно обрабатывает 10,2 ТБ входящих данных, нам потребуется минимальная пропускная способность около 120 МБ в секунду.

$$
\frac{10.2 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 120 \space MB/second
$$

### Оценка высокого уровня

Вот наши оценки высокого уровня:

| Тип | Смета |
| ------------------------- | ---------- |
| Ежедневные активные пользователи (DAU) | 50 миллионов |
| Запросы в секунду (RPS) | 24K/s |
| Хранение (в день)| ~10,2 ТБ |
| Хранение (10 лет)| ~38 ПБ |
| Пропускная способность | ~120 МБ/с |

## Разработка модели данных

Это общая модель данных, которая отражает наши требования.

![whatsapp-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-datamodel.png)

У нас есть следующие таблицы:

**users**

Эта таблица содержит информацию о пользователе, такую как `имя`, `номер телефона` и другие данные.

**messages**

Как следует из названия, в этой таблице хранятся сообщения с такими свойствами, как `тип` (текст, изображение, видео и т.д.), `содержание` и временные метки для доставки сообщений. Сообщение также будет иметь соответствующий `chatID` или `groupID`.

**chats**.

Эта таблица представляет собой приватный чат между двумя пользователями и может содержать несколько сообщений.

**users_chats**

Эта таблица отображает пользователей и чаты, поскольку несколько пользователей могут иметь несколько чатов (связь N:M) и наоборот.

**groups**

Эта таблица представляет группу, состоящую из нескольких пользователей.

**users_groups**

Эта таблица отображает пользователей и группы, поскольку несколько пользователей могут состоять в нескольких группах (связь N:M) и наоборот.

### Какую базу данных мы должны использовать?

Хотя наша модель данных выглядит вполне реляционной, нам не обязательно хранить все в одной базе данных, поскольку это может ограничить масштабируемость и быстро превратиться в узкое место.

Мы разделим данные между различными службами, каждая из которых будет владеть определенной таблицей. Тогда мы можем использовать реляционную базу данных, например [PostgreSQL](https://www.postgresql.org), или распределенную базу данных NoSQL, например [Apache Cassandra](https://cassandra.apache.org/_/index.html), для нашего случая.

## Дизайн API

Давайте сделаем базовый дизайн API для наших сервисов:

### Получить все чаты или группы

Этот API позволяет получить все чаты или группы для заданного `userID`.

```tsx
getAll(userID: UUID): Chat[] | Group[]
```

**Параметры**

User ID (`UUID`): ID текущего пользователя.

**Возврат**.

Результат (`Chat[] | Group[]`): Все чаты и группы, в которых состоит пользователь.

### Получить сообщения

Получение всех сообщений для пользователя, заданного `channelID` (идентификатор чата или группы).

```tsx
getMessages(userID: UUID, channelID: UUID): Message[]
```

**Параметры**

User ID (`UUID`): Идентификатор текущего пользователя.

Channel ID (`UUID`): Идентификатор канала (чата или группы), из которого необходимо извлечь сообщения.

**Возвращается**

Messages (`Message[]`): Все сообщения в данном чате или группе.

### Отправить сообщение

Отправка сообщения от пользователя в канал (чат или группу).

```tsx
sendMessage(userID: UUID, channelID: UUID, message: Message): boolean
```

**Параметры**

User ID (`UUID`): Идентификатор текущего пользователя.

Channel ID (`UUID`): ID канала (чата или группы), на который пользователь хочет отправить сообщение.

Message (`Message`): Сообщение (текст, изображение, видео и т. д.), которое пользователь хочет отправить.

**Возврат**.

Result (`boolean`): Указывает, была ли операция успешной или нет.

### Присоединиться к каналу или покинуть его

Позволяет пользователю присоединиться к каналу (чату или группе) или покинуть его.

```tsx
joinGroup(userID: UUID, channelID: UUID): boolean
leaveGroup(userID: UUID, channelID: UUID): boolean
```

**Параметры**

User ID (`UUID`): Идентификатор текущего пользователя.

Channel ID (`UUID`): ID канала (чата или группы), к которому пользователь хочет присоединиться или покинуть.

**Возврат**

Результат (`boolean`): Указывает, была ли операция успешной или нет.

## Высокоуровневый дизайн

Теперь давайте сделаем высокоуровневый дизайн нашей системы.

### Архитектура

Мы будем использовать [архитектуру микросервисов](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices), так как она облегчает горизонтальное масштабирование и разделение наших сервисов. Каждый сервис будет владеть своей собственной моделью данных. Давайте попробуем разделить нашу систему на несколько основных сервисов.

**Сервис пользователя**

Это служба на основе HTTP, которая обрабатывает вопросы, связанные с пользователями, такие как аутентификация и информация о пользователе.

**Сервис чата**

Служба чата будет использовать WebSockets и устанавливать соединения с клиентом для обработки функций чата и групповых сообщений. Мы также можем использовать кэш для отслеживания всех активных подключений, что-то вроде сессий, что поможет нам определить, находится ли пользователь онлайн или нет.

**Сервис уведомлений**

Этот сервис будет просто отправлять пользователям push-уведомления. Он будет подробно рассмотрен отдельно.

**Служба присутствия**

Служба присутствия будет отслеживать статус _последнего увиденного_ всех пользователей. Подробнее об этом будет рассказано отдельно.

**Медиа-сервис**

Эта служба будет обрабатывать загрузку медиафайлов (изображений, видео, файлов и т. д.). Подробнее об этом будет рассказано отдельно.

**Что касается межсервисного взаимодействия и обнаружения сервисов?**

Поскольку наша архитектура основана на микросервисах, сервисы также будут взаимодействовать друг с другом. Как правило, REST или HTTP работают хорошо, но мы можем еще больше повысить производительность, используя [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc), который является более легким и эффективным.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) - это еще одна вещь, которую мы должны принять во внимание. Мы также можем использовать сетку сервисов, которая обеспечивает управляемую, наблюдаемую и безопасную связь между отдельными сервисами.

_Примечание: Узнайте больше о [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) и их сравнении друг с другом._

### Обмен сообщениями в реальном времени

Как эффективно отправлять и получать сообщения? У нас есть два варианта:

**Модель "тяни-толкай "**.

Клиент может периодически отправлять HTTP-запрос на сервер, чтобы проверить, есть ли новые сообщения. Этого можно добиться с помощью чего-то вроде [Long polling](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling).

**Модель Push**

Клиент открывает долговременное соединение с сервером, и как только появляются новые данные, они передаются клиенту. Для этого можно использовать [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) или [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse).

Подход с использованием модели pull не является масштабируемым, поскольку он создает ненужные накладные расходы на запросы на наших серверах и большую часть времени ответ будет пустым, что приводит к потере наших ресурсов. Для минимизации задержек лучше использовать модель push с [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets), поскольку в этом случае мы можем передавать данные клиенту, как только они становятся доступными, без каких-либо задержек, учитывая, что соединение с клиентом открыто. Кроме того, WebSockets обеспечивают полнодуплексную связь, в отличие от [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse), которые являются только однонаправленными.

_Примечание: Узнайте больше о [длинном опросе, WebSockets, Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events)._

### Last seen

Для реализации функциональности last seen мы можем использовать механизм [heartbeat](<https://en.wikipedia.org/wiki/Heartbeat_(computing)>), в котором клиент может периодически пинговать серверы, указывая на свою активность. Поскольку это должно быть как можно менее накладным, мы можем хранить в кэше временную метку последней активности следующим образом:

| Ключ | Значение |
| ------ | ------------------- |
| Пользователь A | 2022-07-01T14:32:50 |
| Пользователь B | 2022-07-05T05:10:35 |
| Пользователь C | 2022-07-10T04:33:25 |

Это даст нам информацию о том, когда пользователь был активен в последний раз. Эта функциональность будет выполняться сервисом присутствия в сочетании с [Redis](https://redis.io) или [Memcached](https://memcached.org) в качестве кэша.

Другой способ реализовать это - отслеживать последние действия пользователя, как только последняя активность пересечет определенный порог, например _"пользователь не выполнял никаких действий в течение последних 30 секунд"_, мы можем показать пользователя как не в сети и последний раз видеть его с последней записанной временной меткой. Это будет больше похоже на подход "ленивого обновления", и в некоторых случаях мы можем выиграть по сравнению с heartbeat.

### Уведомления

После отправки сообщения в чате или группе мы сначала проверим, активен ли получатель или нет; эту информацию можно получить, приняв во внимание активное соединение пользователя и его последнее посещение.

Если получатель не активен, служба чата добавит событие в [очередь сообщений] (https://karanpratapsingh.com/courses/system-design/message-queues) с дополнительными метаданными, такими как платформа устройства клиента, которые в дальнейшем будут использованы для маршрутизации уведомления на нужную платформу.

Затем служба уведомлений получит событие из очереди сообщений и направит запрос в [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) или [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications) в зависимости от платформы устройства клиента (Android, iOS, web и т. д.). Мы также можем добавить поддержку электронной почты и SMS.

**Почему мы используем очередь сообщений?

Поскольку большинство очередей сообщений обеспечивают наилучшее упорядочивание, что гарантирует доставку сообщений в том же порядке, в каком они были отправлены, и что сообщение будет доставлено хотя бы один раз, что является важной частью функциональности нашего сервиса.

Хотя это кажется классическим вариантом использования [publish-subscribe](https://karanpratapsingh.com/courses/system-design/publish-subscribe), на самом деле это не так, поскольку мобильные устройства и браузеры каждый по-своему обрабатывают push-уведомления. Обычно уведомления обрабатываются извне через Firebase Cloud Messaging (FCM) или Apple Push Notification Service (APNS), в отличие от веерной рассылки сообщений, которую мы обычно видим в бэкенд-сервисах. Для поддержки этой функциональности мы можем использовать что-то вроде [Amazon SQS](https://aws.amazon.com/sqs) или [RabbitMQ](https://www.rabbitmq.com).

### Квитанции на чтение

Обработка квитанций о прочтении может быть непростой задачей, поэтому в данном случае мы можем дождаться какого-нибудь [Acknowledgment (ACK)](<https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)>) от клиента, чтобы определить, было ли сообщение доставлено, и обновить соответствующее поле `deliveredAt`. Аналогично, мы пометим сообщение как увиденное, как только пользователь откроет чат, и обновим соответствующее поле `seenAt`.

### Дизайн

Теперь, когда мы определили некоторые основные компоненты, давайте сделаем первый набросок дизайна нашей системы.

![whatsapp-basic-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-basic-design.png)

## Детальный дизайн

Пришло время обсудить наши проектные решения в деталях.

### Разбиение данных

Чтобы масштабировать наши базы данных, нам нужно разделить данные. Горизонтальное разделение (оно же [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) может стать хорошим первым шагом. Мы можем использовать такие схемы разбиения, как:

- Hash-Based Partitioning
- Разбиение на основе списков
- Разбиение на основе диапазонов
- составные разделы

Вышеперечисленные подходы могут привести к неравномерному распределению данных и нагрузки, но мы можем решить эту проблему с помощью [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_Более подробную информацию вы найдете в разделах [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) и [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Кэширование

В приложении для обмена сообщениями мы должны быть осторожны с использованием кэша, поскольку наши пользователи ожидают самые свежие данные, но многие пользователи будут запрашивать одни и те же сообщения, особенно в групповом чате. Поэтому, чтобы предотвратить скачки использования наших ресурсов, мы можем кэшировать старые сообщения.

Некоторые групповые чаты могут содержать тысячи сообщений, и отправка их по сети будет очень неэффективной, поэтому для повышения эффективности мы можем добавить пагинацию в API нашей системы. Это решение будет полезно для пользователей с ограниченной пропускной способностью сети, так как им не придется получать старые сообщения, если они не запрашиваются.

**Какую политику вытеснения кэша использовать?**

Мы можем использовать такие решения, как [Redis](https://redis.io) или [Memcached](https://memcached.org), и кэшировать 20 % ежедневного трафика, но какая политика вытеснения кэша лучше всего подойдет для наших нужд?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) может быть хорошей политикой для нашей системы. В этой политике мы отбрасываем в первую очередь наименее недавно использованный ключ.

**Как справиться с пропуском кэша?

Когда происходит пропуск кэша, наши серверы могут напрямую обращаться к базе данных и обновлять кэш новыми записями.

Более подробную информацию вы найдете в разделе [Кэширование](https://karanpratapsingh.com/courses/system-design/caching)._

### Доступ к носителям и их хранение

Как мы знаем, большая часть нашего хранилища будет использоваться для хранения медиафайлов, таких как изображения, видео или другие файлы. Наш медиасервис будет управлять доступом и хранением пользовательских медиафайлов.

Но где мы можем хранить файлы в масштабе? Что ж, [объектное хранилище](https://karanpratapsingh.com/courses/system-design/storage#object-storage) - это то, что нам нужно. Объектные хранилища разбивают файлы данных на части, называемые объектами. Затем эти объекты хранятся в едином хранилище, которое может быть распределено по нескольким сетевым системам. Мы также можем использовать распределенные файловые хранилища, такие как [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs) или [GlusterFS](https://www.gluster.org).

_Забавный факт: WhatsApp удаляет медиафайлы на своих серверах после того, как они были загружены пользователем._

Для этого случая мы можем использовать такие объектные хранилища, как [Amazon S3](https://aws.amazon.com/s3), [Azure Blob Storage](https://azure.microsoft.com/en-in/services/storage/blobs) или [Google Cloud Storage](https://cloud.google.com/storage).

### Сеть доставки контента (CDN)

[Сеть доставки контента (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) повышает доступность и избыточность контента, снижая при этом затраты на пропускную способность. Как правило, статические файлы, такие как изображения и видео, обслуживаются из CDN. Для этого случая мы можем использовать такие сервисы, как [Amazon CloudFront](https://aws.amazon.com/cloudfront) или [Cloudflare CDN](https://www.cloudflare.com/cdn).

### API-шлюз

Поскольку мы будем использовать несколько протоколов, таких как HTTP, WebSocket, TCP/IP, развертывание нескольких балансиров нагрузки типа L4 (транспортный уровень) или L7 (прикладной уровень) отдельно для каждого протокола будет дорогостоящим. Вместо этого мы можем использовать [API Gateway](https://karanpratapsingh.com/courses/system-design/api-gateway), который поддерживает несколько протоколов без каких-либо проблем.

API Gateway также может предлагать другие функции, такие как аутентификация, авторизация, ограничение скорости, дросселирование и версионирование API, что повысит качество наших услуг.

Для этого случая мы можем использовать такие сервисы, как [Amazon API Gateway](https://aws.amazon.com/api-gateway) или [Azure API Gateway](https://azure.microsoft.com/en-in/services/api-management).

## Выявление и устранение узких мест

![whatsapp-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-advanced-design.png)

Давайте определим и устраним узкие места, такие как единые точки отказа в нашем дизайне:

- "Что, если один из наших сервисов сломается?"
- "Как мы будем распределять трафик между компонентами?"
- "Как мы можем снизить нагрузку на нашу базу данных?"
- "Как повысить доступность нашего кэша?"
- "Не будет ли API Gateway единой точкой отказа?"
- "Как сделать нашу систему уведомлений более надежной?"
- "Как мы можем сократить расходы на хранение медиафайлов?"
- "Не слишком ли много обязанностей у чат-службы?".

Чтобы сделать нашу систему более устойчивой, мы можем сделать следующее:

- Запустить несколько экземпляров каждой из наших служб.
- Внедрение [балансировщиков нагрузки](https://karanpratapsingh.com/courses/system-design/load-balancing) между клиентами, серверами, базами данных и серверами кэша.
- Использование нескольких реплик чтения для наших баз данных.
- Несколько экземпляров и реплик для нашего распределенного кэша.
- Мы можем иметь резервную копию нашего API-шлюза.
- В распределенной системе доставка и упорядочивание сообщений является сложной задачей, поэтому мы можем использовать специализированный [брокер сообщений](https://karanpratapsingh.com/courses/system-design/message-brokers), такой как [Apache Kafka](https://kafka.apache.org) или [NATS](https://nats.io), чтобы сделать нашу систему уведомлений более надежной.
- Мы можем добавить возможности обработки и сжатия медиафайлов в медиасервис, чтобы сжимать большие файлы подобно WhatsApp, что позволит сэкономить много места для хранения и снизить стоимость.
- Мы можем создать сервис групп отдельно от сервиса чатов, чтобы еще больше разделить наши сервисы.

# Twitter

Давайте разработаем социальный медиасервис [Twitter](https://twitter.com), похожий на такие сервисы, как [Facebook](https://facebook.com), [Instagram](https://instagram.com) и т.д.

## Что такое Twitter?

Twitter - это социальный медиасервис, где пользователи могут читать или публиковать короткие сообщения (до 280 символов), называемые твитами. Он доступен в Интернете и на мобильных платформах, таких как Android и iOS.

## Требования

Наша система должна отвечать следующим требованиям:

### Функциональные требования

- Должна быть возможность публиковать новые твиты (это может быть текст, изображение, видео и т. д.).
- Должна быть возможность следовать за другими пользователями.
- Должна быть лента новостей, состоящая из твитов людей, за которыми следит пользователь.
- Должна быть возможность поиска по твитам.

### Нефункциональные требования

- Высокая доступность при минимальной задержке.
- Система должна быть масштабируемой и эффективной.

### Расширенные требования

- Метрика и аналитика.
- Функциональность ретвитов.
- Любимые твиты.

## Оценка и ограничения

Давайте начнем с оценки и ограничений.

_Примечание: Обязательно уточните у интервьюера любые допущения, связанные с масштабом или трафиком._

### Трафик

Это будет система с большим объемом чтения. Предположим, что у нас 1 миллиард пользователей с 200 миллионами ежедневных активных пользователей (DAU), и в среднем каждый пользователь пишет твиты 5 раз в день. Это дает нам 1 миллиард твитов в день.

$$
200 \space million \times 5 \space tweets = 1 \space billion/day
$$

Твиты также могут содержать медиафайлы, такие как изображения или видео. Мы можем предположить, что 10 % твитов - это медиафайлы, которыми делятся пользователи, что дает нам дополнительные 100 миллионов файлов, которые необходимо хранить.

$$
10 \space percent \times 1 \space billion = 100 \space million/day
$$

**Какова будет скорость запросов в секунду (RPS) для нашей системы?

1 миллиард запросов в день - это 12 тысяч запросов в секунду.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Хранилище

Если предположить, что каждое сообщение в среднем занимает 100 байт, то нам потребуется около 100 ГБ хранилища базы данных в день.

$$
1 \space billion \times 100 \space bytes = \sim 100 \space GB/day
$$

Мы также знаем, что около 10 процентов наших ежедневных сообщений (100 миллионов) - это медиафайлы, соответствующие нашим требованиям. Если предположить, что каждый файл в среднем занимает 50 КБ, то нам потребуется 5 ТБ хранилища каждый день.

$$
100 \space million \times 50 \space KB = 5 \space TB/day
$$

А за 10 лет нам потребуется около 19 ПБ хранилища.

$$
(5 \space TB + 0.1 \space TB) \times 365 \space days \times 10 \space years = \sim 19 \space PB
$$

### Пропускная способность

Поскольку наша система ежедневно обрабатывает 5,1 ТБ входящих данных, нам потребуется минимальная пропускная способность около 60 МБ в секунду.

$$
\frac{5.1 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 60 \space MB/second
$$

### Оценка высокого уровня

Вот наша оценка высокого уровня:

| Тип | Смета |
| ------------------------- | ----------- |
| Ежедневные активные пользователи (DAU) | 100 миллионов |
| Запросы в секунду (RPS) | 12K/s |
| Хранение (в день)| ~5,1 ТБ |
| Хранение (10 лет)| ~19 ПБ |
| Пропускная способность | ~60 МБ/с |

## Разработка модели данных

Это общая модель данных, которая отражает наши требования.

![twitter-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-datamodel.png)

У нас есть следующие таблицы:

**users**

Эта таблица будет содержать информацию о пользователе, такую как `имя`, `электронная почта`, `добавка` и другие данные.

**tweets**

Как следует из названия, в этой таблице будут храниться твиты и их свойства, такие как `тип` (текст, изображение, видео и т. д.), `содержание` и т. д. Мы также будем хранить соответствующий `userID`.

**favorites**

Эта таблица сопоставляет твиты с пользователями для функциональности избранных твитов в нашем приложении.

**followers**

В этой таблице отображаются последователи и [followees](https://en.wiktionary.org/wiki/followee), поскольку пользователи могут следовать друг за другом (отношения N:M).

**feeds**

В этой таблице хранятся свойства фида с соответствующим `userID`.

**feeds_tweets**

В этой таблице отображаются твиты и фиды (связь N:M).

### Какую базу данных мы должны использовать?

Хотя наша модель данных выглядит вполне реляционной, нам не обязательно хранить все в одной базе данных, поскольку это может ограничить масштабируемость и быстро превратиться в узкое место.

Мы разделим данные между различными службами, каждая из которых будет владеть определенной таблицей. Тогда мы можем использовать реляционную базу данных, например [PostgreSQL](https://www.postgresql.org), или распределенную базу данных NoSQL, например [Apache Cassandra](https://cassandra.apache.org/_/index.html), для нашего случая.

## Дизайн API

Давайте сделаем базовый дизайн API для наших сервисов:

### Опубликовать твит

Этот API позволит пользователю опубликовать твит на платформе.

```tsx
postTweet(userID: UUID, content: string, mediaURL?: string): boolean
```

**Параметры**

User ID (`UUID`): Идентификатор пользователя.

Content (`string`): Содержание твита.

Media URL (`string`): URL-адрес прикрепленного медиафайла _(необязательно)_.

**Возврат**

Result (`булево`): Отражает, была ли операция успешной или нет.

### Следовать или не следовать за пользователем

Этот API позволяет пользователю следовать или не следовать за другим пользователем.

```tsx
follow(followerID: UUID, followeeID: UUID): boolean
unfollow(followerID: UUID, followeeID: UUID): boolean
```

**Параметры**

Follower ID (`UUID`): Идентификатор текущего пользователя.

Followee ID(`UUID`): ID пользователя, за которым мы хотим следить или от которого хотим откреститься.

Media URL (`string`): URL-адрес прикрепленного медиафайла _(необязательно)_.


**Возврат**

Result (`boolean`): Отражает, была ли операция успешной или нет.

### Получить ленту новостей

Этот API вернет все твиты, которые будут показаны в заданной ленте новостей.

```tsx
getNewsfeed(userID: UUID): Tweet[]
```

**Параметры**

User ID (`UUID`): ID пользователя.

**Возвращает**

Tweets (`Tweet[]`): Все твиты, которые будут показаны в данной ленте новостей.

## Высокоуровневый дизайн

Теперь давайте сделаем высокоуровневый дизайн нашей системы.

### Архитектура

Мы будем использовать [архитектуру микросервисов](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices), так как она облегчает горизонтальное масштабирование и разделение наших сервисов.Каждый сервис будет владеть своей собственной моделью данных. Давайте попробуем разделить нашу систему на несколько основных сервисов.

**Сервис пользователя**.

Этот сервис занимается вопросами, связанными с пользователями, такими как аутентификация и информация о пользователе.

**Сервис новостной ленты**.

Этот сервис будет заниматься созданием и публикацией новостных лент пользователей. Он будет подробно рассмотрен отдельно.

**Сервис твитов**

Сервис твитов будет обрабатывать связанные с твитами сценарии использования, такие как публикация твита, избранное и т.д.

**Поисковый сервис**

Этот сервис отвечает за работу с функциями, связанными с поиском. Он будет подробно рассмотрен отдельно.

**Медиа-сервис**

Этот сервис отвечает за загрузку медиафайлов (изображений, видео, файлов и т. д.). Подробнее об этом будет рассказано отдельно.

**Сервис уведомлений**

Этот сервис будет просто отправлять пользователям push-уведомления.

**Аналитический сервис**

Этот сервис будет использоваться для метрик и аналитики.

**А как насчет межсервисного взаимодействия и обнаружения сервисов?

Поскольку наша архитектура основана на микросервисах, сервисы также будут взаимодействовать друг с другом. Как правило, REST или HTTP работают хорошо, но мы можем еще больше повысить производительность, используя [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc), который является более легким и эффективным.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) - это еще одна вещь, которую мы должны принять во внимание. Мы также можем использовать сетку сервисов, которая обеспечивает управляемую, наблюдаемую и безопасную связь между отдельными сервисами.

_Примечание: Узнайте больше о [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) и их сравнении друг с другом._

### Лента новостей

Когда речь заходит о ленте новостей, кажется, что реализовать ее достаточно просто, но есть много вещей, которые могут сделать или сломать эту функцию. Итак, давайте разделим нашу проблему на две части:

**Генерация**.

Допустим, мы хотим сгенерировать ленту для пользователя A, для этого мы выполним следующие шаги:

1. Получим идентификаторы всех пользователей и сущностей (хэштегов, тем и т. д.), за которыми следит пользователь A.
2. Найти релевантные твиты для каждого из полученных идентификаторов.
3. Используйте алгоритм ранжирования для ранжирования твитов по таким параметрам, как релевантность, время, вовлеченность и т. д.
4. Возврат ранжированных твитов клиенту в постраничном виде.

Формирование ленты - интенсивный процесс, который может занимать довольно много времени, особенно для пользователей, следящих за большим количеством людей. Чтобы повысить производительность, фид может быть предварительно сгенерирован и сохранен в кэше, а затем мы можем иметь механизм для периодического обновления фида и применения нашего алгоритма ранжирования к новым твитам.

**Публикация**

Публикация - это этап, на котором данные ленты рассылаются каждому конкретному пользователю. Это может быть довольно сложной операцией, поскольку у пользователя могут быть миллионы друзей или подписчиков. Чтобы справиться с этим, у нас есть три различных подхода:

- Pull Model (или Fan-out on load)

![newsfeed-pull-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-pull-model.png)

Когда пользователь создает твит, а его последователь перезагружает свою ленту новостей, лента создается и сохраняется в памяти. Самая последняя лента загружается только тогда, когда пользователь ее запрашивает. Такой подход позволяет сократить количество операций записи в нашу базу данных.

Недостатком этого подхода является то, что пользователи не смогут просматривать последние ленты, пока не "вытащат" данные с сервера, что увеличит количество операций чтения на сервере.

- Модель Push (или веерная запись)

![newsfeed-push-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-push-model.png)

В этой модели, как только пользователь создает твит, он сразу же "проталкивается" во все ленты последователей. Это избавляет систему от необходимости просматривать весь список подписчиков пользователя, чтобы проверить наличие обновлений.

Однако недостатком такого подхода является увеличение количества операций записи в базу данных.

- Гибридная модель

Третий подход - это гибридная модель между "тянущей" и "толкающей" моделями. Она сочетает в себе положительные черты двух вышеупомянутых моделей и пытается обеспечить сбалансированный подход между ними.

Гибридная модель позволяет использовать модель push только пользователям с меньшим числом подписчиков. Для пользователей с большим числом подписчиков, например знаменитостей, используется модель pull.

### Алгоритм ранжирования

Как мы уже говорили, нам понадобится алгоритм ранжирования, чтобы ранжировать каждый твит в соответствии с его релевантностью для каждого конкретного пользователя.

Например, в Facebook используется алгоритм [EdgeRank](https://en.wikipedia.org/wiki/EdgeRank). Здесь ранг каждого элемента ленты описывается:

$$
Rank = Affinity \times Weight \times Decay
$$

Где,

`Affinity`: это "близость" пользователя к создателю края. Если пользователь часто ставит лайки, комментирует или пишет сообщения создателю ребра, то значение близости будет выше, что приведет к более высокому рангу поста.

`Weight`: значение, присваиваемое каждому краю. Комментарий может иметь больший вес, чем лайк, и поэтому пост с большим количеством комментариев с большей вероятностью получит более высокий ранг.

`Decay`: показатель времени создания края. Чем старше край, тем меньше значение распада и, в конечном счете, ранг.

В настоящее время алгоритмы стали намного сложнее, и ранжирование осуществляется с помощью моделей машинного обучения, которые могут учитывать тысячи факторов.

### Ретвиты

Ретвиты - одно из наших расширенных требований. Чтобы реализовать эту функцию, мы можем просто создать новый твит с идентификатором пользователя, ретвитнувшего оригинальный твит, а затем изменить свойства `type` enum и `content` нового твита, чтобы связать его с оригинальным твитом.

Например, свойство перечисления `type` может быть типом твита, таким же, как текст, видео и т. д., а `content` может быть идентификатором оригинального твита. Здесь первая строка указывает на оригинальный твит, а вторая - на то, как мы можем представить ретвит.

| id | userID | type | content | createdAt |
| ------------------- | ------------------- | ----- | ---------------------------- | ------------- |
| ad34-291a-45f6-b36c | 7a2c-62c4-4dc8-b1bb | text | Привет, это мой первый твит...| 1658905644054 |
| f064-49ad-9aa2-84a6 | 6aa2-2bc9-4331-879f | tweet | ad34-291a-45f6-b36c | 1658906165427 |

Это очень базовая реализация. Чтобы улучшить ее, мы можем создать отдельную таблицу для хранения ретвитов.

### Поиск

Иногда традиционные СУБД недостаточно производительны, нам нужно что-то, что позволяет хранить, искать и анализировать огромные объемы данных быстро и практически в режиме реального времени, выдавая результаты в течение миллисекунд. В этом нам может помочь [Elasticsearch](https://www.elastic.co).

[Elasticsearch](https://www.elastic.co) - это распределенная, бесплатная и открытая поисковая и аналитическая система для всех типов данных, включая текстовые, числовые, геопространственные, структурированные и неструктурированные. Он построен на основе [Apache Lucene](https://lucene.apache.org).

**Как мы будем определять трендовые темы?**

Функциональность трендов будет основана на функциональности поиска. Мы можем кэшировать наиболее часто встречающиеся запросы, хэштеги и темы за последние `N` секунд и обновлять их каждые `M` секунд, используя какой-то механизм пакетной работы. Наш алгоритм ранжирования также может быть применен к трендовым темам, чтобы придать им больший вес и персонализировать их для пользователя.

### Уведомления

Push-уведомления являются неотъемлемой частью любой платформы социальных сетей. Мы можем использовать очередь сообщений или брокер сообщений, например [Apache Kafka](https://kafka.apache.org), вместе со службой уведомлений для отправки запросов в [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) или [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications), которые будут заниматься доставкой push-уведомлений на пользовательские устройства.

За более подробной информацией обратитесь к проекту системы [WhatsApp](https://karanpratapsingh.com/courses/system-design/whatsapp#notifications), где мы подробно обсуждаем push-уведомления._

## Детальный дизайн

Пришло время обсудить наши проектные решения в деталях.

### Разбиение данных

Чтобы масштабировать наши базы данных, нам нужно разделить данные. Горизонтальное разделение (оно же [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) может быть хорошим первым шагом. Мы можем использовать такие схемы разбиения, как:

- Hash-Based Partitioning
- Разбиение на основе списков
- Разбиение на основе диапазонов
- составные разделы

Вышеперечисленные подходы могут привести к неравномерному распределению данных и нагрузки, но мы можем решить эту проблему с помощью [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

Более подробную информацию вы найдете в разделах [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) и [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

### Взаимные друзья

Для поиска общих друзей мы можем построить социальный граф для каждого пользователя. Каждый узел в графе будет представлять пользователя, а направленное ребро - последователей и подписчиков. После этого мы можем просмотреть последователей пользователя, чтобы найти и предложить ему общего друга. Для этого потребуется база данных графов, такая как [Neo4j](https://neo4j.com) и [ArangoDB](https://www.arangodb.com).

Это довольно простой алгоритм, но для повышения точности рекомендаций нам потребуется включить в алгоритм модель рекомендаций, использующую машинное обучение.

### Метрики и аналитика

Запись аналитики и метрик - одно из наших расширенных требований. Поскольку мы будем использовать [Apache Kafka](https://kafka.apache.org) для публикации всевозможных событий, мы можем обрабатывать эти события и проводить аналитику данных с помощью [Apache Spark](https://spark.apache.org), который является унифицированным аналитическим движком с открытым исходным кодом для обработки крупномасштабных данных.

### Кэширование

В приложениях для социальных сетей мы должны быть осторожны с использованием кэша, поскольку наши пользователи ожидают самых свежих данных. Поэтому, чтобы предотвратить перегрузку наших ресурсов, мы можем кэшировать 20 % самых свежих твитов.

Для дальнейшего повышения эффективности мы можем добавить пагинацию в API нашей системы. Это решение будет полезно для пользователей с ограниченной пропускной способностью сети, так как им не придется получать старые сообщения, если они не запрашиваются.

**Какую политику вытеснения кэша использовать?**

Мы можем использовать такие решения, как [Redis](https://redis.io) или [Memcached](https://memcached.org), и кэшировать 20 % ежедневного трафика, но какая политика вытеснения кэша лучше всего подойдет для наших нужд?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) может быть хорошей политикой для нашей системы. В этой политике мы отбрасываем в первую очередь наименее недавно использованный ключ.

**Как справиться с пропуском кэша?**

Когда происходит пропуск кэша, наши серверы могут напрямую обращаться к базе данных и обновлять кэш новыми записями.

Более подробную информацию вы найдете в разделе [Кэширование](https://karanpratapsingh.com/courses/system-design/caching)._

### Доступ к носителям и их хранение

Как мы знаем, большая часть нашего хранилища будет использоваться для хранения медиафайлов, таких как изображения, видео или другие файлы. Наш медиасервис будет управлять доступом и хранением пользовательских медиафайлов.

Но где мы можем хранить файлы в масштабе? Что ж, [объектное хранилище](https://karanpratapsingh.com/courses/system-design/storage#object-storage) - это то, что нам нужно. Объектные хранилища разбивают файлы данных на части, называемые объектами. Затем эти объекты хранятся в едином хранилище, которое может быть распределено по нескольким сетевым системам. Мы также можем использовать распределенные файловые хранилища, такие как [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs) или [GlusterFS](https://www.gluster.org).

### Сеть доставки контента (CDN)

[Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) повышает доступность и избыточность контента, снижая при этом затраты на пропускную способность. Как правило, статические файлы, такие как изображения и видео, обслуживаются из CDN. Для этого случая мы можем использовать такие сервисы, как [Amazon CloudFront](https://aws.amazon.com/cloudfront) или [Cloudflare CDN](https://www.cloudflare.com/cdn).

## Выявление и устранение узких мест

![twitter-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-advanced-design.png)

Давайте определим и устраним узкие места, такие как единые точки отказа в нашем дизайне:

- "Что, если один из наших сервисов сломается?"
- "Как мы будем распределять трафик между компонентами?"
- "Как мы можем снизить нагрузку на нашу базу данных?"
- "Как повысить доступность нашего кэша?"
- "Как сделать нашу систему уведомлений более надежной?"
- "Как мы можем сократить расходы на хранение информации?"

Чтобы сделать нашу систему более устойчивой, мы можем сделать следующее:

- Запустить несколько экземпляров каждой из наших служб.
- Внедрение [балансировщиков нагрузки](https://karanpratapsingh.com/courses/system-design/load-balancing) между клиентами, серверами, базами данных и серверами кэша.
- Использование нескольких реплик чтения для наших баз данных.
- Несколько экземпляров и реплик для нашего распределенного кэша.
- Именно тогда, когда доставка и упорядочивание сообщений в распределенной системе являются сложной задачей, мы можем использовать специализированный [брокер сообщений](https://karanpratapsingh.com/courses/system-design/message-brokers), такой как [Apache Kafka](https://kafka.apache.org) или [NATS](https://nats.io), чтобы сделать нашу систему уведомлений более надежной.
- Мы можем добавить возможности обработки и сжатия медиафайлов в медиасервис, чтобы сжимать большие файлы, что позволит сэкономить много места для хранения и снизить стоимость.

# Netflix

Давайте спроектируем потоковый видеосервис [Netflix](https://netflix.com), подобный таким сервисам, как [Amazon Prime Video](https://www.primevideo.com), [Disney Plus](https://www.disneyplus.com), [Hulu](https://www.hulu.com), [Youtube](https://youtube.com), [Vimeo](https://vimeo.com) и т.д.

## Что такое Netflix?

Netflix - это основанный на подписке потоковый сервис, который позволяет своим пользователям смотреть телешоу и фильмы на подключенных к интернету устройствах. Он доступен на таких платформах, как Web, iOS, Android, TV и т. д.

## Требования

Наша система должна отвечать следующим требованиям:

### Функциональные требования

- Пользователи должны иметь возможность транслировать видео и обмениваться им.
- Команда разработчиков контента (или пользователи в случае YouTube) должна иметь возможность загружать новые видео (фильмы, эпизоды телешоу и другой контент).
- Пользователи должны иметь возможность искать видео по названиям или тегам.
- Пользователи должны иметь возможность комментировать видео, как на YouTube.

### Нефункциональные требования

- Высокая доступность с минимальными задержками.
- Высокая надежность, ни одна загрузка не должна быть потеряна.
- Система должна быть масштабируемой и эффективной.

### Расширенные требования

- Определенный контент должен быть [geo-blocked](https://en.wikipedia.org/wiki/Geo-blocking).
- Возобновление воспроизведения видео с того места, на котором пользователь остановился.
- Запись метрик и аналитика видео.

## Оценка и ограничения

Давайте начнем с оценки и ограничений.

Примечание: Обязательно уточните у интервьюера все допущения, связанные с масштабом или трафиком.

### Трафик

Это будет система с высокой нагрузкой на чтение. Предположим, что у нас 1 миллиард пользователей с 200 миллионами ежедневных активных пользователей (DAU), и в среднем каждый пользователь смотрит 5 видео в день. Это дает нам 1 миллиард просмотренных видео в день.

$$
200 \space million \times 5 \space videos = 1 \space billion/day
$$

Если предположить, что соотношение чтения и записи будет составлять 200:1, то каждый день будет загружаться около 5 миллионов видео.

$$
\frac{1}{200} \times 1 \space billion = 5 \space million/day
$$

**Какова будет скорость запросов в секунду (RPS) для нашей системы?**

1 миллиард запросов в день - это 12 тысяч запросов в секунду.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Хранение

Если предположить, что каждый видеоролик в среднем занимает 100 МБ, то нам потребуется около 500 ТБ хранилища в день.

$$
5 \space million \times 100 \space MB = 500 \space TB/day
$$

А в течение 10 лет нам потребуется 1 825 ПБ хранилищ.

$$
500 \space TB \times 365 \space days \times 10 \space years = \sim 1,825 \space PB
$$
### Пропускная способность

Поскольку наша система ежедневно обрабатывает 500 ТБ входящего потока, нам потребуется минимальная пропускная способность около 5,8 ГБ в секунду.

$$
\frac{500 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 5.8 \space GB/second
$$

### Оценка высокого уровня

Вот наша оценка  высокого уровня:

| Тип | Смета |
| ------------------------- | ----------- |
| Ежедневные активные пользователи (DAU) | 200 миллионов |
| Запросы в секунду (RPS) | 12K/s |
| Хранение (в день)| ~500 ТБ |
| Хранение (10 лет)| ~1,825 ПБ |
| Пропускная способность | ~5,8 ГБ/с |

## Дизайн модели данных

Это общая модель данных, которая отражает наши требования.

![netflix-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-datamodel.png)

У нас есть следующие таблицы:

**users**.

Эта таблица содержит информацию о пользователе, такую как `имя`, `email`, `dob` и другие данные.

**videos**

Как следует из названия, в этой таблице будут храниться видео и их свойства, такие как `title`, `streamURL`, `tags` и т.д. Мы также будем хранить соответствующий `userID`.

**tags**

В этой таблице хранятся теги, связанные с видео.

**views**

Эта таблица поможет нам хранить все просмотры, полученные видео.

**comments**

В этой таблице хранятся все комментарии, полученные к видео (как на YouTube).

### Какую базу данных мы должны использовать?

Хотя наша модель данных выглядит вполне реляционной, нам не обязательно хранить все в одной базе данных, поскольку это может ограничить масштабируемость и быстро превратиться в узкое место.

Мы разделим данные между различными службами, каждая из которых будет владеть определенной таблицей. Тогда мы можем использовать реляционную базу данных, например [PostgreSQL](https://www.postgresql.org), или распределенную базу данных NoSQL, например [Apache Cassandra](https://cassandra.apache.org/_/index.html), для нашего случая.

## Дизайн API

Давайте сделаем базовый дизайн API для наших сервисов:

### Загрузка видео

Этот API позволяет загрузить видео в наш сервис, получив поток байтов.

```tsx
uploadVideo(title: string, description: string, data: Stream<byte>, tags?: string[]): boolean
```

**Параметры**

Title (`string`): Название нового видео.

Description (`string`): Описание нового видео.

Data (`Byte[]`): Поток байтов видеоданных.

Tags (`string[]`): Теги для видео _(необязательно)_.

**Возврат**

Result (`boolean`): Указывает, была ли операция успешной или нет.

### Потоковое видео

Этот API позволяет нашим пользователям передавать потоковое видео с выбранным кодеком и разрешением.

```tsx
streamVideo(videoID: UUID, codec: Enum<string>, resolution: Tuple<int>, offset?: int): VideoStream
```

**Параметры**

Video ID (`UUID`): Идентификатор видео, которое необходимо транслировать.

Codec (`Enum<string>`): Требуемый [кодек](https://en.wikipedia.org/wiki/Video_codec) запрашиваемого видео, например `h.265`, `h.264`, `VP9` и т. д.

Resolution (`Tuple<int>`): [Разрешение](https://en.wikipedia.org/wiki/Display_resolution) запрашиваемого видео.

Offset (`int`): Смещение видеопотока в секундах для передачи данных из любой точки видео _(необязательно)_.

**Возврат**

Stream (`VideoStream`): Поток данных запрашиваемого видео.

### Поиск видео

Этот API позволит нашим пользователям искать видео по его названию или тегам.

``tsx
searchVideo(query: string, nextPage?: string): Video[]
```

**Параметры**

Query (`string`): Поисковый запрос от пользователя.

Next Page (`строка`): Токен для следующей страницы, который может быть использован для пагинации _(необязательно)_.

**Возвраты**.

Videos (`Video[]`): Все видео, доступные для определенного поискового запроса.

### Добавить комментарий

Этот API позволит нашим пользователям оставлять комментарии к видео (как на YouTube).

``tsx
comment(videoID: UUID, comment: string): boolean
```

**Параметры**

VideoID (`UUID`): ID видео, которое пользователь хочет прокомментировать.

Comment (`string`): Текстовое содержимое комментария.

**Возврат**

Result (`boolean`): Указывает, была ли операция успешной или нет.

## Высокоуровневый дизайн

Теперь давайте сделаем высокоуровневый дизайн нашей системы.

### Архитектура

Мы будем использовать [архитектуру микросервисов](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices), так как она облегчает горизонтальное масштабирование и разделение наших сервисов. Каждый сервис будет владеть своей собственной моделью данных. Давайте попробуем разделить нашу систему на несколько основных сервисов.

**Сервис пользователя**.

Этот сервис занимается вопросами, связанными с пользователями, такими как аутентификация и информация о пользователе.

**Сервис потока**

Служба потоков будет обрабатывать функции, связанные с потоковым видео.

**Поисковый сервис**

Эта служба отвечает за работу с функциями, связанными с поиском. Он будет подробно рассмотрен отдельно.

**Медиа-сервис**

Этот сервис отвечает за загрузку и обработку видео. Подробнее об этом будет рассказано отдельно.

**Аналитический сервис**.

Этот сервис будет использоваться для работы с метриками и аналитикой.

**А как насчет межсервисного взаимодействия и обнаружения сервисов?**

Поскольку наша архитектура основана на микросервисах, сервисы также будут взаимодействовать друг с другом. Как правило, REST или HTTP работают хорошо, но мы можем еще больше повысить производительность, используя [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc), который является более легким и эффективным.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) - это еще одна вещь, которую мы должны принять во внимание. Мы также можем использовать сетку сервисов, которая обеспечивает управляемую, наблюдаемую и безопасную связь между отдельными сервисами.

_Примечание: Узнайте больше о [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) и их сравнении друг с другом._

### Обработка видео

![video-processing-pipeline](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/video-processing-pipeline.png)

Когда речь заходит об обработке видео, в игру вступает множество переменных. Например, средний размер данных двухчасового необработанного 8K-видео с высококлассной камеры может легко достигать 4 ТБ, поэтому нам необходима определенная обработка, чтобы сократить расходы на хранение и доставку.

Вот как мы можем обрабатывать видео после того, как оно загружено командой разработчиков контента (или пользователями в случае YouTube) и поставлено в очередь на обработку в нашей [очереди сообщений](https://karanpratapsingh.com/courses/system-design/message-queues).

Давайте обсудим, как это работает:

- **Файловый чанкер**

![file-chunking](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/file-chunking.png)

Это первый шаг нашего конвейера обработки. Разбивка файла на части - это процесс разделения файла на более мелкие части, называемые кусками. Это помогает нам избавиться от дубликатов повторяющихся данных в хранилище и сократить объем данных, передаваемых по сети, выбирая только измененные фрагменты.

Обычно видеофайл можно разделить на одинаковые по размеру фрагменты по временным меткам, но Netflix вместо этого делит фрагменты по сценам. Это небольшое различие становится важным фактором для улучшения качества работы пользователей, поскольку при запросе клиентом фрагмента с сервера вероятность прерывания меньше, так как будет получена полная сцена.

- **Фильтр контента**

На этом этапе проверяется, соответствует ли видео контентной политике платформы. Она может быть предварительно одобрена, как в случае с Netflix, в соответствии с [рейтингом контента] (https://en.wikipedia.org/wiki/Motion_picture_content_rating_system) медиа или строго соблюдаться, как на YouTube.

Весь этот процесс осуществляется с помощью модели машинного обучения, которая выполняет проверку на авторские права, пиратство и NSFW. Если обнаружены проблемы, мы можем перенести задание в [очередь мертвых букв (DLQ)](https://karanpratapsingh.com/courses/system-design/message-queues#dead-letter-queues), и кто-то из команды модераторов сможет провести дальнейшую проверку.

- **Транскодер**

[Транскодирование](https://en.wikipedia.org/wiki/Transcoding) - это процесс, в котором исходные данные декодируются в промежуточный несжатый формат, который затем кодируется в целевой формат. В этом процессе используются различные [кодеки](https://en.wikipedia.org/wiki/Video_codec) для регулировки битрейта, понижения дискретизации изображения или повторного кодирования носителя.

В результате получается файл меньшего размера и гораздо более оптимизированный формат для целевых устройств. Для реализации этого этапа конвейера можно использовать автономные решения, такие как [FFmpeg](https://ffmpeg.org), или облачные решения, например [AWS Elemental MediaConvert](https://aws.amazon.com/mediaconvert).

- **Преобразование качества**.

Это последний этап конвейера обработки, и, как следует из названия, на этом этапе происходит преобразование транскодированного медиафайла, полученного на предыдущем этапе, в различные разрешения, такие как 4K, 1440p, 1080p, 720p и т. д.

Это позволяет нам получить желаемое качество видео в соответствии с запросом пользователя, и как только медиафайл завершает обработку, он загружается в распределенное файловое хранилище, такое как [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs), [GlusterFS](https://www.gluster.org), или [объектное хранилище](https://karanpratapsingh.com/courses/system-design/storage#object-storage), такое как [Amazon S3](https://aws.amazon.com/s3), для последующего получения во время потоковой передачи.

_Примечание: Мы можем добавить дополнительные шаги, такие как создание субтитров и миниатюр, как часть нашего конвейера._

**Почему мы используем очередь сообщений?**

Обработка видео как длительная задача с использованием [очереди сообщений] (https://karanpratapsingh.com/courses/system-design/message-queues) имеет гораздо больше смысла. Она также отделяет наш конвейер обработки видео от функциональности загрузки. Мы можем использовать что-то вроде [Amazon SQS](https://aws.amazon.com/sqs) или [RabbitMQ](https://www.rabbitmq.com) для поддержки этого.

### Видеопоток

Передача потокового видео - сложная задача как с точки зрения клиента, так и с точки зрения сервера. Кроме того, скорость интернет-соединения у разных пользователей сильно различается. Чтобы пользователи не получали повторно один и тот же контент, мы можем использовать [Сеть доставки контента (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network).

Netflix делает еще один шаг вперед благодаря своей программе [Open Connect](https://openconnect.netflix.com). В рамках этого подхода компания сотрудничает с тысячами интернет-провайдеров (ISP), чтобы локализовать свой трафик и доставлять контент более эффективно.

**В чем разница между Open Connect от Netflix и традиционной сетью доставки контента (CDN)?**

Netflix Open Connect - это специально созданная [Сеть доставки контента (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network), отвечающая за обслуживание видеотрафика Netflix. Около 95 % трафика по всему миру доставляется через прямые соединения между Open Connect и провайдерами, через которых их клиенты выходят в Интернет.

В настоящее время устройства Open Connect Appliances (OCA) установлены в более чем 1000 отдельных точках по всему миру. В случае возникновения проблем устройства Open Connect Appliances (OCA) могут отказать, и трафик может быть перенаправлен на серверы Netflix.

Кроме того, мы можем использовать протоколы [Adaptive bitrate streaming](https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming), такие как [HTTP Live Streaming (HLS)](https://en.wikipedia.org/wiki/HTTP_Live_Streaming), которые разработаны для обеспечения надежности и динамически адаптируются к условиям сети, оптимизируя воспроизведение под доступную скорость соединения.

Наконец, для воспроизведения видео с того места, на котором пользователь остановился (часть наших расширенных требований), мы можем просто использовать свойство `offset`, сохраненное в таблице `views`, чтобы получить чанк сцены в конкретную временную метку и возобновить воспроизведение для пользователя.

### Поиск

Иногда традиционные СУБД недостаточно производительны, нам нужно что-то, что позволяет хранить, искать и анализировать огромные объемы данных быстро и практически в режиме реального времени, выдавая результаты в течение миллисекунд. В этом нам может помочь [Elasticsearch](https://www.elastic.co).

[Elasticsearch](https://www.elastic.co) - это распределенная, бесплатная и открытая поисковая и аналитическая система для всех типов данных, включая текстовые, числовые, геопространственные, структурированные и неструктурированные. Он построен на основе [Apache Lucene](https://lucene.apache.org).

**Как мы будем определять трендовый контент?**

Функциональность трендов будет основана на функциональности поиска. Мы можем кэшировать наиболее часто встречающиеся запросы за последние `N` секунд и обновлять их каждые `M` секунд, используя некий механизм пакетной работы.

### Sharing

Обмен контентом - важная часть любой платформы, для этого мы можем использовать службу укорачивания URL, которая будет генерировать короткие URL для пользователей.

За более подробной информацией обратитесь к проекту системы [URL Shortener](https://karanpratapsingh.com/courses/system-design/url-shortener).

## Детальный дизайн

Пришло время обсудить наши проектные решения в деталях.

### Разбиение данных

Чтобы масштабировать наши базы данных, нам нужно разделить данные. Горизонтальное разделение (оно же [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) может быть хорошим первым шагом. Мы можем использовать такие схемы разбиения, как:

- Hash-Based Partitioning
- Разбиение на основе списков
- Разбиение на основе диапазонов
- составные разделы

Вышеперечисленные подходы могут привести к неравномерному распределению данных и нагрузки, но мы можем решить эту проблему с помощью [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

Более подробную информацию вы найдете в разделах [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) и [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

### Гео-блокировка

Такие платформы, как Netflix и YouTube, используют [Геоблокировку](https://en.wikipedia.org/wiki/Geo-blocking) для ограничения контента в определенных географических зонах или странах. В первую очередь это связано с законами о распространении, которых Netflix должен придерживаться при заключении сделок с компаниями-производителями и дистрибьюторами. В случае с YouTube это будет контролироваться пользователем во время публикации контента.

Мы можем определить местоположение пользователя, используя его [IP](https://karanpratapsingh.com/courses/system-design/ip) или настройки региона в его профиле, а затем использовать такие сервисы, как [Amazon CloudFront](https://aws.amazon.com/cloudfront), который поддерживает функцию географических ограничений, или [геолокационную политику маршрутизации](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html) с [Amazon Route53](https://aws.amazon.com/route53) для ограничения контента и перенаправления пользователя на страницу ошибки, если контент недоступен в данном регионе или стране.

### Рекомендации

Netflix использует модель машинного обучения, которая использует историю просмотров пользователя, чтобы предсказать, что пользователь может захотеть посмотреть следующим, может быть использован такой алгоритм, как [Collaborative Filtering](https://en.wikipedia.org/wiki/Collaborative_filtering).

Однако Netflix (как и YouTube) использует свой собственный алгоритм под названием Netflix Recommendation Engine, который может отслеживать несколько точек данных, таких как:

- Информация о профиле пользователя, такая как возраст, пол и местоположение.
- Поведение пользователя при просмотре и прокрутке.
- Время и дата просмотра пользователем заголовка.
- Устройство, с которого осуществлялась потоковая передача контента.
- Количество поисковых запросов и то, по каким запросам осуществлялся поиск.

_Более подробную информацию см. в [исследовании рекомендаций Netflix](https://research.netflix.com/research-area/recommendations)._

### Метрики и аналитика

Запись аналитики и метрик - одно из наших расширенных требований. Мы можем получать данные из различных сервисов и проводить аналитику с помощью [Apache Spark](https://spark.apache.org), который является унифицированным аналитическим движком с открытым исходным кодом для обработки крупномасштабных данных. Кроме того, мы можем хранить важные метаданные в таблице представлений, чтобы увеличить количество точек данных в наших данных.

### Кэширование

Для потоковой платформы кэширование имеет большое значение. Мы должны иметь возможность кэшировать как можно больше статического медиаконтента, чтобы улучшить пользовательский опыт. Мы можем использовать такие решения, как [Redis](https://redis.io) или [Memcached](https://memcached.org), но какая политика вытеснения кэша лучше всего подойдет для наших нужд?

**Какую политику вытеснения кэша использовать?**

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) может быть хорошей политикой для нашей системы. В этой политике мы сначала удаляем наименее недавно использованный ключ.

**Как обрабатывать пропуски кэша?**

Когда происходит пропуск кэша, наши серверы могут напрямую обращаться к базе данных и обновлять кэш новыми записями.

_Более подробную информацию см. в разделе [Кэширование](https://karanpratapsingh.com/courses/system-design/caching)._

### Потоковое воспроизведение и хранение медиафайлов

Большая часть нашего пространства для хранения будет использоваться для хранения медиафайлов, таких как миниатюры и видео. Как мы обсуждали ранее, медиасервис будет заниматься как загрузкой, так и обработкой медиафайлов.

Для хранения и потоковой передачи контента мы будем использовать распределенные файловые хранилища, такие как [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs), [GlusterFS](https://www.gluster.org) или [объектные хранилища](https://karanpratapsingh.com/courses/system-design/storage#object-storage), например [Amazon S3](https://aws.amazon.com/s3).

### Content Delivery Network (CDN)

[Сеть доставки контента (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) повышает доступность и избыточность контента, снижая при этом затраты на пропускную способность. Как правило, статические файлы, такие как изображения и видео, обслуживаются из CDN. Для этого случая мы можем использовать такие сервисы, как [Amazon CloudFront](https://aws.amazon.com/cloudfront) или [Cloudflare CDN](https://www.cloudflare.com/cdn).

## Выявление и устранение узких мест

![netflix-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-advanced-design.png)

Давайте определим и устраним узкие места, такие как единые точки отказа в нашем дизайне:

- "Что, если один из наших сервисов сломается?"
- "Как мы будем распределять трафик между компонентами?"
- "Как мы можем снизить нагрузку на нашу базу данных?"
- "Как повысить доступность нашего кэша?".

Чтобы сделать нашу систему более устойчивой, мы можем сделать следующее:

- Запустить несколько экземпляров каждого из наших сервисов.
- Внедрение [балансировщиков нагрузки](https://karanpratapsingh.com/courses/system-design/load-balancing) между клиентами, серверами, базами данных и серверами кэша.
- Использование нескольких реплик чтения для наших баз данных.
- Несколько экземпляров и реплик для нашего распределенного кэша.

# Uber

Давайте спроектируем [Uber](https://uber.com), похожий на сервис поездок, аналогичный таким сервисам, как [Lyft](https://www.lyft.com), [OLA Cabs](https://www.olacabs.com) и т. д.

## Что такое Uber?

Uber - это провайдер услуг мобильности, позволяющий пользователям заказывать поездки и водителя для их перевозки по аналогии с такси. Он доступен в Интернете и на мобильных платформах, таких как Android и iOS.

## Требования

Наша система должна отвечать следующим требованиям:

### Функциональные требования

Мы разработаем нашу систему для двух типов пользователей: Клиентов и Водителей.

**Клиенты**.

- Клиенты должны иметь возможность видеть все такси поблизости с информацией о времени прибытия и ценах.
- Клиенты должны иметь возможность заказать такси до места назначения.
- Клиенты должны иметь возможность видеть местоположение водителя.

**Drivers**

- Водители должны иметь возможность принять или отклонить заявку клиента на поездку.
- После того как водитель примет поездку, он должен увидеть местоположение клиента.
- Водители должны иметь возможность отметить поездку как завершенную по достижении места назначения.

### Нефункциональные требования

- Высокая надежность.
- Высокая доступность при минимальных задержках.
- Система должна быть масштабируемой и эффективной.

### Расширенные требования

- Клиенты могут оценивать поездку после ее завершения.
- Обработка платежей.
- Метрики и аналитика.

## Оценка и ограничения

Давайте начнем с оценки и ограничений.

_Примечание: Обязательно уточните у интервьюера все допущения, связанные с масштабом или трафиком._

### Трафик

Предположим, что у нас 100 миллионов ежедневных активных пользователей (DAU) и 1 миллион водителей, а в среднем наша платформа обеспечивает 10 миллионов поездок в день.

Если в среднем каждый пользователь выполняет 10 действий (например, запрашивает информацию о доступных поездках, тарифах, бронирует поездки и т. д.), нам придется обрабатывать 1 миллиард запросов ежедневно.

$$
100 \space million \times 10 \space actions = 1 \space billion/day
$$

**Какова будет скорость запросов в секунду (RPS) для нашей системы?**

1 миллиард запросов в день - это 12 тысяч запросов в секунду.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Хранилище

Если мы предположим, что каждое сообщение в среднем составляет 400 байт, то нам потребуется около 400 ГБ хранилища базы данных каждый день.

$$
1 \space billion \times 400 \space bytes = \sim 400 \space GB/day
$$

А за 10 лет нам потребуется около 1,4 Pb хранилища.

$$
400 \space GB \times 10 \space years \times 365 \space days = \sim 1.4 \space PB
$$

### Пропускная способность

Поскольку наша система ежедневно обрабатывает 400 ГБ входящего потока, нам потребуется минимальная пропускная способность около 4 МБ в секунду.

$$
\frac{400 \space GB}{(24 \space hrs \times 3600 \space seconds)} = \sim 5 \space MB/second
$$

### Оценка высокого уровня

Вот наша смета высокого уровня:

| Тип | Смета |
| ------------------------- | ----------- |
| Ежедневные активные пользователи (DAU) | 100 миллионов |
| Запросы в секунду (RPS) | 12K/s |
| Хранение (в день)| ~400 ГБ |
| Хранение (10 лет)| ~1,4 ПБ |
| Пропускная способность | ~5 МБ/с |

## Разработка модели данных

Это общая модель данных, которая отражает наши требования.

![uber-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-datamodel.png)

У нас есть следующие таблицы:

**customers**.

Эта таблица будет содержать информацию о клиенте, такую как `имя`, `электронная почта` и другие данные.

**drivers**

Эта таблица содержит информацию о водителе, такую как `имя`, `email`, `dob` и другие данные.

**trips**

Эта таблица представляет поездку, совершенную клиентом, и хранит такие данные, как `источник`, `пункт назначения` и `статус` поездки.

**cabs**

В этой таблице хранятся такие данные, как регистрационный номер и тип (например, Uber Go, Uber XL и т. д.) такси, которым будет управлять водитель.

**ratings**.

Как следует из названия, в этой таблице хранятся `рейтинг` и `отзывы` о поездке.

**payments**

Таблица payments содержит данные о платежах с соответствующим `tripID`.

### Какую базу данных мы должны использовать?

Хотя наша модель данных кажется вполне реляционной, нам не обязательно хранить все в одной базе данных, поскольку это может ограничить масштабируемость и быстро превратиться в узкое место.

Мы разделим данные между различными службами, каждая из которых будет владеть определенной таблицей. Тогда мы можем использовать реляционную базу данных, например [PostgreSQL](https://www.postgresql.org), или распределенную базу данных NoSQL, например [Apache Cassandra](https://cassandra.apache.org/_/index.html), для нашего случая.

## Дизайн API

Давайте сделаем базовый дизайн API для наших сервисов:

### Request a Ride

Через этот API клиенты смогут запросить поездку.

```tsx
requestRide(customerID: UUID, source: Tuple<float>, destination: Tuple<float>, cabType: Enum<string>, paymentMethod: Enum<string>): Ride
```

**Параметры**

Идентификатор клиента (`UUID`): Идентификатор клиента.

Источник (`Tuple<float>`): Кортеж, содержащий широту и долготу начального местоположения поездки.

Destination (`Tuple<float>`): Кортеж, содержащий широту и долготу места назначения поездки.

**Возврат**.

Result (`Ride`): Сопутствующая информация о поездке.

### Отменить поездку

Этот API позволит клиентам отменить поездку.

```tsx
cancelRide(customerID: UUID, reason?: string): boolean
```

**Параметры**

Customer ID (`UUID`): ID клиента.

Reason (`UUID`): Причина отмены поездки _(необязательно)_.

**Возврат**

Result (`boolean`): Отражает, была ли операция успешной или нет.

### Принять или отклонить поездку

Этот API позволяет водителю принять или отклонить поездку.

```tsx
acceptRide(driverID: UUID, rideID: UUID): boolean
denyRide(driverID: UUID, rideID: UUID): boolean
```

**Параметры**

Driver ID (`UUID`): ID водителя.

Ride ID (`UUID`): ID запрошенной клиентом поездки.

**Возврат**

Result (`boolean`): Отражает, была ли операция успешной или нет.

### Начало или окончание поездки

Используя этот API, водитель сможет начать и закончить поездку.

```tsx
startTrip(driverID: UUID, tripID: UUID): boolean
endTrip(driverID: UUID, tripID: UUID): boolean
```

**Параметры**

Driver ID (`UUID`): Идентификатор водителя.

Trip ID (`UUID`): Идентификатор запрашиваемой поездки.

**Возврат**.

Результат (`Boolean`): Отражает, была ли операция успешной или нет.

### Оценить поездку

Этот API позволит клиентам оценить поездку.

```tsx
rateTrip(customerID: UUID, tripID: UUID, rating: int, feedback?: string): boolean
```

**Параметры**

Client ID (`UUID`): ID клиента.

Ride ID (`UUID`): ID завершенной поездки.

Raiting (`int`): Оценка поездки.

Feedback (`string`): Отзыв клиента о поездке _(необязательно)_.

**Возврат**

Result (`boolean`): Отражает, была ли операция успешной или нет.

## Высокоуровневый дизайн

Теперь давайте сделаем высокоуровневый дизайн нашей системы.

### Архитектура

Мы будем использовать [архитектуру микросервисов](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices), так как она облегчает горизонтальное масштабирование и разделение наших сервисов. Каждый сервис будет владеть своей собственной моделью данных. Давайте попробуем разделить нашу систему на несколько основных сервисов.

**Клиентский сервис**.

Этот сервис занимается вопросами, связанными с клиентами, такими как аутентификация и информация о клиенте.

**Сервис водителя**

Эта служба занимается вопросами, связанными с водителем, такими как аутентификация и информация о водителе.

**Сервис поездок**

Эта служба будет отвечать за подбор поездок и агрегацию квадтри. Он будет подробно рассмотрен отдельно.

**Сервис поездок**

Этот сервис отвечает за функциональность, связанную с поездками в нашей системе.

**Платежный сервис**

Этот сервис будет отвечать за обработку платежей в нашей системе.

**Сервис уведомлений**

Этот сервис будет просто отправлять пользователям push-уведомления. Подробнее об этом будет рассказано отдельно.

**Аналитический сервис**

Этот сервис будет использоваться для метрик и аналитики.

**А как насчет межсервисного взаимодействия и обнаружения сервисов?

Поскольку наша архитектура основана на микросервисах, сервисы также будут взаимодействовать друг с другом. Как правило, REST или HTTP работают хорошо, но мы можем еще больше повысить производительность, используя [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc), который является более легким и эффективным.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) - это еще одна вещь, которую мы должны принять во внимание. Мы также можем использовать сетку сервисов, которая обеспечивает управляемую, наблюдаемую и безопасную связь между отдельными сервисами.

_Примечание: Узнайте больше о [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) и их сравнении друг с другом._

### Как должен работать сервис?

Вот как должен работать наш сервис:

![uber-working](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-working.png)

1. Клиент запрашивает поездку, указывая источник, пункт назначения, тип такси, способ оплаты и т. д.
2. Сервис регистрирует запрос, находит ближайших водителей и рассчитывает расчетное время прибытия (ETA).
3. Запрос передается ближайшим водителям, чтобы они приняли его или отклонили.
4. Если водитель принимает запрос, клиент получает уведомление о местонахождении водителя с указанием расчетного времени прибытия (ETA), пока он ждет попутку.
5. Клиента забирают, и водитель может начать поездку.
6. Как только место назначения будет достигнуто, водитель отметит поездку как завершенную и получит оплату.
7. После оплаты клиент может оставить оценку и отзыв о поездке, если захочет.

### Отслеживание местоположения

Как мы можем эффективно передавать и получать данные о местоположении клиента (клиента и водителя) в бэкэнд? У нас есть два варианта:

**Модель "Push-Pull"**.

_Клиент может периодически отправлять HTTP-запрос на серверы, чтобы сообщить о своем текущем местоположении и получить информацию о времени прибытия и цене. Этого можно добиться с помощью чего-то вроде [Long polling](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling)._

**Push model**

Клиент открывает долговременное соединение с сервером, и как только появляются новые данные, они передаются клиенту. Для этого мы можем использовать [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) или [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse).

Подход с использованием модели pull не является масштабируемым, поскольку он создает ненужные накладные расходы на запросы на наших серверах, и в большинстве случаев ответ будет пустым, что приводит к потере наших ресурсов. Для минимизации задержек лучше использовать модель push с [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets), так как в этом случае мы можем передавать данные клиенту, как только они становятся доступными, без задержек, при условии, что соединение с клиентом открыто. Кроме того, WebSockets обеспечивают полнодуплексную связь, в отличие от [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse), которые являются только однонаправленными.

Кроме того, клиентское приложение должно иметь некий механизм фоновой работы, чтобы пинговать местоположение GPS, пока приложение находится в фоновом режиме.

_Примечание: Узнайте больше о [Длинный опрос, WebSockets, Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events)._

### Поиск попутчиков

Нам нужен способ эффективно хранить и запрашивать ближайших водителей. Давайте рассмотрим различные решения, которые мы можем включить в наш дизайн.

**SQL**

У нас уже есть доступ к широте и долготе наших клиентов, и с помощью таких баз данных, как [PostgreSQL](https://www.postgresql.org) и [MySQL](https://www.mysql.com), мы можем выполнить запрос, чтобы найти местоположение ближайших водителей, задав широту и долготу (X, Y) в радиусе (R).

```ql
SELECT * FROM locations WHERE lat BETWEEN X-R AND X+R AND long BETWEEN Y-R AND Y+R
```

Однако этот способ не масштабируется, и выполнение этого запроса на больших наборах данных будет довольно медленным.

**Geohashing**

[Geohashing](/courses/sytem-design/geohashing-and-quadtrees#geohashing) - это метод [геокодирования](https://en.wikipedia.org/wiki/Address_geocoding), используемый для кодирования географических координат, таких как широта и долгота, в короткие буквенно-цифровые строки. Он был создан [Густаво Нимейером](https://twitter.com/gniemeyer) в 2008 году.

Geohash - это иерархический пространственный индекс, использующий кодировку алфавита Base-32. Первый символ в geohash идентифицирует начальное местоположение как одну из 32 ячеек. Эта ячейка также будет содержать 32 ячейки. Это означает, что для представления точки мир рекурсивно делится на все меньшие и меньшие ячейки с каждым дополнительным битом, пока не будет достигнута необходимая точность. Коэффициент точности также определяет размер ячейки.

![geohashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png)

Например, Сан-Франциско с координатами `37.7564, -122.4016` может быть представлен в геохаше как `9q8yy9mf`.

Теперь, используя геохэш клиента, мы можем определить ближайшего доступного водителя, просто сравнив его с геохэшем водителя. Для повышения производительности мы будем индексировать и хранить геохэш водителя в памяти для более быстрого поиска.

**Квадтреи**

[Quadtree](/courses/sytem-design/geohashing-and-quadtrees#quadtrees) - это древовидная структура данных, в которой каждый внутренний узел имеет ровно четыре дочерних. Они часто используются для разбиения двумерного пространства путем рекурсивного разбиения его на четыре квадранта или области. Каждый дочерний или листовой узел хранит пространственную информацию. Квадтри - это двумерный аналог [Octrees](https://en.wikipedia.org/wiki/Octree), который используется для разбиения трехмерного пространства.

![quadtree](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png)

Квадтри позволяет эффективно искать точки в двумерном диапазоне, где эти точки определены как координаты широты/долготы или как декартовы координаты (x, y).
Мы можем сэкономить дальнейшие вычисления, подразделяя узел только после определенного порога.

![quadtree-subdivision](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png)

[Quadtree](/courses/sytem-design/geohashing-and-quadtrees#quadtrees) кажется идеальным для нашего случая использования, мы можем обновлять Quadtree каждый раз, когда получаем новое обновление местоположения от водителя. Для снижения нагрузки на серверы квадтри мы можем использовать хранилище данных in-memory, например [Redis](https://redis.io), для кэширования последних обновлений. А с применением алгоритмов отображения, таких как [кривая Гильберта](https://en.wikipedia.org/wiki/Hilbert_curve), мы можем выполнять эффективные запросы диапазона для поиска ближайших водителей для клиента.

**А как насчет условий гонки?**

Условия гонки могут легко возникнуть, если большое количество клиентов будет запрашивать поездки одновременно. Чтобы избежать этого, мы можем обернуть нашу логику подбора водителей в [Mutex](<https://en.wikipedia.org/wiki/Lock_(computer_science)>), чтобы избежать любых условий гонки. Кроме того, каждое действие должно быть транзакционным по своей природе.

_За более подробной информацией обращайтесь к разделам [Транзакции](https://karanpratapsingh.com/courses/system-design/transactions) и [Распределенные транзакции](https://karanpratapsingh.com/courses/system-design/distributed-transactions)._

**Как найти лучших водителей поблизости?**

Получив список ближайших водителей с серверов Quadtree, мы можем провести некое ранжирование на основе таких параметров, как средний рейтинг, релевантность, отзывы клиентов и т. д. Это позволит нам отправлять уведомления в первую очередь наиболее доступным водителям.

**Решение проблемы высокого спроса**

В случае высокого спроса мы можем использовать концепцию Surge Pricing. Всплеск цен - это динамический метод ценообразования, при котором цены временно повышаются как реакция на повышенный спрос и ограниченное предложение. Эта цена может быть добавлена к базовой цене поездки.

_Для получения более подробной информации узнайте о том, как работает [суррогатное ценообразование](https://www.uber.com/us/en/drive/driver-app/how-surge-works) в Uber._

### Платежи

Обработка платежей в масштабе - сложная задача, поэтому для упрощения нашей системы мы можем использовать сторонний платежный процессор, например [Stripe](https://stripe.com) или [PayPal](https://www.paypal.com). После завершения платежа платежный процессор перенаправит пользователя обратно в наше приложение, и мы можем настроить [webhook](https://en.wikipedia.org/wiki/Webhook) для сбора всех данных, связанных с оплатой.

### Уведомления

Push-уведомления станут неотъемлемой частью нашей платформы. Мы можем использовать очередь сообщений или брокер сообщений, например [Apache Kafka](https://kafka.apache.org), вместе со службой уведомлений для отправки запросов в [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) или [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications), которые будут заниматься доставкой push-уведомлений на пользовательские устройства.

_За более подробной информацией обратитесь к проекту системы [WhatsApp](https://karanpratapsingh.com/courses/system-design/whatsapp#notifications), где мы подробно обсуждаем push-уведомления._

## Детальный дизайн

Пришло время обсудить наши проектные решения в деталях.

### Разбиение данных

Чтобы масштабировать наши базы данных, нам нужно разделить данные. Горизонтальное разделение (оно же [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) может стать хорошим первым шагом. Мы можем разделить нашу базу данных либо на основе существующих [схем разделов](https://karanpratapsingh.com/courses/system-design/sharding#partitioning-criteria), либо на основе регионов. Если мы разделим местоположения на регионы, используя, например, почтовые индексы, мы сможем эффективно хранить все данные в данном регионе на фиксированном узле. Но это все равно может привести к неравномерному распределению данных и нагрузки, что можно решить с помощью [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_Более подробную информацию вы найдете в разделах [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) и [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Метрики и аналитика

Запись аналитики и метрик - одно из наших расширенных требований. Мы можем получать данные из различных сервисов и выполнять аналитику на основе этих данных, используя [Apache Spark](https://spark.apache.org), который является унифицированным аналитическим движком с открытым исходным кодом для обработки крупномасштабных данных. Кроме того, мы можем хранить важные метаданные в таблице представлений, чтобы увеличить количество точек данных в наших данных.

### Кэширование

В платформе, основанной на сервисах определения местоположения, кэширование играет важную роль. Мы должны иметь возможность кэшировать последние местоположения клиентов и водителей для быстрого поиска. Мы можем использовать такие решения, как [Redis](https://redis.io) или [Memcached](https://memcached.org), но какая политика вытеснения кэша лучше всего подойдет для наших нужд?

**Какую политику вытеснения кэша использовать?**

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) может быть хорошей политикой для нашей системы. В этой политике мы сначала удаляем наименее недавно использованный ключ.

**Как обрабатывать пропуски кэша?**

Когда происходит пропуск кэша, наши серверы могут напрямую обращаться к базе данных и обновлять кэш новыми записями.

_Более подробную информацию см. в разделе [Кэширование](https://karanpratapsingh.com/courses/system-design/caching)._

## Выявление и устранение узких мест

![uber-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-advanced-design.png)

Давайте определим и устраним узкие места, такие как единые точки отказа в нашем дизайне:

- "Что, если один из наших сервисов сломается?"
- "Как мы будем распределять трафик между компонентами?"
- "Как мы можем снизить нагрузку на нашу базу данных?"
- "Как повысить доступность нашего кэша?"
- "Как сделать нашу систему уведомлений более надежной?"

Чтобы сделать нашу систему более устойчивой, мы можем сделать следующее:

- Запустить несколько экземпляров каждого из наших сервисов.
- Внедрение [балансировщиков нагрузки](https://karanpratapsingh.com/courses/system-design/load-balancing) между клиентами, серверами, базами данных и серверами кэша.
- Использование нескольких реплик чтения для наших баз данных.
- Несколько экземпляров и реплик для нашего распределенного кэша.
- Именно тогда, когда доставка и упорядочивание сообщений в распределенной системе являются сложной задачей, мы можем использовать специальный [брокер сообщений](https://karanpratapsingh.com/courses/system-design/message-brokers), такой как [Apache Kafka](https://kafka.apache.org) или [NATS](https://nats.io), чтобы сделать нашу систему уведомлений более надежной.

# Следующие шаги

Поздравляем, вы закончили курс!

Теперь, когда вы знаете основы системного проектирования, вот некоторые дополнительные ресурсы:

- [Распределенные системы](https://www.youtube.com/watch?v=UEAMfLPZZhE&list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB) (автор д-р Мартин Клеппманн)
- [System Design Interview: An Insider's Guide](https://www.amazon.in/System-Design-Interview-insiders-Second/dp/B08CMF2CQF)
- [Микросервисы](https://microservices.io) (автор Крис Ричардсон)
- [Бессерверные вычисления](https://en.wikipedia.org/wiki/Serverless_computing)
- [Kubernetes](https://kubernetes.io)

Также рекомендуем активно следить за инженерными блогами компаний, применяющих полученные на курсе знания на практике в масштабах:

- [Microsoft Engineering](https://engineering.microsoft.com)
- [Google Research Blog](http://googleresearch.blogspot.com)
- [Netflix Tech Blog](http://techblog.netflix.com)
- [AWS Blog](https://aws.amazon.com/blogs/aws)
- [Facebook Engineering](https://www.facebook.com/Engineering)
- [Блог Uber Engineering](http://eng.uber.com)
- [Airbnb Engineering](http://nerds.airbnb.com)
- [Блог инженера GitHub](https://github.blog/category/engineering)
- [Intel Software Blog](https://software.intel.com/en-us/blogs)
- [LinkedIn Engineering](http://engineering.linkedin.com/blog)
- [Paypal Developer Blog](https://medium.com/paypal-engineering)
- [Twitter Engineering](https://blog.twitter.com/engineering)

И последнее, но не менее важное: станьте добровольцем в новых проектах вашей компании и учитесь у старших инженеров и архитекторов, чтобы еще больше усовершенствовать свои навыки проектирования систем.

Я надеюсь, что этот курс был отличным опытом обучения. Я буду рад услышать от вас отзывы.

Желаю вам всего наилучшего в дальнейшем обучении!

# Ссылки

Вот ресурсы, на которые ссылались при создании этого курса.

- [Учебный центр Cloudflare](https://www.cloudflare.com/learning)
- [IBM Blogs](https://www.ibm.com/blogs)
- [Fastly Blogs](https://www.fastly.com/blog)
- [NS1 Blogs](https://ns1.com/blog)
- [Grokking the System Design Interview](https://www.designgurus.io/course/grokking-the-system-design-interview)
- [Grokking Microservices Design Patterns](https://www.designgurus.io/course/grokking-microservices-design-patterns)
- [System Design Primer](https://github.com/donnemartin/system-design-primer)
- [AWS Blogs](https://aws.amazon.com/blogs)
- [Architecture Patterns by Microsoft](https://learn.microsoft.com/en-us/azure/architecture/patterns)
- [Martin Fowler](https://martinfowler.com)
- [Ресурсы PagerDuty](https://www.pagerduty.com/resources)
- [VMWare Blogs](https://blogs.vmware.com/learning)

Все диаграммы были сделаны с помощью [Excalidraw](https://excalidraw.com) и доступны [здесь](https://github.com/karanpratapsingh/system-design/tree/main/diagrams)._
